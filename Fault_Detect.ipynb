{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fault_Detect.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ashraf-Saleh/Fault-Detect/blob/Trial-branch/Fault_Detect.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cbgwZWWfWpp"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9PFzkDY9Spa"
      },
      "source": [
        "import numpy\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import keras \n",
        "from keras import layers\n",
        "from keras.models import Sequential\n",
        "from keras.layers.convolutional import Conv1D, MaxPooling1D\n",
        "from keras.layers.convolutional import Conv2D, MaxPooling2D, AveragePooling2D\n",
        "from keras.optimizers import SGD\n",
        "from keras.layers import Dense, Flatten, Dropout, Activation, BatchNormalization,Concatenate, merge\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.models import model_from_json\n",
        "from keras.utils import plot_model\n",
        "import tensorflow as tf\n",
        "import random, os\n",
        "import multiprocessing as mp\n",
        "from queue import Empty\n",
        "import time"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4l8tGQJ9v91",
        "outputId": "d2521984-cea2-4f9b-9e92-e8fc77def0f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpO0tJE1908T"
      },
      "source": [
        "Data_X = numpy.load(\"/content/drive/My Drive/Colab_Data/Fault_Detect/Train_X_Sample.npy\",None,allow_pickle=True)\n",
        "Data_Y = numpy.load(\"/content/drive/My Drive/Colab_Data/Fault_Detect/Train_Y_Sample.npy\",None,allow_pickle=True)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RyuU4RWd95V2",
        "outputId": "a33bf51c-a239-4a71-95bb-79a5704fbdc3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#Train_X = Data_X\n",
        "#Train_Y = Data_Y\n",
        "Train_X = Data_X[:int(len(Data_X)*0.4)]\n",
        "Train_Y = Data_Y[:int(len(Data_Y)*0.4)]\n",
        "Vald_X = Data_X[int(len(Data_X)*0.4):int(len(Data_X)*0.7)]\n",
        "Vald_Y = Data_Y[int(len(Data_Y)*0.4):int(len(Data_Y)*0.7)]\n",
        "Test_X = Data_X[int(len(Data_X)*0.7):]\n",
        "Test_Y = Data_Y[int(len(Data_Y)*0.7):]\n",
        " \n",
        "print(Data_X.shape)\n",
        "print(Train_X.shape)\n",
        "print(Vald_X.shape)\n",
        "print(Test_X.shape)\n",
        "\n",
        "print(Data_Y.shape)\n",
        "print(Train_Y.shape)\n",
        "print(Vald_Y.shape)\n",
        "print(Test_Y.shape)\n",
        "\n",
        "print(Data_X.shape)\n",
        "print(Data_Y.shape)\n",
        "print(Data_X[:10])\n",
        "print(Data_Y[:10].astype('int'))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(22950, 5, 5000, 1)\n",
            "(9180, 5, 5000, 1)\n",
            "(6884, 5, 5000, 1)\n",
            "(6886, 5, 5000, 1)\n",
            "(22950, 9)\n",
            "(9180, 9)\n",
            "(6884, 9)\n",
            "(6886, 9)\n",
            "(22950, 5, 5000, 1)\n",
            "(22950, 9)\n",
            "[[[[ 0.13094077]\n",
            "   [ 0.13426788]\n",
            "   [ 0.13725989]\n",
            "   ...\n",
            "   [ 0.29248513]\n",
            "   [ 0.29248513]\n",
            "   [ 0.29248513]]\n",
            "\n",
            "  [[ 0.1185824 ]\n",
            "   [ 0.12181842]\n",
            "   [ 0.12472851]\n",
            "   ...\n",
            "   [ 0.2930481 ]\n",
            "   [ 0.2930481 ]\n",
            "   [ 0.2930481 ]]\n",
            "\n",
            "  [[ 0.06765384]\n",
            "   [ 0.06765384]\n",
            "   [ 0.06765384]\n",
            "   ...\n",
            "   [ 0.0653845 ]\n",
            "   [ 0.0653845 ]\n",
            "   [ 0.0653845 ]]\n",
            "\n",
            "  [[ 0.10997413]\n",
            "   [ 0.10997413]\n",
            "   [ 0.10997413]\n",
            "   ...\n",
            "   [ 0.05445085]\n",
            "   [ 0.05445085]\n",
            "   [ 0.05445085]]\n",
            "\n",
            "  [[ 0.31572279]\n",
            "   [ 0.30807951]\n",
            "   [ 0.29945085]\n",
            "   ...\n",
            "   [ 0.20175829]\n",
            "   [ 0.20368338]\n",
            "   [ 0.20553999]]]\n",
            "\n",
            "\n",
            " [[[ 0.09996753]\n",
            "   [ 0.09996753]\n",
            "   [ 0.09996753]\n",
            "   ...\n",
            "   [ 0.1853474 ]\n",
            "   [ 0.1897277 ]\n",
            "   [ 0.19018248]]\n",
            "\n",
            "  [[ 0.09835145]\n",
            "   [ 0.09877051]\n",
            "   [ 0.10244886]\n",
            "   ...\n",
            "   [ 0.22707055]\n",
            "   [ 0.22707055]\n",
            "   [ 0.22707055]]\n",
            "\n",
            "  [[ 0.12270904]\n",
            "   [ 0.12426921]\n",
            "   [ 0.12554571]\n",
            "   ...\n",
            "   [ 0.13322839]\n",
            "   [ 0.13594687]\n",
            "   [ 0.13816893]]\n",
            "\n",
            "  [[ 0.1363514 ]\n",
            "   [ 0.13785938]\n",
            "   [ 0.13860101]\n",
            "   ...\n",
            "   [ 0.14512734]\n",
            "   [ 0.14668476]\n",
            "   [ 0.14883549]]\n",
            "\n",
            "  [[ 0.00789118]\n",
            "   [-0.00136142]\n",
            "   [-0.00696548]\n",
            "   ...\n",
            "   [ 0.04603914]\n",
            "   [ 0.03142977]\n",
            "   [ 0.01752043]]]\n",
            "\n",
            "\n",
            " [[[ 0.06353688]\n",
            "   [ 0.06353688]\n",
            "   [ 0.06353688]\n",
            "   ...\n",
            "   [-0.67472249]\n",
            "   [-0.67472249]\n",
            "   [-0.67472249]]\n",
            "\n",
            "  [[ 0.09911972]\n",
            "   [ 0.09911972]\n",
            "   [ 0.09911972]\n",
            "   ...\n",
            "   [-0.5871726 ]\n",
            "   [-0.5871726 ]\n",
            "   [-0.58719588]]\n",
            "\n",
            "  [[ 0.14058011]\n",
            "   [ 0.13977638]\n",
            "   [ 0.13847624]\n",
            "   ...\n",
            "   [ 0.0853358 ]\n",
            "   [ 0.08519397]\n",
            "   [ 0.08495758]]\n",
            "\n",
            "  [[ 0.13983706]\n",
            "   [ 0.13899654]\n",
            "   [ 0.13763689]\n",
            "   ...\n",
            "   [ 0.10725483]\n",
            "   [ 0.1071065 ]\n",
            "   [ 0.10685929]]\n",
            "\n",
            "  [[-0.06298709]\n",
            "   [-0.07921833]\n",
            "   [-0.09483856]\n",
            "   ...\n",
            "   [-0.04833496]\n",
            "   [-0.05135514]\n",
            "   [-0.05409288]]]\n",
            "\n",
            "\n",
            " ...\n",
            "\n",
            "\n",
            " [[[ 0.11198343]\n",
            "   [ 0.10901536]\n",
            "   [ 0.1075792 ]\n",
            "   ...\n",
            "   [-0.47358792]\n",
            "   [-0.4730374 ]\n",
            "   [-0.47263048]]\n",
            "\n",
            "  [[ 0.11560247]\n",
            "   [ 0.11415906]\n",
            "   [ 0.11257597]\n",
            "   ...\n",
            "   [-0.49502751]\n",
            "   [-0.49449205]\n",
            "   [-0.49409628]]\n",
            "\n",
            "  [[ 0.05637804]\n",
            "   [ 0.05491243]\n",
            "   [ 0.05231214]\n",
            "   ...\n",
            "   [ 0.07677849]\n",
            "   [ 0.07677849]\n",
            "   [ 0.07677849]]\n",
            "\n",
            "  [[ 0.10043184]\n",
            "   [ 0.10040712]\n",
            "   [ 0.10040712]\n",
            "   ...\n",
            "   [ 0.66772848]\n",
            "   [ 0.66772848]\n",
            "   [ 0.66772848]]\n",
            "\n",
            "  [[-0.1410445 ]\n",
            "   [-0.13661984]\n",
            "   [-0.13046032]\n",
            "   ...\n",
            "   [-0.04525898]\n",
            "   [-0.04525911]\n",
            "   [-0.04525922]]]\n",
            "\n",
            "\n",
            " [[[ 0.06353688]\n",
            "   [ 0.06353688]\n",
            "   [ 0.06353688]\n",
            "   ...\n",
            "   [-0.66397521]\n",
            "   [-0.66397521]\n",
            "   [-0.66397521]]\n",
            "\n",
            "  [[ 0.09911972]\n",
            "   [ 0.09911972]\n",
            "   [ 0.09911972]\n",
            "   ...\n",
            "   [-0.59764892]\n",
            "   [-0.5976722 ]\n",
            "   [-0.5976722 ]]\n",
            "\n",
            "  [[ 0.14058011]\n",
            "   [ 0.13977638]\n",
            "   [ 0.13847624]\n",
            "   ...\n",
            "   [ 0.10996762]\n",
            "   [ 0.10982579]\n",
            "   [ 0.1095894 ]]\n",
            "\n",
            "  [[ 0.13983706]\n",
            "   [ 0.13899654]\n",
            "   [ 0.13763689]\n",
            "   ...\n",
            "   [ 0.08147086]\n",
            "   [ 0.08129782]\n",
            "   [ 0.08107533]]\n",
            "\n",
            "  [[-0.06298709]\n",
            "   [-0.07921833]\n",
            "   [-0.09483856]\n",
            "   ...\n",
            "   [-0.0483288 ]\n",
            "   [-0.05134183]\n",
            "   [-0.05407271]]]\n",
            "\n",
            "\n",
            " [[[ 0.09941701]\n",
            "   [ 0.10370156]\n",
            "   [ 0.10786643]\n",
            "   ...\n",
            "   [ 0.06356081]\n",
            "   [ 0.07011929]\n",
            "   [ 0.07677351]]\n",
            "\n",
            "  [[ 0.10610393]\n",
            "   [ 0.11027118]\n",
            "   [ 0.11432203]\n",
            "   ...\n",
            "   [ 0.09087834]\n",
            "   [ 0.09723398]\n",
            "   [ 0.10370602]]\n",
            "\n",
            "  [[ 0.07124697]\n",
            "   [ 0.07124697]\n",
            "   [ 0.07124697]\n",
            "   ...\n",
            "   [ 0.24071485]\n",
            "   [ 0.24071485]\n",
            "   [ 0.24071485]]\n",
            "\n",
            "  [[ 0.08814552]\n",
            "   [ 0.0881208 ]\n",
            "   [ 0.0881208 ]\n",
            "   ...\n",
            "   [ 0.31745717]\n",
            "   [ 0.31743245]\n",
            "   [ 0.31743245]]\n",
            "\n",
            "  [[ 0.33473019]\n",
            "   [ 0.33393505]\n",
            "   [ 0.33178169]\n",
            "   ...\n",
            "   [ 0.39495961]\n",
            "   [ 0.40169361]\n",
            "   [ 0.40629709]]]]\n",
            "[[0 0 0 0 0 0 0 1 0]\n",
            " [0 0 0 0 0 0 0 1 0]\n",
            " [0 0 0 0 1 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 1]\n",
            " [0 1 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 1 0 0]\n",
            " [0 1 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 1 0 0 0 0]\n",
            " [0 0 1 0 0 0 0 0 0]\n",
            " [0 0 0 1 0 0 0 0 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfxkga2O-DYs",
        "outputId": "b50a92e2-0670-4828-ad14-6fb609fc9606",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "inputs = keras.Input(shape = (Train_X.shape[1], Train_X.shape[2], Train_X.shape[3]), name=\"data\")\n",
        " \n",
        "x = layers.Conv2D(filters = 50, kernel_size = (2, 5),strides=(1, 2), activation = \"relu\") (inputs)\n",
        "x = layers.Conv2D(filters = 50, kernel_size = (2, 2),strides=(1, 2), activation = \"relu\") (x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.MaxPooling2D(pool_size = (1,10)) (x)\n",
        "\n",
        "x = layers.Conv2D(filters = 50, kernel_size = (2,5),strides = (1, 2),padding = 'valid', activation='relu') (x)\n",
        "x = layers.Conv2D(filters = 50, kernel_size = (1,5),strides = (1, 2),padding = 'valid', activation='relu') (x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.MaxPooling2D(pool_size = (1,8)) (x)\n",
        "\n",
        "x = layers.Conv2D(filters = 50,kernel_size= (2, 3),strides = (1, 2), activation=\"relu\")(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.MaxPooling2D(pool_size = (1,1))(x)\n",
        "\n",
        "#x = layers.Conv2D(filters = 50,kernel_size= (1, 10),strides = (1, 2), activation=\"relu\")(x)\n",
        "\n",
        "#x = layers.AveragePooling2D(pool_size = (1,4))(x)\n",
        "#x = layers.Conv2D(filters = 25,kernel_size= (1, 10),strides = (1, 1), activation=\"relu\")(x)\n",
        "#x = layers.AveragePooling2D(pool_size = (1,4))(x)\n",
        "\n",
        "'''\n",
        "x = layers.Conv2D(filters = 21, kernel_size = (3, 100), activation='relu') (inputs)\n",
        "block_1_output = layers.MaxPooling2D(pool_size = (1,4)) (x)\n",
        " \n",
        "x = layers.Conv2D(filters = 11, kernel_size = (2, 200), activation=\"relu\", padding=\"same\")(block_1_output)\n",
        "x = layers.Conv2D(filters = 21, kernel_size = (2, 20), activation=\"relu\", padding=\"same\")(x)\n",
        "block_2_output = layers.add([x, block_1_output])\n",
        " \n",
        " \n",
        "x = layers.Conv2D(filters = 21,kernel_size= (1, 50), activation=\"relu\", padding=\"same\")(block_2_output)\n",
        "x = layers.Conv2D(filters = 21,kernel_size= (1, 70), activation=\"relu\", padding=\"same\")(x)\n",
        "block_3_output = layers.add([x, block_2_output])\n",
        " \n",
        " \n",
        "x = layers.Conv2D(filters = 11, kernel_size = (2, 20), activation=\"relu\", padding=\"same\")(block_3_output)\n",
        "x = layers.Conv2D(filters = 21, kernel_size = (2, 20), activation=\"relu\", padding=\"same\")(x)\n",
        " \n",
        "block_6_output = layers.add([x, block_3_output])\n",
        " \n",
        "x = layers.Conv2D(filters = 21,kernel_size= (1, 20), activation=\"relu\", padding=\"same\")(block_6_output)\n",
        "x = layers.Conv2D(filters = 21,kernel_size= (1, 20), activation=\"relu\", padding=\"same\")(x)\n",
        "block_7_output = layers.add([x, block_6_output])\n",
        " \n",
        "x = layers.MaxPooling2D(pool_size = (1,4)) (block_7_output) \n",
        " '''\n",
        "x = layers.Flatten()(x) \n",
        " \n",
        " \n",
        "x = layers.Dense(64, activation=\"relu\")(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.Dense(58, activation=\"relu\")(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.Dense(52, activation=\"relu\")(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.Dense(46, activation=\"relu\")(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.Dense(40, activation=\"relu\")(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.Dense(32, activation=\"relu\")(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "#x = layers.Dense(28, activation=\"relu\")(x)\n",
        "#x = layers.Dense(22, activation=\"relu\")(x)\n",
        "#block_4_output = layers.Dense(16, activation=\"relu\")(x)\n",
        " \n",
        "#x = layers.Dense(16, activation=\"relu\")(block_4_output)\n",
        "#x = layers.Dense(16, activation=\"relu\")(x)\n",
        "x = layers.Dense(16, activation=\"relu\")(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "#block_5_output = layers.add([x, block_4_output])\n",
        " \n",
        "#x = block_5_output\n",
        "#x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(Train_Y.shape[1], activation='softmax')(x)\n",
        " \n",
        " \n",
        "model = keras.Model(inputs, outputs, name=\"model\")\n",
        " \n",
        "model.compile(optimizer='adam', loss='CategoricalCrossentropy', metrics=['accuracy'])\n",
        " \n",
        "model.summary()\n",
        "plot_model(model, to_file='/content/drive/My Drive/Colab_Data/Fault_Detect/model.png',show_shapes=True)\n",
        "plt.imshow(mpimg.imread('/content/drive/My Drive/Colab_Data/Fault_Detect/model.png'))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "data (InputLayer)            [(None, 5, 5000, 1)]      0         \n",
            "_________________________________________________________________\n",
            "conv2d_69 (Conv2D)           (None, 4, 2498, 50)       550       \n",
            "_________________________________________________________________\n",
            "conv2d_70 (Conv2D)           (None, 3, 1249, 50)       10050     \n",
            "_________________________________________________________________\n",
            "batch_normalization_117 (Bat (None, 3, 1249, 50)       200       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_54 (MaxPooling (None, 3, 124, 50)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_71 (Conv2D)           (None, 2, 60, 50)         25050     \n",
            "_________________________________________________________________\n",
            "conv2d_72 (Conv2D)           (None, 2, 28, 50)         12550     \n",
            "_________________________________________________________________\n",
            "batch_normalization_118 (Bat (None, 2, 28, 50)         200       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_55 (MaxPooling (None, 2, 3, 50)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_73 (Conv2D)           (None, 1, 1, 50)          15050     \n",
            "_________________________________________________________________\n",
            "batch_normalization_119 (Bat (None, 1, 1, 50)          200       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_56 (MaxPooling (None, 1, 1, 50)          0         \n",
            "_________________________________________________________________\n",
            "flatten_9 (Flatten)          (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense_72 (Dense)             (None, 64)                3264      \n",
            "_________________________________________________________________\n",
            "batch_normalization_120 (Bat (None, 64)                256       \n",
            "_________________________________________________________________\n",
            "dense_73 (Dense)             (None, 58)                3770      \n",
            "_________________________________________________________________\n",
            "batch_normalization_121 (Bat (None, 58)                232       \n",
            "_________________________________________________________________\n",
            "dense_74 (Dense)             (None, 52)                3068      \n",
            "_________________________________________________________________\n",
            "batch_normalization_122 (Bat (None, 52)                208       \n",
            "_________________________________________________________________\n",
            "dense_75 (Dense)             (None, 46)                2438      \n",
            "_________________________________________________________________\n",
            "batch_normalization_123 (Bat (None, 46)                184       \n",
            "_________________________________________________________________\n",
            "dense_76 (Dense)             (None, 40)                1880      \n",
            "_________________________________________________________________\n",
            "batch_normalization_124 (Bat (None, 40)                160       \n",
            "_________________________________________________________________\n",
            "dense_77 (Dense)             (None, 32)                1312      \n",
            "_________________________________________________________________\n",
            "batch_normalization_125 (Bat (None, 32)                128       \n",
            "_________________________________________________________________\n",
            "dense_78 (Dense)             (None, 16)                528       \n",
            "_________________________________________________________________\n",
            "batch_normalization_126 (Bat (None, 16)                64        \n",
            "_________________________________________________________________\n",
            "dense_79 (Dense)             (None, 9)                 153       \n",
            "=================================================================\n",
            "Total params: 81,495\n",
            "Trainable params: 80,579\n",
            "Non-trainable params: 916\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f7ccf32aa90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2ZHnfqh-E6C",
        "outputId": "274a5def-2e7a-42e8-e304-0913ff65000b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = model.fit(Train_X, Train_Y, epochs=1000,batch_size = 200, verbose=2, validation_data=(Vald_X,Vald_Y))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "46/46 - 4s - loss: 1.2319 - accuracy: 0.5720 - val_loss: 2.2034 - val_accuracy: 0.1075\n",
            "Epoch 2/1000\n",
            "46/46 - 3s - loss: 0.5978 - accuracy: 0.7707 - val_loss: 2.2295 - val_accuracy: 0.1079\n",
            "Epoch 3/1000\n",
            "46/46 - 3s - loss: 0.4364 - accuracy: 0.8241 - val_loss: 2.1856 - val_accuracy: 0.1296\n",
            "Epoch 4/1000\n",
            "46/46 - 3s - loss: 0.3837 - accuracy: 0.8321 - val_loss: 2.2169 - val_accuracy: 0.1296\n",
            "Epoch 5/1000\n",
            "46/46 - 3s - loss: 0.3405 - accuracy: 0.8386 - val_loss: 2.2847 - val_accuracy: 0.0763\n",
            "Epoch 6/1000\n",
            "46/46 - 3s - loss: 0.3189 - accuracy: 0.8477 - val_loss: 1.8859 - val_accuracy: 0.2693\n",
            "Epoch 7/1000\n",
            "46/46 - 3s - loss: 0.2958 - accuracy: 0.8545 - val_loss: 1.4574 - val_accuracy: 0.4001\n",
            "Epoch 8/1000\n",
            "46/46 - 3s - loss: 0.2754 - accuracy: 0.8602 - val_loss: 1.2603 - val_accuracy: 0.4526\n",
            "Epoch 9/1000\n",
            "46/46 - 3s - loss: 0.2479 - accuracy: 0.8757 - val_loss: 1.2379 - val_accuracy: 0.5662\n",
            "Epoch 10/1000\n",
            "46/46 - 3s - loss: 0.2313 - accuracy: 0.8841 - val_loss: 1.1385 - val_accuracy: 0.6027\n",
            "Epoch 11/1000\n",
            "46/46 - 3s - loss: 0.2165 - accuracy: 0.8925 - val_loss: 1.2479 - val_accuracy: 0.6225\n",
            "Epoch 12/1000\n",
            "46/46 - 3s - loss: 0.2213 - accuracy: 0.8883 - val_loss: 0.5997 - val_accuracy: 0.7895\n",
            "Epoch 13/1000\n",
            "46/46 - 3s - loss: 0.2081 - accuracy: 0.8952 - val_loss: 0.3990 - val_accuracy: 0.8081\n",
            "Epoch 14/1000\n",
            "46/46 - 3s - loss: 0.1729 - accuracy: 0.9117 - val_loss: 0.5513 - val_accuracy: 0.8093\n",
            "Epoch 15/1000\n",
            "46/46 - 3s - loss: 0.1731 - accuracy: 0.9075 - val_loss: 0.3292 - val_accuracy: 0.8574\n",
            "Epoch 16/1000\n",
            "46/46 - 3s - loss: 0.1672 - accuracy: 0.9110 - val_loss: 0.3173 - val_accuracy: 0.8344\n",
            "Epoch 17/1000\n",
            "46/46 - 3s - loss: 0.1697 - accuracy: 0.9016 - val_loss: 0.1899 - val_accuracy: 0.8909\n",
            "Epoch 18/1000\n",
            "46/46 - 3s - loss: 0.1697 - accuracy: 0.9051 - val_loss: 0.2372 - val_accuracy: 0.8803\n",
            "Epoch 19/1000\n",
            "46/46 - 3s - loss: 0.1865 - accuracy: 0.8966 - val_loss: 0.5648 - val_accuracy: 0.8154\n",
            "Epoch 20/1000\n",
            "46/46 - 3s - loss: 0.1707 - accuracy: 0.9059 - val_loss: 0.4851 - val_accuracy: 0.8186\n",
            "Epoch 21/1000\n",
            "46/46 - 3s - loss: 0.1657 - accuracy: 0.9136 - val_loss: 0.5713 - val_accuracy: 0.8438\n",
            "Epoch 22/1000\n",
            "46/46 - 3s - loss: 0.1530 - accuracy: 0.9151 - val_loss: 0.3462 - val_accuracy: 0.8579\n",
            "Epoch 23/1000\n",
            "46/46 - 3s - loss: 0.1449 - accuracy: 0.9180 - val_loss: 0.4674 - val_accuracy: 0.8592\n",
            "Epoch 24/1000\n",
            "46/46 - 3s - loss: 0.1579 - accuracy: 0.9135 - val_loss: 0.2114 - val_accuracy: 0.8979\n",
            "Epoch 25/1000\n",
            "46/46 - 3s - loss: 0.1399 - accuracy: 0.9219 - val_loss: 0.4002 - val_accuracy: 0.8282\n",
            "Epoch 26/1000\n",
            "46/46 - 3s - loss: 0.1563 - accuracy: 0.9169 - val_loss: 0.2416 - val_accuracy: 0.8640\n",
            "Epoch 27/1000\n",
            "46/46 - 3s - loss: 0.1466 - accuracy: 0.9174 - val_loss: 0.1288 - val_accuracy: 0.9277\n",
            "Epoch 28/1000\n",
            "46/46 - 3s - loss: 0.1498 - accuracy: 0.9183 - val_loss: 0.1496 - val_accuracy: 0.9182\n",
            "Epoch 29/1000\n",
            "46/46 - 3s - loss: 0.1372 - accuracy: 0.9242 - val_loss: 0.5965 - val_accuracy: 0.8420\n",
            "Epoch 30/1000\n",
            "46/46 - 3s - loss: 0.1437 - accuracy: 0.9228 - val_loss: 0.2250 - val_accuracy: 0.8899\n",
            "Epoch 31/1000\n",
            "46/46 - 3s - loss: 0.1346 - accuracy: 0.9221 - val_loss: 0.2118 - val_accuracy: 0.8818\n",
            "Epoch 32/1000\n",
            "46/46 - 3s - loss: 0.1434 - accuracy: 0.9217 - val_loss: 0.2351 - val_accuracy: 0.8767\n",
            "Epoch 33/1000\n",
            "46/46 - 3s - loss: 0.1483 - accuracy: 0.9157 - val_loss: 0.1935 - val_accuracy: 0.8873\n",
            "Epoch 34/1000\n",
            "46/46 - 3s - loss: 0.1357 - accuracy: 0.9200 - val_loss: 0.2151 - val_accuracy: 0.8832\n",
            "Epoch 35/1000\n",
            "46/46 - 3s - loss: 0.1454 - accuracy: 0.9191 - val_loss: 0.3109 - val_accuracy: 0.8521\n",
            "Epoch 36/1000\n",
            "46/46 - 3s - loss: 0.1268 - accuracy: 0.9320 - val_loss: 0.3589 - val_accuracy: 0.8451\n",
            "Epoch 37/1000\n",
            "46/46 - 3s - loss: 0.1506 - accuracy: 0.9193 - val_loss: 0.4719 - val_accuracy: 0.8213\n",
            "Epoch 38/1000\n",
            "46/46 - 3s - loss: 0.1233 - accuracy: 0.9296 - val_loss: 0.1496 - val_accuracy: 0.9160\n",
            "Epoch 39/1000\n",
            "46/46 - 3s - loss: 0.1236 - accuracy: 0.9283 - val_loss: 0.2035 - val_accuracy: 0.8976\n",
            "Epoch 40/1000\n",
            "46/46 - 3s - loss: 0.1136 - accuracy: 0.9330 - val_loss: 0.2286 - val_accuracy: 0.8973\n",
            "Epoch 41/1000\n",
            "46/46 - 3s - loss: 0.1339 - accuracy: 0.9210 - val_loss: 0.4279 - val_accuracy: 0.8395\n",
            "Epoch 42/1000\n",
            "46/46 - 3s - loss: 0.1401 - accuracy: 0.9205 - val_loss: 0.2017 - val_accuracy: 0.8972\n",
            "Epoch 43/1000\n",
            "46/46 - 3s - loss: 0.1265 - accuracy: 0.9290 - val_loss: 0.2054 - val_accuracy: 0.8956\n",
            "Epoch 44/1000\n",
            "46/46 - 3s - loss: 0.1335 - accuracy: 0.9246 - val_loss: 0.6340 - val_accuracy: 0.8271\n",
            "Epoch 45/1000\n",
            "46/46 - 3s - loss: 0.1315 - accuracy: 0.9291 - val_loss: 0.2636 - val_accuracy: 0.8963\n",
            "Epoch 46/1000\n",
            "46/46 - 3s - loss: 0.1315 - accuracy: 0.9228 - val_loss: 0.1562 - val_accuracy: 0.9082\n",
            "Epoch 47/1000\n",
            "46/46 - 3s - loss: 0.1247 - accuracy: 0.9310 - val_loss: 0.1443 - val_accuracy: 0.9272\n",
            "Epoch 48/1000\n",
            "46/46 - 3s - loss: 0.1200 - accuracy: 0.9307 - val_loss: 0.1906 - val_accuracy: 0.9099\n",
            "Epoch 49/1000\n",
            "46/46 - 3s - loss: 0.1090 - accuracy: 0.9394 - val_loss: 0.1061 - val_accuracy: 0.9393\n",
            "Epoch 50/1000\n",
            "46/46 - 3s - loss: 0.1095 - accuracy: 0.9402 - val_loss: 0.1836 - val_accuracy: 0.9214\n",
            "Epoch 51/1000\n",
            "46/46 - 3s - loss: 0.1158 - accuracy: 0.9337 - val_loss: 1.0574 - val_accuracy: 0.8013\n",
            "Epoch 52/1000\n",
            "46/46 - 3s - loss: 0.1392 - accuracy: 0.9255 - val_loss: 0.3077 - val_accuracy: 0.8453\n",
            "Epoch 53/1000\n",
            "46/46 - 3s - loss: 0.1128 - accuracy: 0.9390 - val_loss: 0.5229 - val_accuracy: 0.8623\n",
            "Epoch 54/1000\n",
            "46/46 - 3s - loss: 0.1160 - accuracy: 0.9324 - val_loss: 0.1877 - val_accuracy: 0.8908\n",
            "Epoch 55/1000\n",
            "46/46 - 3s - loss: 0.1262 - accuracy: 0.9281 - val_loss: 0.1194 - val_accuracy: 0.9246\n",
            "Epoch 56/1000\n",
            "46/46 - 3s - loss: 0.1029 - accuracy: 0.9388 - val_loss: 0.1386 - val_accuracy: 0.9265\n",
            "Epoch 57/1000\n",
            "46/46 - 3s - loss: 0.1000 - accuracy: 0.9419 - val_loss: 0.6849 - val_accuracy: 0.8587\n",
            "Epoch 58/1000\n",
            "46/46 - 3s - loss: 0.1122 - accuracy: 0.9364 - val_loss: 0.1630 - val_accuracy: 0.9266\n",
            "Epoch 59/1000\n",
            "46/46 - 3s - loss: 0.1146 - accuracy: 0.9394 - val_loss: 0.2246 - val_accuracy: 0.8979\n",
            "Epoch 60/1000\n",
            "46/46 - 3s - loss: 0.1239 - accuracy: 0.9295 - val_loss: 0.1836 - val_accuracy: 0.9059\n",
            "Epoch 61/1000\n",
            "46/46 - 3s - loss: 0.1276 - accuracy: 0.9296 - val_loss: 0.3390 - val_accuracy: 0.8547\n",
            "Epoch 62/1000\n",
            "46/46 - 3s - loss: 0.1433 - accuracy: 0.9253 - val_loss: 0.3322 - val_accuracy: 0.8241\n",
            "Epoch 63/1000\n",
            "46/46 - 3s - loss: 0.1229 - accuracy: 0.9296 - val_loss: 0.3650 - val_accuracy: 0.8453\n",
            "Epoch 64/1000\n",
            "46/46 - 3s - loss: 0.1208 - accuracy: 0.9296 - val_loss: 0.2104 - val_accuracy: 0.8979\n",
            "Epoch 65/1000\n",
            "46/46 - 3s - loss: 0.1163 - accuracy: 0.9305 - val_loss: 0.1390 - val_accuracy: 0.9237\n",
            "Epoch 66/1000\n",
            "46/46 - 3s - loss: 0.1288 - accuracy: 0.9275 - val_loss: 0.2744 - val_accuracy: 0.8682\n",
            "Epoch 67/1000\n",
            "46/46 - 3s - loss: 0.1160 - accuracy: 0.9337 - val_loss: 0.1114 - val_accuracy: 0.9252\n",
            "Epoch 68/1000\n",
            "46/46 - 3s - loss: 0.1106 - accuracy: 0.9328 - val_loss: 0.1492 - val_accuracy: 0.9099\n",
            "Epoch 69/1000\n",
            "46/46 - 3s - loss: 0.1090 - accuracy: 0.9345 - val_loss: 0.6675 - val_accuracy: 0.8268\n",
            "Epoch 70/1000\n",
            "46/46 - 3s - loss: 0.1408 - accuracy: 0.9228 - val_loss: 0.7585 - val_accuracy: 0.8309\n",
            "Epoch 71/1000\n",
            "46/46 - 3s - loss: 0.1157 - accuracy: 0.9322 - val_loss: 0.5932 - val_accuracy: 0.8261\n",
            "Epoch 72/1000\n",
            "46/46 - 3s - loss: 0.1226 - accuracy: 0.9296 - val_loss: 0.1625 - val_accuracy: 0.9030\n",
            "Epoch 73/1000\n",
            "46/46 - 3s - loss: 0.1221 - accuracy: 0.9303 - val_loss: 0.2591 - val_accuracy: 0.8966\n",
            "Epoch 74/1000\n",
            "46/46 - 3s - loss: 0.1285 - accuracy: 0.9345 - val_loss: 1.2350 - val_accuracy: 0.7905\n",
            "Epoch 75/1000\n",
            "46/46 - 3s - loss: 0.1255 - accuracy: 0.9301 - val_loss: 0.1157 - val_accuracy: 0.9323\n",
            "Epoch 76/1000\n",
            "46/46 - 3s - loss: 0.1072 - accuracy: 0.9408 - val_loss: 0.2071 - val_accuracy: 0.9099\n",
            "Epoch 77/1000\n",
            "46/46 - 3s - loss: 0.1060 - accuracy: 0.9406 - val_loss: 0.1354 - val_accuracy: 0.9339\n",
            "Epoch 78/1000\n",
            "46/46 - 3s - loss: 0.1099 - accuracy: 0.9379 - val_loss: 0.2630 - val_accuracy: 0.9038\n",
            "Epoch 79/1000\n",
            "46/46 - 3s - loss: 0.1048 - accuracy: 0.9389 - val_loss: 0.2396 - val_accuracy: 0.8912\n",
            "Epoch 80/1000\n",
            "46/46 - 3s - loss: 0.1205 - accuracy: 0.9333 - val_loss: 0.4158 - val_accuracy: 0.8754\n",
            "Epoch 81/1000\n",
            "46/46 - 3s - loss: 0.1116 - accuracy: 0.9368 - val_loss: 0.9297 - val_accuracy: 0.8729\n",
            "Epoch 82/1000\n",
            "46/46 - 3s - loss: 0.1022 - accuracy: 0.9455 - val_loss: 0.5189 - val_accuracy: 0.8819\n",
            "Epoch 83/1000\n",
            "46/46 - 3s - loss: 0.1020 - accuracy: 0.9427 - val_loss: 0.4989 - val_accuracy: 0.8694\n",
            "Epoch 84/1000\n",
            "46/46 - 3s - loss: 0.1070 - accuracy: 0.9412 - val_loss: 0.3985 - val_accuracy: 0.8610\n",
            "Epoch 85/1000\n",
            "46/46 - 3s - loss: 0.1004 - accuracy: 0.9429 - val_loss: 0.0977 - val_accuracy: 0.9474\n",
            "Epoch 86/1000\n",
            "46/46 - 3s - loss: 0.0994 - accuracy: 0.9447 - val_loss: 0.4466 - val_accuracy: 0.8617\n",
            "Epoch 87/1000\n",
            "46/46 - 3s - loss: 0.0950 - accuracy: 0.9473 - val_loss: 0.2525 - val_accuracy: 0.8905\n",
            "Epoch 88/1000\n",
            "46/46 - 3s - loss: 0.0932 - accuracy: 0.9487 - val_loss: 0.5572 - val_accuracy: 0.8719\n",
            "Epoch 89/1000\n",
            "46/46 - 3s - loss: 0.1028 - accuracy: 0.9428 - val_loss: 0.1289 - val_accuracy: 0.9210\n",
            "Epoch 90/1000\n",
            "46/46 - 3s - loss: 0.0934 - accuracy: 0.9477 - val_loss: 0.0919 - val_accuracy: 0.9429\n",
            "Epoch 91/1000\n",
            "46/46 - 3s - loss: 0.0869 - accuracy: 0.9535 - val_loss: 0.1570 - val_accuracy: 0.9182\n",
            "Epoch 92/1000\n",
            "46/46 - 3s - loss: 0.0869 - accuracy: 0.9528 - val_loss: 0.1778 - val_accuracy: 0.9002\n",
            "Epoch 93/1000\n",
            "46/46 - 3s - loss: 0.1034 - accuracy: 0.9442 - val_loss: 0.6385 - val_accuracy: 0.8544\n",
            "Epoch 94/1000\n",
            "46/46 - 3s - loss: 0.0873 - accuracy: 0.9492 - val_loss: 0.1354 - val_accuracy: 0.9336\n",
            "Epoch 95/1000\n",
            "46/46 - 3s - loss: 0.0866 - accuracy: 0.9517 - val_loss: 0.3695 - val_accuracy: 0.8932\n",
            "Epoch 96/1000\n",
            "46/46 - 3s - loss: 0.0798 - accuracy: 0.9547 - val_loss: 0.1150 - val_accuracy: 0.9371\n",
            "Epoch 97/1000\n",
            "46/46 - 3s - loss: 0.0861 - accuracy: 0.9508 - val_loss: 0.2144 - val_accuracy: 0.9057\n",
            "Epoch 98/1000\n",
            "46/46 - 3s - loss: 0.0885 - accuracy: 0.9531 - val_loss: 0.1009 - val_accuracy: 0.9473\n",
            "Epoch 99/1000\n",
            "46/46 - 3s - loss: 0.0911 - accuracy: 0.9510 - val_loss: 0.6468 - val_accuracy: 0.8465\n",
            "Epoch 100/1000\n",
            "46/46 - 3s - loss: 0.1014 - accuracy: 0.9443 - val_loss: 0.2292 - val_accuracy: 0.9031\n",
            "Epoch 101/1000\n",
            "46/46 - 3s - loss: 0.1035 - accuracy: 0.9467 - val_loss: 0.3723 - val_accuracy: 0.8838\n",
            "Epoch 102/1000\n",
            "46/46 - 3s - loss: 0.0887 - accuracy: 0.9535 - val_loss: 0.0843 - val_accuracy: 0.9518\n",
            "Epoch 103/1000\n",
            "46/46 - 3s - loss: 0.0900 - accuracy: 0.9528 - val_loss: 0.2334 - val_accuracy: 0.8990\n",
            "Epoch 104/1000\n",
            "46/46 - 3s - loss: 0.0880 - accuracy: 0.9492 - val_loss: 0.1807 - val_accuracy: 0.9101\n",
            "Epoch 105/1000\n",
            "46/46 - 3s - loss: 0.0913 - accuracy: 0.9491 - val_loss: 0.1743 - val_accuracy: 0.9172\n",
            "Epoch 106/1000\n",
            "46/46 - 3s - loss: 0.0900 - accuracy: 0.9498 - val_loss: 0.1107 - val_accuracy: 0.9403\n",
            "Epoch 107/1000\n",
            "46/46 - 3s - loss: 0.0828 - accuracy: 0.9533 - val_loss: 0.3062 - val_accuracy: 0.8790\n",
            "Epoch 108/1000\n",
            "46/46 - 3s - loss: 0.0843 - accuracy: 0.9512 - val_loss: 0.2580 - val_accuracy: 0.9163\n",
            "Epoch 109/1000\n",
            "46/46 - 3s - loss: 0.0801 - accuracy: 0.9535 - val_loss: 0.2742 - val_accuracy: 0.8998\n",
            "Epoch 110/1000\n",
            "46/46 - 3s - loss: 0.0818 - accuracy: 0.9545 - val_loss: 0.1049 - val_accuracy: 0.9454\n",
            "Epoch 111/1000\n",
            "46/46 - 3s - loss: 0.0876 - accuracy: 0.9556 - val_loss: 0.3708 - val_accuracy: 0.8931\n",
            "Epoch 112/1000\n",
            "46/46 - 3s - loss: 0.0895 - accuracy: 0.9509 - val_loss: 0.3449 - val_accuracy: 0.8791\n",
            "Epoch 113/1000\n",
            "46/46 - 3s - loss: 0.0858 - accuracy: 0.9520 - val_loss: 0.0923 - val_accuracy: 0.9538\n",
            "Epoch 114/1000\n",
            "46/46 - 3s - loss: 0.0787 - accuracy: 0.9522 - val_loss: 0.0882 - val_accuracy: 0.9487\n",
            "Epoch 115/1000\n",
            "46/46 - 3s - loss: 0.0843 - accuracy: 0.9529 - val_loss: 0.2284 - val_accuracy: 0.9146\n",
            "Epoch 116/1000\n",
            "46/46 - 3s - loss: 0.0829 - accuracy: 0.9557 - val_loss: 0.1340 - val_accuracy: 0.9284\n",
            "Epoch 117/1000\n",
            "46/46 - 3s - loss: 0.0750 - accuracy: 0.9558 - val_loss: 0.0863 - val_accuracy: 0.9518\n",
            "Epoch 118/1000\n",
            "46/46 - 3s - loss: 0.0729 - accuracy: 0.9588 - val_loss: 0.3078 - val_accuracy: 0.9060\n",
            "Epoch 119/1000\n",
            "46/46 - 3s - loss: 0.0735 - accuracy: 0.9562 - val_loss: 0.1047 - val_accuracy: 0.9442\n",
            "Epoch 120/1000\n",
            "46/46 - 3s - loss: 0.0709 - accuracy: 0.9577 - val_loss: 0.1038 - val_accuracy: 0.9451\n",
            "Epoch 121/1000\n",
            "46/46 - 3s - loss: 0.0732 - accuracy: 0.9584 - val_loss: 0.1301 - val_accuracy: 0.9410\n",
            "Epoch 122/1000\n",
            "46/46 - 3s - loss: 0.0803 - accuracy: 0.9557 - val_loss: 0.1387 - val_accuracy: 0.9298\n",
            "Epoch 123/1000\n",
            "46/46 - 3s - loss: 0.0677 - accuracy: 0.9610 - val_loss: 0.0808 - val_accuracy: 0.9524\n",
            "Epoch 124/1000\n",
            "46/46 - 3s - loss: 0.0742 - accuracy: 0.9590 - val_loss: 0.1834 - val_accuracy: 0.8992\n",
            "Epoch 125/1000\n",
            "46/46 - 3s - loss: 0.0827 - accuracy: 0.9538 - val_loss: 0.1237 - val_accuracy: 0.9378\n",
            "Epoch 126/1000\n",
            "46/46 - 3s - loss: 0.0875 - accuracy: 0.9519 - val_loss: 0.3307 - val_accuracy: 0.8857\n",
            "Epoch 127/1000\n",
            "46/46 - 3s - loss: 0.0811 - accuracy: 0.9534 - val_loss: 0.1783 - val_accuracy: 0.9202\n",
            "Epoch 128/1000\n",
            "46/46 - 3s - loss: 0.0918 - accuracy: 0.9490 - val_loss: 0.1372 - val_accuracy: 0.9310\n",
            "Epoch 129/1000\n",
            "46/46 - 3s - loss: 0.0958 - accuracy: 0.9493 - val_loss: 0.6867 - val_accuracy: 0.8675\n",
            "Epoch 130/1000\n",
            "46/46 - 3s - loss: 0.0979 - accuracy: 0.9504 - val_loss: 0.2423 - val_accuracy: 0.8854\n",
            "Epoch 131/1000\n",
            "46/46 - 3s - loss: 0.0848 - accuracy: 0.9525 - val_loss: 0.1182 - val_accuracy: 0.9384\n",
            "Epoch 132/1000\n",
            "46/46 - 3s - loss: 0.0819 - accuracy: 0.9541 - val_loss: 0.2352 - val_accuracy: 0.9053\n",
            "Epoch 133/1000\n",
            "46/46 - 3s - loss: 0.0814 - accuracy: 0.9540 - val_loss: 0.1205 - val_accuracy: 0.9415\n",
            "Epoch 134/1000\n",
            "46/46 - 3s - loss: 0.0678 - accuracy: 0.9596 - val_loss: 0.1065 - val_accuracy: 0.9447\n",
            "Epoch 135/1000\n",
            "46/46 - 3s - loss: 0.0661 - accuracy: 0.9625 - val_loss: 0.0842 - val_accuracy: 0.9512\n",
            "Epoch 136/1000\n",
            "46/46 - 3s - loss: 0.0685 - accuracy: 0.9608 - val_loss: 0.0955 - val_accuracy: 0.9474\n",
            "Epoch 137/1000\n",
            "46/46 - 3s - loss: 0.0763 - accuracy: 0.9569 - val_loss: 0.1724 - val_accuracy: 0.9291\n",
            "Epoch 138/1000\n",
            "46/46 - 3s - loss: 0.0820 - accuracy: 0.9540 - val_loss: 0.1489 - val_accuracy: 0.9358\n",
            "Epoch 139/1000\n",
            "46/46 - 3s - loss: 0.0792 - accuracy: 0.9553 - val_loss: 0.0860 - val_accuracy: 0.9579\n",
            "Epoch 140/1000\n",
            "46/46 - 3s - loss: 0.0695 - accuracy: 0.9595 - val_loss: 0.0905 - val_accuracy: 0.9484\n",
            "Epoch 141/1000\n",
            "46/46 - 3s - loss: 0.0730 - accuracy: 0.9572 - val_loss: 0.1173 - val_accuracy: 0.9377\n",
            "Epoch 142/1000\n",
            "46/46 - 3s - loss: 0.0720 - accuracy: 0.9572 - val_loss: 0.1273 - val_accuracy: 0.9412\n",
            "Epoch 143/1000\n",
            "46/46 - 3s - loss: 0.0848 - accuracy: 0.9545 - val_loss: 0.1605 - val_accuracy: 0.9300\n",
            "Epoch 144/1000\n",
            "46/46 - 3s - loss: 0.0785 - accuracy: 0.9571 - val_loss: 0.1647 - val_accuracy: 0.9160\n",
            "Epoch 145/1000\n",
            "46/46 - 3s - loss: 0.0705 - accuracy: 0.9587 - val_loss: 0.0751 - val_accuracy: 0.9590\n",
            "Epoch 146/1000\n",
            "46/46 - 3s - loss: 0.0807 - accuracy: 0.9569 - val_loss: 0.1852 - val_accuracy: 0.9066\n",
            "Epoch 147/1000\n",
            "46/46 - 3s - loss: 0.0699 - accuracy: 0.9587 - val_loss: 0.0936 - val_accuracy: 0.9468\n",
            "Epoch 148/1000\n",
            "46/46 - 3s - loss: 0.0781 - accuracy: 0.9587 - val_loss: 0.0757 - val_accuracy: 0.9576\n",
            "Epoch 149/1000\n",
            "46/46 - 3s - loss: 0.0698 - accuracy: 0.9595 - val_loss: 0.0925 - val_accuracy: 0.9563\n",
            "Epoch 150/1000\n",
            "46/46 - 3s - loss: 0.0703 - accuracy: 0.9607 - val_loss: 0.0803 - val_accuracy: 0.9555\n",
            "Epoch 151/1000\n",
            "46/46 - 3s - loss: 0.0636 - accuracy: 0.9624 - val_loss: 0.0863 - val_accuracy: 0.9512\n",
            "Epoch 152/1000\n",
            "46/46 - 3s - loss: 0.0668 - accuracy: 0.9625 - val_loss: 0.0946 - val_accuracy: 0.9494\n",
            "Epoch 153/1000\n",
            "46/46 - 3s - loss: 0.0822 - accuracy: 0.9553 - val_loss: 0.0994 - val_accuracy: 0.9480\n",
            "Epoch 154/1000\n",
            "46/46 - 3s - loss: 0.0699 - accuracy: 0.9623 - val_loss: 0.0812 - val_accuracy: 0.9525\n",
            "Epoch 155/1000\n",
            "46/46 - 3s - loss: 0.0745 - accuracy: 0.9589 - val_loss: 0.1300 - val_accuracy: 0.9348\n",
            "Epoch 156/1000\n",
            "46/46 - 3s - loss: 0.0853 - accuracy: 0.9540 - val_loss: 0.7514 - val_accuracy: 0.8800\n",
            "Epoch 157/1000\n",
            "46/46 - 3s - loss: 0.0786 - accuracy: 0.9571 - val_loss: 0.1807 - val_accuracy: 0.9246\n",
            "Epoch 158/1000\n",
            "46/46 - 3s - loss: 0.0907 - accuracy: 0.9517 - val_loss: 1.1090 - val_accuracy: 0.8004\n",
            "Epoch 159/1000\n",
            "46/46 - 3s - loss: 0.0882 - accuracy: 0.9554 - val_loss: 0.5803 - val_accuracy: 0.8870\n",
            "Epoch 160/1000\n",
            "46/46 - 3s - loss: 0.0737 - accuracy: 0.9600 - val_loss: 0.0884 - val_accuracy: 0.9518\n",
            "Epoch 161/1000\n",
            "46/46 - 3s - loss: 0.0658 - accuracy: 0.9625 - val_loss: 0.5148 - val_accuracy: 0.8960\n",
            "Epoch 162/1000\n",
            "46/46 - 3s - loss: 0.0702 - accuracy: 0.9572 - val_loss: 0.1588 - val_accuracy: 0.9307\n",
            "Epoch 163/1000\n",
            "46/46 - 3s - loss: 0.0717 - accuracy: 0.9623 - val_loss: 0.0763 - val_accuracy: 0.9538\n",
            "Epoch 164/1000\n",
            "46/46 - 3s - loss: 0.0664 - accuracy: 0.9592 - val_loss: 0.0823 - val_accuracy: 0.9521\n",
            "Epoch 165/1000\n",
            "46/46 - 3s - loss: 0.0635 - accuracy: 0.9642 - val_loss: 0.0995 - val_accuracy: 0.9416\n",
            "Epoch 166/1000\n",
            "46/46 - 3s - loss: 0.0621 - accuracy: 0.9662 - val_loss: 0.0805 - val_accuracy: 0.9580\n",
            "Epoch 167/1000\n",
            "46/46 - 3s - loss: 0.0644 - accuracy: 0.9637 - val_loss: 0.1259 - val_accuracy: 0.9213\n",
            "Epoch 168/1000\n",
            "46/46 - 3s - loss: 0.0873 - accuracy: 0.9592 - val_loss: 0.5170 - val_accuracy: 0.8929\n",
            "Epoch 169/1000\n",
            "46/46 - 3s - loss: 0.0668 - accuracy: 0.9636 - val_loss: 0.8318 - val_accuracy: 0.8925\n",
            "Epoch 170/1000\n",
            "46/46 - 3s - loss: 0.0664 - accuracy: 0.9636 - val_loss: 0.4051 - val_accuracy: 0.9034\n",
            "Epoch 171/1000\n",
            "46/46 - 3s - loss: 0.0625 - accuracy: 0.9654 - val_loss: 0.1216 - val_accuracy: 0.9449\n",
            "Epoch 172/1000\n",
            "46/46 - 3s - loss: 0.0605 - accuracy: 0.9638 - val_loss: 0.2003 - val_accuracy: 0.9290\n",
            "Epoch 173/1000\n",
            "46/46 - 3s - loss: 0.0589 - accuracy: 0.9643 - val_loss: 0.0902 - val_accuracy: 0.9541\n",
            "Epoch 174/1000\n",
            "46/46 - 3s - loss: 0.0601 - accuracy: 0.9656 - val_loss: 0.0727 - val_accuracy: 0.9662\n",
            "Epoch 175/1000\n",
            "46/46 - 3s - loss: 0.0594 - accuracy: 0.9671 - val_loss: 0.1455 - val_accuracy: 0.9413\n",
            "Epoch 176/1000\n",
            "46/46 - 3s - loss: 0.0607 - accuracy: 0.9645 - val_loss: 0.1079 - val_accuracy: 0.9494\n",
            "Epoch 177/1000\n",
            "46/46 - 3s - loss: 0.0635 - accuracy: 0.9666 - val_loss: 0.5671 - val_accuracy: 0.8897\n",
            "Epoch 178/1000\n",
            "46/46 - 3s - loss: 0.0646 - accuracy: 0.9626 - val_loss: 0.0675 - val_accuracy: 0.9622\n",
            "Epoch 179/1000\n",
            "46/46 - 3s - loss: 0.0596 - accuracy: 0.9669 - val_loss: 0.0743 - val_accuracy: 0.9596\n",
            "Epoch 180/1000\n",
            "46/46 - 3s - loss: 0.0664 - accuracy: 0.9634 - val_loss: 0.2676 - val_accuracy: 0.9277\n",
            "Epoch 181/1000\n",
            "46/46 - 3s - loss: 0.0633 - accuracy: 0.9655 - val_loss: 0.0923 - val_accuracy: 0.9561\n",
            "Epoch 182/1000\n",
            "46/46 - 3s - loss: 0.0553 - accuracy: 0.9682 - val_loss: 0.1212 - val_accuracy: 0.9457\n",
            "Epoch 183/1000\n",
            "46/46 - 3s - loss: 0.0608 - accuracy: 0.9682 - val_loss: 0.1477 - val_accuracy: 0.9417\n",
            "Epoch 184/1000\n",
            "46/46 - 3s - loss: 0.0664 - accuracy: 0.9627 - val_loss: 0.2023 - val_accuracy: 0.9168\n",
            "Epoch 185/1000\n",
            "46/46 - 3s - loss: 0.0691 - accuracy: 0.9610 - val_loss: 0.0859 - val_accuracy: 0.9569\n",
            "Epoch 186/1000\n",
            "46/46 - 3s - loss: 0.0627 - accuracy: 0.9644 - val_loss: 0.1957 - val_accuracy: 0.9246\n",
            "Epoch 187/1000\n",
            "46/46 - 3s - loss: 0.0625 - accuracy: 0.9669 - val_loss: 0.0826 - val_accuracy: 0.9573\n",
            "Epoch 188/1000\n",
            "46/46 - 3s - loss: 0.0860 - accuracy: 0.9589 - val_loss: 0.0904 - val_accuracy: 0.9535\n",
            "Epoch 189/1000\n",
            "46/46 - 3s - loss: 0.0631 - accuracy: 0.9645 - val_loss: 0.0694 - val_accuracy: 0.9602\n",
            "Epoch 190/1000\n",
            "46/46 - 3s - loss: 0.0626 - accuracy: 0.9624 - val_loss: 0.0981 - val_accuracy: 0.9490\n",
            "Epoch 191/1000\n",
            "46/46 - 3s - loss: 0.0550 - accuracy: 0.9681 - val_loss: 0.1451 - val_accuracy: 0.9455\n",
            "Epoch 192/1000\n",
            "46/46 - 3s - loss: 0.0758 - accuracy: 0.9600 - val_loss: 1.3526 - val_accuracy: 0.8052\n",
            "Epoch 193/1000\n",
            "46/46 - 3s - loss: 0.0686 - accuracy: 0.9635 - val_loss: 0.2915 - val_accuracy: 0.8996\n",
            "Epoch 194/1000\n",
            "46/46 - 3s - loss: 0.0632 - accuracy: 0.9650 - val_loss: 0.7230 - val_accuracy: 0.8999\n",
            "Epoch 195/1000\n",
            "46/46 - 3s - loss: 0.0625 - accuracy: 0.9654 - val_loss: 0.2327 - val_accuracy: 0.9075\n",
            "Epoch 196/1000\n",
            "46/46 - 3s - loss: 0.0641 - accuracy: 0.9659 - val_loss: 0.0785 - val_accuracy: 0.9624\n",
            "Epoch 197/1000\n",
            "46/46 - 3s - loss: 0.0639 - accuracy: 0.9670 - val_loss: 0.0908 - val_accuracy: 0.9515\n",
            "Epoch 198/1000\n",
            "46/46 - 3s - loss: 0.0551 - accuracy: 0.9683 - val_loss: 0.1489 - val_accuracy: 0.9266\n",
            "Epoch 199/1000\n",
            "46/46 - 3s - loss: 0.0565 - accuracy: 0.9690 - val_loss: 0.1588 - val_accuracy: 0.9441\n",
            "Epoch 200/1000\n",
            "46/46 - 3s - loss: 0.0745 - accuracy: 0.9612 - val_loss: 0.6195 - val_accuracy: 0.8889\n",
            "Epoch 201/1000\n",
            "46/46 - 3s - loss: 0.0606 - accuracy: 0.9673 - val_loss: 0.8342 - val_accuracy: 0.8934\n",
            "Epoch 202/1000\n",
            "46/46 - 3s - loss: 0.0557 - accuracy: 0.9673 - val_loss: 0.8576 - val_accuracy: 0.9006\n",
            "Epoch 203/1000\n",
            "46/46 - 3s - loss: 0.0569 - accuracy: 0.9660 - val_loss: 0.2924 - val_accuracy: 0.9246\n",
            "Epoch 204/1000\n",
            "46/46 - 3s - loss: 0.0588 - accuracy: 0.9648 - val_loss: 1.2882 - val_accuracy: 0.8928\n",
            "Epoch 205/1000\n",
            "46/46 - 3s - loss: 0.0644 - accuracy: 0.9641 - val_loss: 0.1868 - val_accuracy: 0.9175\n",
            "Epoch 206/1000\n",
            "46/46 - 3s - loss: 0.0564 - accuracy: 0.9671 - val_loss: 0.1381 - val_accuracy: 0.9377\n",
            "Epoch 207/1000\n",
            "46/46 - 3s - loss: 0.0658 - accuracy: 0.9653 - val_loss: 0.0932 - val_accuracy: 0.9547\n",
            "Epoch 208/1000\n",
            "46/46 - 3s - loss: 0.0563 - accuracy: 0.9662 - val_loss: 0.0876 - val_accuracy: 0.9561\n",
            "Epoch 209/1000\n",
            "46/46 - 3s - loss: 0.0576 - accuracy: 0.9662 - val_loss: 0.0792 - val_accuracy: 0.9609\n",
            "Epoch 210/1000\n",
            "46/46 - 3s - loss: 0.0606 - accuracy: 0.9644 - val_loss: 0.0699 - val_accuracy: 0.9576\n",
            "Epoch 211/1000\n",
            "46/46 - 3s - loss: 0.0746 - accuracy: 0.9623 - val_loss: 0.1355 - val_accuracy: 0.9261\n",
            "Epoch 212/1000\n",
            "46/46 - 3s - loss: 0.0588 - accuracy: 0.9687 - val_loss: 0.0966 - val_accuracy: 0.9460\n",
            "Epoch 213/1000\n",
            "46/46 - 3s - loss: 0.0549 - accuracy: 0.9675 - val_loss: 0.0697 - val_accuracy: 0.9611\n",
            "Epoch 214/1000\n",
            "46/46 - 3s - loss: 0.0533 - accuracy: 0.9672 - val_loss: 0.2436 - val_accuracy: 0.9210\n",
            "Epoch 215/1000\n",
            "46/46 - 3s - loss: 0.0531 - accuracy: 0.9680 - val_loss: 0.0704 - val_accuracy: 0.9609\n",
            "Epoch 216/1000\n",
            "46/46 - 3s - loss: 0.0543 - accuracy: 0.9675 - val_loss: 0.0746 - val_accuracy: 0.9614\n",
            "Epoch 217/1000\n",
            "46/46 - 3s - loss: 0.0509 - accuracy: 0.9683 - val_loss: 0.0680 - val_accuracy: 0.9627\n",
            "Epoch 218/1000\n",
            "46/46 - 3s - loss: 0.0529 - accuracy: 0.9687 - val_loss: 0.9141 - val_accuracy: 0.9005\n",
            "Epoch 219/1000\n",
            "46/46 - 3s - loss: 0.0595 - accuracy: 0.9663 - val_loss: 0.2260 - val_accuracy: 0.9319\n",
            "Epoch 220/1000\n",
            "46/46 - 3s - loss: 0.0610 - accuracy: 0.9649 - val_loss: 0.0736 - val_accuracy: 0.9614\n",
            "Epoch 221/1000\n",
            "46/46 - 3s - loss: 0.0628 - accuracy: 0.9671 - val_loss: 0.1704 - val_accuracy: 0.9266\n",
            "Epoch 222/1000\n",
            "46/46 - 3s - loss: 0.0587 - accuracy: 0.9649 - val_loss: 0.1059 - val_accuracy: 0.9494\n",
            "Epoch 223/1000\n",
            "46/46 - 3s - loss: 0.0624 - accuracy: 0.9669 - val_loss: 0.2162 - val_accuracy: 0.9252\n",
            "Epoch 224/1000\n",
            "46/46 - 3s - loss: 0.0572 - accuracy: 0.9667 - val_loss: 0.0735 - val_accuracy: 0.9585\n",
            "Epoch 225/1000\n",
            "46/46 - 3s - loss: 0.0606 - accuracy: 0.9654 - val_loss: 0.1160 - val_accuracy: 0.9431\n",
            "Epoch 226/1000\n",
            "46/46 - 3s - loss: 0.0947 - accuracy: 0.9516 - val_loss: 0.3002 - val_accuracy: 0.8988\n",
            "Epoch 227/1000\n",
            "46/46 - 3s - loss: 0.0648 - accuracy: 0.9674 - val_loss: 0.1021 - val_accuracy: 0.9509\n",
            "Epoch 228/1000\n",
            "46/46 - 3s - loss: 0.0581 - accuracy: 0.9655 - val_loss: 0.0818 - val_accuracy: 0.9576\n",
            "Epoch 229/1000\n",
            "46/46 - 3s - loss: 0.0532 - accuracy: 0.9684 - val_loss: 0.0775 - val_accuracy: 0.9631\n",
            "Epoch 230/1000\n",
            "46/46 - 3s - loss: 0.0564 - accuracy: 0.9669 - val_loss: 0.0980 - val_accuracy: 0.9550\n",
            "Epoch 231/1000\n",
            "46/46 - 3s - loss: 0.0627 - accuracy: 0.9647 - val_loss: 0.1195 - val_accuracy: 0.9402\n",
            "Epoch 232/1000\n",
            "46/46 - 3s - loss: 0.0564 - accuracy: 0.9683 - val_loss: 0.2878 - val_accuracy: 0.9185\n",
            "Epoch 233/1000\n",
            "46/46 - 3s - loss: 0.0604 - accuracy: 0.9667 - val_loss: 0.0745 - val_accuracy: 0.9582\n",
            "Epoch 234/1000\n",
            "46/46 - 3s - loss: 0.0520 - accuracy: 0.9676 - val_loss: 0.0727 - val_accuracy: 0.9644\n",
            "Epoch 235/1000\n",
            "46/46 - 3s - loss: 0.0560 - accuracy: 0.9675 - val_loss: 0.1081 - val_accuracy: 0.9480\n",
            "Epoch 236/1000\n",
            "46/46 - 3s - loss: 0.0625 - accuracy: 0.9653 - val_loss: 0.0997 - val_accuracy: 0.9538\n",
            "Epoch 237/1000\n",
            "46/46 - 3s - loss: 0.0641 - accuracy: 0.9641 - val_loss: 0.1850 - val_accuracy: 0.9304\n",
            "Epoch 238/1000\n",
            "46/46 - 3s - loss: 0.0572 - accuracy: 0.9672 - val_loss: 0.1361 - val_accuracy: 0.9431\n",
            "Epoch 239/1000\n",
            "46/46 - 3s - loss: 0.0551 - accuracy: 0.9666 - val_loss: 0.0895 - val_accuracy: 0.9526\n",
            "Epoch 240/1000\n",
            "46/46 - 3s - loss: 0.0539 - accuracy: 0.9676 - val_loss: 0.0798 - val_accuracy: 0.9601\n",
            "Epoch 241/1000\n",
            "46/46 - 3s - loss: 0.0503 - accuracy: 0.9690 - val_loss: 0.0756 - val_accuracy: 0.9595\n",
            "Epoch 242/1000\n",
            "46/46 - 3s - loss: 0.0640 - accuracy: 0.9646 - val_loss: 0.0865 - val_accuracy: 0.9590\n",
            "Epoch 243/1000\n",
            "46/46 - 3s - loss: 0.0611 - accuracy: 0.9661 - val_loss: 0.0970 - val_accuracy: 0.9492\n",
            "Epoch 244/1000\n",
            "46/46 - 3s - loss: 0.0531 - accuracy: 0.9680 - val_loss: 0.0712 - val_accuracy: 0.9622\n",
            "Epoch 245/1000\n",
            "46/46 - 3s - loss: 0.0533 - accuracy: 0.9675 - val_loss: 0.1022 - val_accuracy: 0.9441\n",
            "Epoch 246/1000\n",
            "46/46 - 3s - loss: 0.0489 - accuracy: 0.9698 - val_loss: 0.0761 - val_accuracy: 0.9619\n",
            "Epoch 247/1000\n",
            "46/46 - 3s - loss: 0.0491 - accuracy: 0.9698 - val_loss: 0.1580 - val_accuracy: 0.9448\n",
            "Epoch 248/1000\n",
            "46/46 - 3s - loss: 0.0638 - accuracy: 0.9646 - val_loss: 0.1978 - val_accuracy: 0.9214\n",
            "Epoch 249/1000\n",
            "46/46 - 3s - loss: 0.0569 - accuracy: 0.9661 - val_loss: 0.0775 - val_accuracy: 0.9589\n",
            "Epoch 250/1000\n",
            "46/46 - 3s - loss: 0.0528 - accuracy: 0.9704 - val_loss: 0.0935 - val_accuracy: 0.9526\n",
            "Epoch 251/1000\n",
            "46/46 - 3s - loss: 0.0671 - accuracy: 0.9634 - val_loss: 0.0775 - val_accuracy: 0.9586\n",
            "Epoch 252/1000\n",
            "46/46 - 3s - loss: 0.0599 - accuracy: 0.9644 - val_loss: 0.1032 - val_accuracy: 0.9413\n",
            "Epoch 253/1000\n",
            "46/46 - 3s - loss: 0.0594 - accuracy: 0.9647 - val_loss: 0.3401 - val_accuracy: 0.9131\n",
            "Epoch 254/1000\n",
            "46/46 - 3s - loss: 0.0526 - accuracy: 0.9694 - val_loss: 0.3163 - val_accuracy: 0.9233\n",
            "Epoch 255/1000\n",
            "46/46 - 3s - loss: 0.0519 - accuracy: 0.9703 - val_loss: 0.0903 - val_accuracy: 0.9561\n",
            "Epoch 256/1000\n",
            "46/46 - 3s - loss: 0.0602 - accuracy: 0.9650 - val_loss: 0.1904 - val_accuracy: 0.9317\n",
            "Epoch 257/1000\n",
            "46/46 - 3s - loss: 0.0518 - accuracy: 0.9683 - val_loss: 0.0810 - val_accuracy: 0.9598\n",
            "Epoch 258/1000\n",
            "46/46 - 3s - loss: 0.0518 - accuracy: 0.9696 - val_loss: 0.1070 - val_accuracy: 0.9489\n",
            "Epoch 259/1000\n",
            "46/46 - 3s - loss: 0.0560 - accuracy: 0.9688 - val_loss: 0.0703 - val_accuracy: 0.9637\n",
            "Epoch 260/1000\n",
            "46/46 - 3s - loss: 0.0551 - accuracy: 0.9684 - val_loss: 0.0969 - val_accuracy: 0.9542\n",
            "Epoch 261/1000\n",
            "46/46 - 3s - loss: 0.0488 - accuracy: 0.9694 - val_loss: 0.1128 - val_accuracy: 0.9441\n",
            "Epoch 262/1000\n",
            "46/46 - 3s - loss: 0.0575 - accuracy: 0.9644 - val_loss: 0.2055 - val_accuracy: 0.9204\n",
            "Epoch 263/1000\n",
            "46/46 - 3s - loss: 0.0515 - accuracy: 0.9670 - val_loss: 0.2003 - val_accuracy: 0.9313\n",
            "Epoch 264/1000\n",
            "46/46 - 3s - loss: 0.0512 - accuracy: 0.9686 - val_loss: 0.1015 - val_accuracy: 0.9483\n",
            "Epoch 265/1000\n",
            "46/46 - 3s - loss: 0.0590 - accuracy: 0.9690 - val_loss: 0.1545 - val_accuracy: 0.9444\n",
            "Epoch 266/1000\n",
            "46/46 - 3s - loss: 0.0581 - accuracy: 0.9676 - val_loss: 0.0879 - val_accuracy: 0.9563\n",
            "Epoch 267/1000\n",
            "46/46 - 3s - loss: 0.0521 - accuracy: 0.9684 - val_loss: 0.2791 - val_accuracy: 0.9300\n",
            "Epoch 268/1000\n",
            "46/46 - 3s - loss: 0.0497 - accuracy: 0.9702 - val_loss: 0.0790 - val_accuracy: 0.9609\n",
            "Epoch 269/1000\n",
            "46/46 - 3s - loss: 0.0524 - accuracy: 0.9688 - val_loss: 0.0738 - val_accuracy: 0.9644\n",
            "Epoch 270/1000\n",
            "46/46 - 3s - loss: 0.0528 - accuracy: 0.9674 - val_loss: 0.0746 - val_accuracy: 0.9631\n",
            "Epoch 271/1000\n",
            "46/46 - 3s - loss: 0.0537 - accuracy: 0.9672 - val_loss: 0.0762 - val_accuracy: 0.9601\n",
            "Epoch 272/1000\n",
            "46/46 - 3s - loss: 0.0529 - accuracy: 0.9703 - val_loss: 0.0695 - val_accuracy: 0.9634\n",
            "Epoch 273/1000\n",
            "46/46 - 3s - loss: 0.0491 - accuracy: 0.9699 - val_loss: 0.0749 - val_accuracy: 0.9650\n",
            "Epoch 274/1000\n",
            "46/46 - 3s - loss: 0.0570 - accuracy: 0.9657 - val_loss: 0.4515 - val_accuracy: 0.9053\n",
            "Epoch 275/1000\n",
            "46/46 - 3s - loss: 0.0547 - accuracy: 0.9681 - val_loss: 0.0804 - val_accuracy: 0.9537\n",
            "Epoch 276/1000\n",
            "46/46 - 3s - loss: 0.0543 - accuracy: 0.9686 - val_loss: 0.2072 - val_accuracy: 0.9417\n",
            "Epoch 277/1000\n",
            "46/46 - 3s - loss: 0.0589 - accuracy: 0.9654 - val_loss: 0.5369 - val_accuracy: 0.9001\n",
            "Epoch 278/1000\n",
            "46/46 - 3s - loss: 0.0685 - accuracy: 0.9637 - val_loss: 0.1440 - val_accuracy: 0.9355\n",
            "Epoch 279/1000\n",
            "46/46 - 3s - loss: 0.0521 - accuracy: 0.9696 - val_loss: 0.0872 - val_accuracy: 0.9553\n",
            "Epoch 280/1000\n",
            "46/46 - 3s - loss: 0.0504 - accuracy: 0.9695 - val_loss: 0.3391 - val_accuracy: 0.9204\n",
            "Epoch 281/1000\n",
            "46/46 - 3s - loss: 0.0525 - accuracy: 0.9682 - val_loss: 0.0727 - val_accuracy: 0.9618\n",
            "Epoch 282/1000\n",
            "46/46 - 3s - loss: 0.0509 - accuracy: 0.9688 - val_loss: 0.1013 - val_accuracy: 0.9524\n",
            "Epoch 283/1000\n",
            "46/46 - 3s - loss: 0.0494 - accuracy: 0.9693 - val_loss: 0.0725 - val_accuracy: 0.9605\n",
            "Epoch 284/1000\n",
            "46/46 - 3s - loss: 0.0548 - accuracy: 0.9671 - val_loss: 0.0909 - val_accuracy: 0.9619\n",
            "Epoch 285/1000\n",
            "46/46 - 3s - loss: 0.0534 - accuracy: 0.9681 - val_loss: 0.0805 - val_accuracy: 0.9518\n",
            "Epoch 286/1000\n",
            "46/46 - 3s - loss: 0.0656 - accuracy: 0.9632 - val_loss: 0.1129 - val_accuracy: 0.9473\n",
            "Epoch 287/1000\n",
            "46/46 - 3s - loss: 0.0558 - accuracy: 0.9650 - val_loss: 0.0723 - val_accuracy: 0.9628\n",
            "Epoch 288/1000\n",
            "46/46 - 3s - loss: 0.0506 - accuracy: 0.9692 - val_loss: 0.5516 - val_accuracy: 0.9104\n",
            "Epoch 289/1000\n",
            "46/46 - 3s - loss: 0.0521 - accuracy: 0.9672 - val_loss: 0.0787 - val_accuracy: 0.9592\n",
            "Epoch 290/1000\n",
            "46/46 - 3s - loss: 0.0533 - accuracy: 0.9687 - val_loss: 0.1271 - val_accuracy: 0.9480\n",
            "Epoch 291/1000\n",
            "46/46 - 3s - loss: 0.0593 - accuracy: 0.9649 - val_loss: 0.2652 - val_accuracy: 0.9139\n",
            "Epoch 292/1000\n",
            "46/46 - 3s - loss: 0.0666 - accuracy: 0.9639 - val_loss: 0.0986 - val_accuracy: 0.9468\n",
            "Epoch 293/1000\n",
            "46/46 - 3s - loss: 0.0550 - accuracy: 0.9676 - val_loss: 0.1851 - val_accuracy: 0.9439\n",
            "Epoch 294/1000\n",
            "46/46 - 3s - loss: 0.0531 - accuracy: 0.9682 - val_loss: 0.1838 - val_accuracy: 0.9211\n",
            "Epoch 295/1000\n",
            "46/46 - 3s - loss: 0.0491 - accuracy: 0.9709 - val_loss: 0.0824 - val_accuracy: 0.9544\n",
            "Epoch 296/1000\n",
            "46/46 - 3s - loss: 0.0542 - accuracy: 0.9691 - val_loss: 0.0881 - val_accuracy: 0.9550\n",
            "Epoch 297/1000\n",
            "46/46 - 3s - loss: 0.0504 - accuracy: 0.9661 - val_loss: 0.0707 - val_accuracy: 0.9618\n",
            "Epoch 298/1000\n",
            "46/46 - 3s - loss: 0.0509 - accuracy: 0.9704 - val_loss: 0.0647 - val_accuracy: 0.9598\n",
            "Epoch 299/1000\n",
            "46/46 - 3s - loss: 0.0539 - accuracy: 0.9680 - val_loss: 0.2746 - val_accuracy: 0.9025\n",
            "Epoch 300/1000\n",
            "46/46 - 3s - loss: 0.0527 - accuracy: 0.9690 - val_loss: 0.0758 - val_accuracy: 0.9583\n",
            "Epoch 301/1000\n",
            "46/46 - 3s - loss: 0.0476 - accuracy: 0.9709 - val_loss: 0.0826 - val_accuracy: 0.9582\n",
            "Epoch 302/1000\n",
            "46/46 - 3s - loss: 0.0508 - accuracy: 0.9697 - val_loss: 0.0735 - val_accuracy: 0.9601\n",
            "Epoch 303/1000\n",
            "46/46 - 3s - loss: 0.0512 - accuracy: 0.9690 - val_loss: 0.0765 - val_accuracy: 0.9612\n",
            "Epoch 304/1000\n",
            "46/46 - 3s - loss: 0.0492 - accuracy: 0.9708 - val_loss: 0.2695 - val_accuracy: 0.9182\n",
            "Epoch 305/1000\n",
            "46/46 - 3s - loss: 0.0523 - accuracy: 0.9690 - val_loss: 0.0804 - val_accuracy: 0.9624\n",
            "Epoch 306/1000\n",
            "46/46 - 3s - loss: 0.0531 - accuracy: 0.9674 - val_loss: 0.0892 - val_accuracy: 0.9554\n",
            "Epoch 307/1000\n",
            "46/46 - 3s - loss: 0.0520 - accuracy: 0.9693 - val_loss: 0.0958 - val_accuracy: 0.9525\n",
            "Epoch 308/1000\n",
            "46/46 - 3s - loss: 0.0537 - accuracy: 0.9673 - val_loss: 0.0715 - val_accuracy: 0.9601\n",
            "Epoch 309/1000\n",
            "46/46 - 3s - loss: 0.0501 - accuracy: 0.9697 - val_loss: 0.0739 - val_accuracy: 0.9593\n",
            "Epoch 310/1000\n",
            "46/46 - 3s - loss: 0.0530 - accuracy: 0.9688 - val_loss: 0.1108 - val_accuracy: 0.9481\n",
            "Epoch 311/1000\n",
            "46/46 - 3s - loss: 0.0474 - accuracy: 0.9694 - val_loss: 0.1849 - val_accuracy: 0.9271\n",
            "Epoch 312/1000\n",
            "46/46 - 3s - loss: 0.0533 - accuracy: 0.9685 - val_loss: 0.1153 - val_accuracy: 0.9467\n",
            "Epoch 313/1000\n",
            "46/46 - 3s - loss: 0.0494 - accuracy: 0.9697 - val_loss: 0.0804 - val_accuracy: 0.9606\n",
            "Epoch 314/1000\n",
            "46/46 - 3s - loss: 0.0571 - accuracy: 0.9688 - val_loss: 0.2455 - val_accuracy: 0.9223\n",
            "Epoch 315/1000\n",
            "46/46 - 3s - loss: 0.0564 - accuracy: 0.9663 - val_loss: 0.1357 - val_accuracy: 0.9364\n",
            "Epoch 316/1000\n",
            "46/46 - 3s - loss: 0.0577 - accuracy: 0.9668 - val_loss: 0.1831 - val_accuracy: 0.9367\n",
            "Epoch 317/1000\n",
            "46/46 - 3s - loss: 0.0566 - accuracy: 0.9698 - val_loss: 0.1310 - val_accuracy: 0.9510\n",
            "Epoch 318/1000\n",
            "46/46 - 3s - loss: 0.0712 - accuracy: 0.9625 - val_loss: 0.2449 - val_accuracy: 0.9245\n",
            "Epoch 319/1000\n",
            "46/46 - 3s - loss: 0.0533 - accuracy: 0.9676 - val_loss: 0.2338 - val_accuracy: 0.9271\n",
            "Epoch 320/1000\n",
            "46/46 - 3s - loss: 0.0550 - accuracy: 0.9686 - val_loss: 0.1005 - val_accuracy: 0.9525\n",
            "Epoch 321/1000\n",
            "46/46 - 3s - loss: 0.0548 - accuracy: 0.9674 - val_loss: 0.1121 - val_accuracy: 0.9518\n",
            "Epoch 322/1000\n",
            "46/46 - 3s - loss: 0.0488 - accuracy: 0.9708 - val_loss: 0.0661 - val_accuracy: 0.9619\n",
            "Epoch 323/1000\n",
            "46/46 - 3s - loss: 0.0483 - accuracy: 0.9694 - val_loss: 0.1088 - val_accuracy: 0.9515\n",
            "Epoch 324/1000\n",
            "46/46 - 3s - loss: 0.0520 - accuracy: 0.9685 - val_loss: 0.0984 - val_accuracy: 0.9547\n",
            "Epoch 325/1000\n",
            "46/46 - 3s - loss: 0.0498 - accuracy: 0.9679 - val_loss: 0.0698 - val_accuracy: 0.9599\n",
            "Epoch 326/1000\n",
            "46/46 - 3s - loss: 0.0546 - accuracy: 0.9687 - val_loss: 0.1849 - val_accuracy: 0.9243\n",
            "Epoch 327/1000\n",
            "46/46 - 3s - loss: 0.0535 - accuracy: 0.9698 - val_loss: 0.4793 - val_accuracy: 0.9189\n",
            "Epoch 328/1000\n",
            "46/46 - 3s - loss: 0.0480 - accuracy: 0.9697 - val_loss: 0.0723 - val_accuracy: 0.9612\n",
            "Epoch 329/1000\n",
            "46/46 - 3s - loss: 0.0497 - accuracy: 0.9684 - val_loss: 0.0922 - val_accuracy: 0.9585\n",
            "Epoch 330/1000\n",
            "46/46 - 3s - loss: 0.0502 - accuracy: 0.9703 - val_loss: 0.0834 - val_accuracy: 0.9576\n",
            "Epoch 331/1000\n",
            "46/46 - 3s - loss: 0.0494 - accuracy: 0.9699 - val_loss: 0.0701 - val_accuracy: 0.9656\n",
            "Epoch 332/1000\n",
            "46/46 - 3s - loss: 0.0496 - accuracy: 0.9696 - val_loss: 0.1449 - val_accuracy: 0.9339\n",
            "Epoch 333/1000\n",
            "46/46 - 3s - loss: 0.0501 - accuracy: 0.9708 - val_loss: 0.0800 - val_accuracy: 0.9619\n",
            "Epoch 334/1000\n",
            "46/46 - 3s - loss: 0.0474 - accuracy: 0.9714 - val_loss: 0.0772 - val_accuracy: 0.9630\n",
            "Epoch 335/1000\n",
            "46/46 - 3s - loss: 0.0509 - accuracy: 0.9702 - val_loss: 0.0871 - val_accuracy: 0.9585\n",
            "Epoch 336/1000\n",
            "46/46 - 3s - loss: 0.0495 - accuracy: 0.9691 - val_loss: 0.0992 - val_accuracy: 0.9567\n",
            "Epoch 337/1000\n",
            "46/46 - 3s - loss: 0.0499 - accuracy: 0.9706 - val_loss: 0.2479 - val_accuracy: 0.9141\n",
            "Epoch 338/1000\n",
            "46/46 - 3s - loss: 0.0636 - accuracy: 0.9674 - val_loss: 0.4323 - val_accuracy: 0.9140\n",
            "Epoch 339/1000\n",
            "46/46 - 3s - loss: 0.0530 - accuracy: 0.9681 - val_loss: 0.2130 - val_accuracy: 0.9288\n",
            "Epoch 340/1000\n",
            "46/46 - 3s - loss: 0.0587 - accuracy: 0.9661 - val_loss: 0.1245 - val_accuracy: 0.9471\n",
            "Epoch 341/1000\n",
            "46/46 - 3s - loss: 0.0541 - accuracy: 0.9699 - val_loss: 0.1149 - val_accuracy: 0.9423\n",
            "Epoch 342/1000\n",
            "46/46 - 3s - loss: 0.0484 - accuracy: 0.9690 - val_loss: 0.0742 - val_accuracy: 0.9611\n",
            "Epoch 343/1000\n",
            "46/46 - 3s - loss: 0.0498 - accuracy: 0.9672 - val_loss: 0.1998 - val_accuracy: 0.9259\n",
            "Epoch 344/1000\n",
            "46/46 - 3s - loss: 0.0500 - accuracy: 0.9680 - val_loss: 0.0776 - val_accuracy: 0.9589\n",
            "Epoch 345/1000\n",
            "46/46 - 3s - loss: 0.0470 - accuracy: 0.9711 - val_loss: 0.0868 - val_accuracy: 0.9614\n",
            "Epoch 346/1000\n",
            "46/46 - 3s - loss: 0.0450 - accuracy: 0.9704 - val_loss: 0.2169 - val_accuracy: 0.9239\n",
            "Epoch 347/1000\n",
            "46/46 - 3s - loss: 0.0497 - accuracy: 0.9699 - val_loss: 0.0815 - val_accuracy: 0.9605\n",
            "Epoch 348/1000\n",
            "46/46 - 3s - loss: 0.0477 - accuracy: 0.9691 - val_loss: 0.0888 - val_accuracy: 0.9601\n",
            "Epoch 349/1000\n",
            "46/46 - 3s - loss: 0.0477 - accuracy: 0.9702 - val_loss: 0.0766 - val_accuracy: 0.9615\n",
            "Epoch 350/1000\n",
            "46/46 - 3s - loss: 0.0452 - accuracy: 0.9705 - val_loss: 0.0754 - val_accuracy: 0.9621\n",
            "Epoch 351/1000\n",
            "46/46 - 3s - loss: 0.0456 - accuracy: 0.9698 - val_loss: 0.0801 - val_accuracy: 0.9628\n",
            "Epoch 352/1000\n",
            "46/46 - 3s - loss: 0.0522 - accuracy: 0.9674 - val_loss: 0.4352 - val_accuracy: 0.9169\n",
            "Epoch 353/1000\n",
            "46/46 - 3s - loss: 0.0482 - accuracy: 0.9722 - val_loss: 0.1724 - val_accuracy: 0.9426\n",
            "Epoch 354/1000\n",
            "46/46 - 3s - loss: 0.0561 - accuracy: 0.9667 - val_loss: 0.7945 - val_accuracy: 0.9143\n",
            "Epoch 355/1000\n",
            "46/46 - 3s - loss: 0.0612 - accuracy: 0.9654 - val_loss: 0.1740 - val_accuracy: 0.9425\n",
            "Epoch 356/1000\n",
            "46/46 - 3s - loss: 0.0623 - accuracy: 0.9656 - val_loss: 0.0742 - val_accuracy: 0.9596\n",
            "Epoch 357/1000\n",
            "46/46 - 3s - loss: 0.0489 - accuracy: 0.9690 - val_loss: 0.0891 - val_accuracy: 0.9560\n",
            "Epoch 358/1000\n",
            "46/46 - 3s - loss: 0.0466 - accuracy: 0.9702 - val_loss: 0.0733 - val_accuracy: 0.9599\n",
            "Epoch 359/1000\n",
            "46/46 - 3s - loss: 0.0494 - accuracy: 0.9696 - val_loss: 0.1096 - val_accuracy: 0.9534\n",
            "Epoch 360/1000\n",
            "46/46 - 3s - loss: 0.0516 - accuracy: 0.9700 - val_loss: 0.0856 - val_accuracy: 0.9576\n",
            "Epoch 361/1000\n",
            "46/46 - 3s - loss: 0.0526 - accuracy: 0.9680 - val_loss: 0.0791 - val_accuracy: 0.9619\n",
            "Epoch 362/1000\n",
            "46/46 - 3s - loss: 0.0491 - accuracy: 0.9682 - val_loss: 0.0791 - val_accuracy: 0.9592\n",
            "Epoch 363/1000\n",
            "46/46 - 3s - loss: 0.0492 - accuracy: 0.9699 - val_loss: 0.0777 - val_accuracy: 0.9638\n",
            "Epoch 364/1000\n",
            "46/46 - 3s - loss: 0.0476 - accuracy: 0.9709 - val_loss: 0.0727 - val_accuracy: 0.9646\n",
            "Epoch 365/1000\n",
            "46/46 - 3s - loss: 0.0475 - accuracy: 0.9705 - val_loss: 0.0782 - val_accuracy: 0.9617\n",
            "Epoch 366/1000\n",
            "46/46 - 3s - loss: 0.0462 - accuracy: 0.9707 - val_loss: 0.0795 - val_accuracy: 0.9612\n",
            "Epoch 367/1000\n",
            "46/46 - 3s - loss: 0.0642 - accuracy: 0.9663 - val_loss: 0.0865 - val_accuracy: 0.9557\n",
            "Epoch 368/1000\n",
            "46/46 - 3s - loss: 0.0471 - accuracy: 0.9706 - val_loss: 0.1841 - val_accuracy: 0.9458\n",
            "Epoch 369/1000\n",
            "46/46 - 3s - loss: 0.0467 - accuracy: 0.9684 - val_loss: 0.0932 - val_accuracy: 0.9567\n",
            "Epoch 370/1000\n",
            "46/46 - 3s - loss: 0.0499 - accuracy: 0.9711 - val_loss: 0.1156 - val_accuracy: 0.9487\n",
            "Epoch 371/1000\n",
            "46/46 - 3s - loss: 0.0564 - accuracy: 0.9650 - val_loss: 0.0787 - val_accuracy: 0.9606\n",
            "Epoch 372/1000\n",
            "46/46 - 3s - loss: 0.0505 - accuracy: 0.9679 - val_loss: 0.0758 - val_accuracy: 0.9608\n",
            "Epoch 373/1000\n",
            "46/46 - 3s - loss: 0.0486 - accuracy: 0.9693 - val_loss: 0.0854 - val_accuracy: 0.9603\n",
            "Epoch 374/1000\n",
            "46/46 - 3s - loss: 0.0462 - accuracy: 0.9707 - val_loss: 0.0854 - val_accuracy: 0.9622\n",
            "Epoch 375/1000\n",
            "46/46 - 3s - loss: 0.0541 - accuracy: 0.9678 - val_loss: 0.0942 - val_accuracy: 0.9535\n",
            "Epoch 376/1000\n",
            "46/46 - 3s - loss: 0.0494 - accuracy: 0.9700 - val_loss: 0.0785 - val_accuracy: 0.9618\n",
            "Epoch 377/1000\n",
            "46/46 - 3s - loss: 0.0455 - accuracy: 0.9719 - val_loss: 0.0730 - val_accuracy: 0.9643\n",
            "Epoch 378/1000\n",
            "46/46 - 3s - loss: 0.0515 - accuracy: 0.9674 - val_loss: 0.3244 - val_accuracy: 0.9233\n",
            "Epoch 379/1000\n",
            "46/46 - 3s - loss: 0.0479 - accuracy: 0.9706 - val_loss: 0.0863 - val_accuracy: 0.9619\n",
            "Epoch 380/1000\n",
            "46/46 - 3s - loss: 0.0466 - accuracy: 0.9706 - val_loss: 0.1157 - val_accuracy: 0.9383\n",
            "Epoch 381/1000\n",
            "46/46 - 3s - loss: 0.0558 - accuracy: 0.9680 - val_loss: 0.2316 - val_accuracy: 0.9374\n",
            "Epoch 382/1000\n",
            "46/46 - 3s - loss: 0.0511 - accuracy: 0.9695 - val_loss: 0.0908 - val_accuracy: 0.9541\n",
            "Epoch 383/1000\n",
            "46/46 - 3s - loss: 0.0464 - accuracy: 0.9712 - val_loss: 0.0777 - val_accuracy: 0.9602\n",
            "Epoch 384/1000\n",
            "46/46 - 3s - loss: 0.0508 - accuracy: 0.9693 - val_loss: 0.4971 - val_accuracy: 0.9152\n",
            "Epoch 385/1000\n",
            "46/46 - 3s - loss: 0.0479 - accuracy: 0.9693 - val_loss: 0.0875 - val_accuracy: 0.9577\n",
            "Epoch 386/1000\n",
            "46/46 - 3s - loss: 0.0444 - accuracy: 0.9690 - val_loss: 0.0784 - val_accuracy: 0.9615\n",
            "Epoch 387/1000\n",
            "46/46 - 3s - loss: 0.0459 - accuracy: 0.9711 - val_loss: 0.0862 - val_accuracy: 0.9647\n",
            "Epoch 388/1000\n",
            "46/46 - 3s - loss: 0.0474 - accuracy: 0.9708 - val_loss: 0.0761 - val_accuracy: 0.9617\n",
            "Epoch 389/1000\n",
            "46/46 - 3s - loss: 0.0431 - accuracy: 0.9714 - val_loss: 0.0962 - val_accuracy: 0.9551\n",
            "Epoch 390/1000\n",
            "46/46 - 3s - loss: 0.0472 - accuracy: 0.9703 - val_loss: 0.0834 - val_accuracy: 0.9651\n",
            "Epoch 391/1000\n",
            "46/46 - 3s - loss: 0.0472 - accuracy: 0.9696 - val_loss: 0.0846 - val_accuracy: 0.9605\n",
            "Epoch 392/1000\n",
            "46/46 - 3s - loss: 0.0446 - accuracy: 0.9694 - val_loss: 0.0887 - val_accuracy: 0.9596\n",
            "Epoch 393/1000\n",
            "46/46 - 3s - loss: 0.0454 - accuracy: 0.9706 - val_loss: 0.0794 - val_accuracy: 0.9627\n",
            "Epoch 394/1000\n",
            "46/46 - 3s - loss: 0.0472 - accuracy: 0.9691 - val_loss: 0.2019 - val_accuracy: 0.9384\n",
            "Epoch 395/1000\n",
            "46/46 - 3s - loss: 0.0482 - accuracy: 0.9698 - val_loss: 0.2083 - val_accuracy: 0.9272\n",
            "Epoch 396/1000\n",
            "46/46 - 3s - loss: 0.0526 - accuracy: 0.9687 - val_loss: 0.0827 - val_accuracy: 0.9627\n",
            "Epoch 397/1000\n",
            "46/46 - 3s - loss: 0.0531 - accuracy: 0.9690 - val_loss: 0.0844 - val_accuracy: 0.9574\n",
            "Epoch 398/1000\n",
            "46/46 - 3s - loss: 0.0513 - accuracy: 0.9693 - val_loss: 0.0740 - val_accuracy: 0.9628\n",
            "Epoch 399/1000\n",
            "46/46 - 3s - loss: 0.0471 - accuracy: 0.9712 - val_loss: 0.1228 - val_accuracy: 0.9503\n",
            "Epoch 400/1000\n",
            "46/46 - 3s - loss: 0.0451 - accuracy: 0.9717 - val_loss: 0.0962 - val_accuracy: 0.9537\n",
            "Epoch 401/1000\n",
            "46/46 - 3s - loss: 0.0437 - accuracy: 0.9732 - val_loss: 0.1429 - val_accuracy: 0.9431\n",
            "Epoch 402/1000\n",
            "46/46 - 3s - loss: 0.0473 - accuracy: 0.9707 - val_loss: 0.0824 - val_accuracy: 0.9612\n",
            "Epoch 403/1000\n",
            "46/46 - 3s - loss: 0.0470 - accuracy: 0.9708 - val_loss: 0.0753 - val_accuracy: 0.9605\n",
            "Epoch 404/1000\n",
            "46/46 - 3s - loss: 0.0450 - accuracy: 0.9714 - val_loss: 0.1500 - val_accuracy: 0.9415\n",
            "Epoch 405/1000\n",
            "46/46 - 3s - loss: 0.0440 - accuracy: 0.9710 - val_loss: 0.0830 - val_accuracy: 0.9606\n",
            "Epoch 406/1000\n",
            "46/46 - 3s - loss: 0.0468 - accuracy: 0.9721 - val_loss: 0.1246 - val_accuracy: 0.9387\n",
            "Epoch 407/1000\n",
            "46/46 - 3s - loss: 0.0481 - accuracy: 0.9704 - val_loss: 0.3191 - val_accuracy: 0.9195\n",
            "Epoch 408/1000\n",
            "46/46 - 3s - loss: 0.0442 - accuracy: 0.9723 - val_loss: 0.2277 - val_accuracy: 0.9221\n",
            "Epoch 409/1000\n",
            "46/46 - 3s - loss: 0.0469 - accuracy: 0.9719 - val_loss: 0.1919 - val_accuracy: 0.9319\n",
            "Epoch 410/1000\n",
            "46/46 - 3s - loss: 0.0466 - accuracy: 0.9728 - val_loss: 0.2145 - val_accuracy: 0.9423\n",
            "Epoch 411/1000\n",
            "46/46 - 3s - loss: 0.0526 - accuracy: 0.9691 - val_loss: 0.0900 - val_accuracy: 0.9621\n",
            "Epoch 412/1000\n",
            "46/46 - 3s - loss: 0.0449 - accuracy: 0.9723 - val_loss: 0.3483 - val_accuracy: 0.9217\n",
            "Epoch 413/1000\n",
            "46/46 - 3s - loss: 0.0613 - accuracy: 0.9682 - val_loss: 0.3308 - val_accuracy: 0.9104\n",
            "Epoch 414/1000\n",
            "46/46 - 3s - loss: 0.0602 - accuracy: 0.9674 - val_loss: 0.0815 - val_accuracy: 0.9622\n",
            "Epoch 415/1000\n",
            "46/46 - 3s - loss: 0.0503 - accuracy: 0.9672 - val_loss: 0.0730 - val_accuracy: 0.9601\n",
            "Epoch 416/1000\n",
            "46/46 - 3s - loss: 0.0476 - accuracy: 0.9714 - val_loss: 0.0846 - val_accuracy: 0.9567\n",
            "Epoch 417/1000\n",
            "46/46 - 3s - loss: 0.0497 - accuracy: 0.9707 - val_loss: 0.0808 - val_accuracy: 0.9612\n",
            "Epoch 418/1000\n",
            "46/46 - 3s - loss: 0.0545 - accuracy: 0.9703 - val_loss: 0.4345 - val_accuracy: 0.9189\n",
            "Epoch 419/1000\n",
            "46/46 - 3s - loss: 0.0473 - accuracy: 0.9723 - val_loss: 0.0789 - val_accuracy: 0.9593\n",
            "Epoch 420/1000\n",
            "46/46 - 3s - loss: 0.0468 - accuracy: 0.9711 - val_loss: 0.2215 - val_accuracy: 0.9294\n",
            "Epoch 421/1000\n",
            "46/46 - 3s - loss: 0.0456 - accuracy: 0.9709 - val_loss: 0.0830 - val_accuracy: 0.9622\n",
            "Epoch 422/1000\n",
            "46/46 - 3s - loss: 0.0443 - accuracy: 0.9723 - val_loss: 0.2138 - val_accuracy: 0.9333\n",
            "Epoch 423/1000\n",
            "46/46 - 3s - loss: 0.0452 - accuracy: 0.9716 - val_loss: 0.4613 - val_accuracy: 0.9187\n",
            "Epoch 424/1000\n",
            "46/46 - 3s - loss: 0.0510 - accuracy: 0.9688 - val_loss: 0.4193 - val_accuracy: 0.9157\n",
            "Epoch 425/1000\n",
            "46/46 - 3s - loss: 0.0506 - accuracy: 0.9728 - val_loss: 0.2253 - val_accuracy: 0.9316\n",
            "Epoch 426/1000\n",
            "46/46 - 3s - loss: 0.0458 - accuracy: 0.9718 - val_loss: 0.0782 - val_accuracy: 0.9617\n",
            "Epoch 427/1000\n",
            "46/46 - 3s - loss: 0.0443 - accuracy: 0.9716 - val_loss: 0.0754 - val_accuracy: 0.9617\n",
            "Epoch 428/1000\n",
            "46/46 - 3s - loss: 0.0483 - accuracy: 0.9688 - val_loss: 0.0756 - val_accuracy: 0.9615\n",
            "Epoch 429/1000\n",
            "46/46 - 3s - loss: 0.0481 - accuracy: 0.9718 - val_loss: 0.1253 - val_accuracy: 0.9458\n",
            "Epoch 430/1000\n",
            "46/46 - 3s - loss: 0.0478 - accuracy: 0.9708 - val_loss: 0.0930 - val_accuracy: 0.9605\n",
            "Epoch 431/1000\n",
            "46/46 - 3s - loss: 0.0540 - accuracy: 0.9679 - val_loss: 0.0859 - val_accuracy: 0.9599\n",
            "Epoch 432/1000\n",
            "46/46 - 3s - loss: 0.0506 - accuracy: 0.9694 - val_loss: 0.0760 - val_accuracy: 0.9614\n",
            "Epoch 433/1000\n",
            "46/46 - 3s - loss: 0.0446 - accuracy: 0.9737 - val_loss: 0.0813 - val_accuracy: 0.9602\n",
            "Epoch 434/1000\n",
            "46/46 - 3s - loss: 0.0448 - accuracy: 0.9691 - val_loss: 0.0806 - val_accuracy: 0.9605\n",
            "Epoch 435/1000\n",
            "46/46 - 3s - loss: 0.0500 - accuracy: 0.9705 - val_loss: 0.2414 - val_accuracy: 0.9339\n",
            "Epoch 436/1000\n",
            "46/46 - 3s - loss: 0.0499 - accuracy: 0.9687 - val_loss: 0.0871 - val_accuracy: 0.9592\n",
            "Epoch 437/1000\n",
            "46/46 - 3s - loss: 0.0452 - accuracy: 0.9704 - val_loss: 0.2048 - val_accuracy: 0.9419\n",
            "Epoch 438/1000\n",
            "46/46 - 3s - loss: 0.0425 - accuracy: 0.9718 - val_loss: 0.0896 - val_accuracy: 0.9593\n",
            "Epoch 439/1000\n",
            "46/46 - 3s - loss: 0.0447 - accuracy: 0.9708 - val_loss: 0.3252 - val_accuracy: 0.9249\n",
            "Epoch 440/1000\n",
            "46/46 - 3s - loss: 0.0417 - accuracy: 0.9736 - val_loss: 0.0889 - val_accuracy: 0.9614\n",
            "Epoch 441/1000\n",
            "46/46 - 3s - loss: 0.0423 - accuracy: 0.9739 - val_loss: 0.1567 - val_accuracy: 0.9368\n",
            "Epoch 442/1000\n",
            "46/46 - 3s - loss: 0.0437 - accuracy: 0.9734 - val_loss: 0.0907 - val_accuracy: 0.9605\n",
            "Epoch 443/1000\n",
            "46/46 - 3s - loss: 0.0460 - accuracy: 0.9723 - val_loss: 0.1179 - val_accuracy: 0.9394\n",
            "Epoch 444/1000\n",
            "46/46 - 3s - loss: 0.0437 - accuracy: 0.9714 - val_loss: 0.0880 - val_accuracy: 0.9586\n",
            "Epoch 445/1000\n",
            "46/46 - 3s - loss: 0.0429 - accuracy: 0.9730 - val_loss: 0.0828 - val_accuracy: 0.9612\n",
            "Epoch 446/1000\n",
            "46/46 - 3s - loss: 0.0414 - accuracy: 0.9731 - val_loss: 0.0831 - val_accuracy: 0.9609\n",
            "Epoch 447/1000\n",
            "46/46 - 3s - loss: 0.0427 - accuracy: 0.9732 - val_loss: 0.0846 - val_accuracy: 0.9619\n",
            "Epoch 448/1000\n",
            "46/46 - 3s - loss: 0.0471 - accuracy: 0.9706 - val_loss: 0.1060 - val_accuracy: 0.9505\n",
            "Epoch 449/1000\n",
            "46/46 - 3s - loss: 0.0570 - accuracy: 0.9699 - val_loss: 0.0816 - val_accuracy: 0.9621\n",
            "Epoch 450/1000\n",
            "46/46 - 3s - loss: 0.0450 - accuracy: 0.9714 - val_loss: 0.0806 - val_accuracy: 0.9634\n",
            "Epoch 451/1000\n",
            "46/46 - 3s - loss: 0.0433 - accuracy: 0.9731 - val_loss: 0.0809 - val_accuracy: 0.9603\n",
            "Epoch 452/1000\n",
            "46/46 - 3s - loss: 0.0410 - accuracy: 0.9754 - val_loss: 0.0861 - val_accuracy: 0.9612\n",
            "Epoch 453/1000\n",
            "46/46 - 3s - loss: 0.0518 - accuracy: 0.9710 - val_loss: 0.0972 - val_accuracy: 0.9555\n",
            "Epoch 454/1000\n",
            "46/46 - 3s - loss: 0.0471 - accuracy: 0.9714 - val_loss: 0.0870 - val_accuracy: 0.9630\n",
            "Epoch 455/1000\n",
            "46/46 - 3s - loss: 0.0426 - accuracy: 0.9718 - val_loss: 0.0827 - val_accuracy: 0.9621\n",
            "Epoch 456/1000\n",
            "46/46 - 3s - loss: 0.0433 - accuracy: 0.9720 - val_loss: 0.0869 - val_accuracy: 0.9596\n",
            "Epoch 457/1000\n",
            "46/46 - 3s - loss: 0.0428 - accuracy: 0.9743 - val_loss: 0.0840 - val_accuracy: 0.9617\n",
            "Epoch 458/1000\n",
            "46/46 - 3s - loss: 0.0416 - accuracy: 0.9714 - val_loss: 0.0876 - val_accuracy: 0.9619\n",
            "Epoch 459/1000\n",
            "46/46 - 3s - loss: 0.0403 - accuracy: 0.9741 - val_loss: 0.0899 - val_accuracy: 0.9624\n",
            "Epoch 460/1000\n",
            "46/46 - 3s - loss: 0.0453 - accuracy: 0.9730 - val_loss: 0.4232 - val_accuracy: 0.9140\n",
            "Epoch 461/1000\n",
            "46/46 - 3s - loss: 0.0455 - accuracy: 0.9722 - val_loss: 0.1577 - val_accuracy: 0.9319\n",
            "Epoch 462/1000\n",
            "46/46 - 3s - loss: 0.0445 - accuracy: 0.9710 - val_loss: 0.1041 - val_accuracy: 0.9512\n",
            "Epoch 463/1000\n",
            "46/46 - 3s - loss: 0.0464 - accuracy: 0.9708 - val_loss: 0.0793 - val_accuracy: 0.9628\n",
            "Epoch 464/1000\n",
            "46/46 - 3s - loss: 0.0463 - accuracy: 0.9719 - val_loss: 0.4560 - val_accuracy: 0.9266\n",
            "Epoch 465/1000\n",
            "46/46 - 3s - loss: 0.0427 - accuracy: 0.9733 - val_loss: 0.0879 - val_accuracy: 0.9598\n",
            "Epoch 466/1000\n",
            "46/46 - 3s - loss: 0.0430 - accuracy: 0.9725 - val_loss: 0.0845 - val_accuracy: 0.9599\n",
            "Epoch 467/1000\n",
            "46/46 - 3s - loss: 0.0434 - accuracy: 0.9723 - val_loss: 0.0881 - val_accuracy: 0.9555\n",
            "Epoch 468/1000\n",
            "46/46 - 3s - loss: 0.0417 - accuracy: 0.9729 - val_loss: 0.0821 - val_accuracy: 0.9641\n",
            "Epoch 469/1000\n",
            "46/46 - 3s - loss: 0.0410 - accuracy: 0.9730 - val_loss: 0.1368 - val_accuracy: 0.9470\n",
            "Epoch 470/1000\n",
            "46/46 - 3s - loss: 0.0397 - accuracy: 0.9755 - val_loss: 0.0958 - val_accuracy: 0.9592\n",
            "Epoch 471/1000\n",
            "46/46 - 3s - loss: 0.0432 - accuracy: 0.9736 - val_loss: 0.0957 - val_accuracy: 0.9595\n",
            "Epoch 472/1000\n",
            "46/46 - 3s - loss: 0.0456 - accuracy: 0.9718 - val_loss: 0.1027 - val_accuracy: 0.9603\n",
            "Epoch 473/1000\n",
            "46/46 - 3s - loss: 0.0477 - accuracy: 0.9710 - val_loss: 0.0872 - val_accuracy: 0.9627\n",
            "Epoch 474/1000\n",
            "46/46 - 3s - loss: 0.0469 - accuracy: 0.9723 - val_loss: 0.0864 - val_accuracy: 0.9598\n",
            "Epoch 475/1000\n",
            "46/46 - 3s - loss: 0.0521 - accuracy: 0.9698 - val_loss: 0.3204 - val_accuracy: 0.9256\n",
            "Epoch 476/1000\n",
            "46/46 - 3s - loss: 0.0427 - accuracy: 0.9708 - val_loss: 0.0861 - val_accuracy: 0.9598\n",
            "Epoch 477/1000\n",
            "46/46 - 3s - loss: 0.0478 - accuracy: 0.9708 - val_loss: 0.2444 - val_accuracy: 0.9197\n",
            "Epoch 478/1000\n",
            "46/46 - 3s - loss: 0.0493 - accuracy: 0.9699 - val_loss: 0.3800 - val_accuracy: 0.9204\n",
            "Epoch 479/1000\n",
            "46/46 - 3s - loss: 0.0449 - accuracy: 0.9719 - val_loss: 0.1144 - val_accuracy: 0.9457\n",
            "Epoch 480/1000\n",
            "46/46 - 3s - loss: 0.0422 - accuracy: 0.9723 - val_loss: 0.0922 - val_accuracy: 0.9599\n",
            "Epoch 481/1000\n",
            "46/46 - 3s - loss: 0.0458 - accuracy: 0.9720 - val_loss: 0.0971 - val_accuracy: 0.9589\n",
            "Epoch 482/1000\n",
            "46/46 - 3s - loss: 0.0537 - accuracy: 0.9676 - val_loss: 0.7511 - val_accuracy: 0.9134\n",
            "Epoch 483/1000\n",
            "46/46 - 3s - loss: 0.0438 - accuracy: 0.9721 - val_loss: 0.1803 - val_accuracy: 0.9224\n",
            "Epoch 484/1000\n",
            "46/46 - 3s - loss: 0.0403 - accuracy: 0.9751 - val_loss: 0.0877 - val_accuracy: 0.9599\n",
            "Epoch 485/1000\n",
            "46/46 - 3s - loss: 0.0409 - accuracy: 0.9721 - val_loss: 0.0880 - val_accuracy: 0.9650\n",
            "Epoch 486/1000\n",
            "46/46 - 3s - loss: 0.0426 - accuracy: 0.9744 - val_loss: 0.0853 - val_accuracy: 0.9592\n",
            "Epoch 487/1000\n",
            "46/46 - 3s - loss: 0.0410 - accuracy: 0.9748 - val_loss: 0.0883 - val_accuracy: 0.9634\n",
            "Epoch 488/1000\n",
            "46/46 - 3s - loss: 0.0459 - accuracy: 0.9707 - val_loss: 0.0933 - val_accuracy: 0.9622\n",
            "Epoch 489/1000\n",
            "46/46 - 3s - loss: 0.0450 - accuracy: 0.9728 - val_loss: 0.0879 - val_accuracy: 0.9628\n",
            "Epoch 490/1000\n",
            "46/46 - 3s - loss: 0.0427 - accuracy: 0.9731 - val_loss: 0.0874 - val_accuracy: 0.9598\n",
            "Epoch 491/1000\n",
            "46/46 - 3s - loss: 0.0458 - accuracy: 0.9710 - val_loss: 0.1706 - val_accuracy: 0.9429\n",
            "Epoch 492/1000\n",
            "46/46 - 3s - loss: 0.0504 - accuracy: 0.9674 - val_loss: 0.7710 - val_accuracy: 0.9033\n",
            "Epoch 493/1000\n",
            "46/46 - 3s - loss: 0.0448 - accuracy: 0.9725 - val_loss: 0.0945 - val_accuracy: 0.9630\n",
            "Epoch 494/1000\n",
            "46/46 - 3s - loss: 0.0418 - accuracy: 0.9725 - val_loss: 0.0915 - val_accuracy: 0.9627\n",
            "Epoch 495/1000\n",
            "46/46 - 3s - loss: 0.0437 - accuracy: 0.9723 - val_loss: 0.1209 - val_accuracy: 0.9529\n",
            "Epoch 496/1000\n",
            "46/46 - 3s - loss: 0.0420 - accuracy: 0.9724 - val_loss: 0.0865 - val_accuracy: 0.9595\n",
            "Epoch 497/1000\n",
            "46/46 - 3s - loss: 0.0433 - accuracy: 0.9723 - val_loss: 0.0884 - val_accuracy: 0.9628\n",
            "Epoch 498/1000\n",
            "46/46 - 3s - loss: 0.0421 - accuracy: 0.9711 - val_loss: 0.0795 - val_accuracy: 0.9622\n",
            "Epoch 499/1000\n",
            "46/46 - 3s - loss: 0.0412 - accuracy: 0.9737 - val_loss: 0.0893 - val_accuracy: 0.9602\n",
            "Epoch 500/1000\n",
            "46/46 - 3s - loss: 0.0491 - accuracy: 0.9700 - val_loss: 0.0813 - val_accuracy: 0.9611\n",
            "Epoch 501/1000\n",
            "46/46 - 3s - loss: 0.0491 - accuracy: 0.9719 - val_loss: 0.0913 - val_accuracy: 0.9651\n",
            "Epoch 502/1000\n",
            "46/46 - 3s - loss: 0.0481 - accuracy: 0.9718 - val_loss: 0.0844 - val_accuracy: 0.9614\n",
            "Epoch 503/1000\n",
            "46/46 - 3s - loss: 0.0448 - accuracy: 0.9718 - val_loss: 0.2106 - val_accuracy: 0.9333\n",
            "Epoch 504/1000\n",
            "46/46 - 3s - loss: 0.0435 - accuracy: 0.9732 - val_loss: 0.0942 - val_accuracy: 0.9622\n",
            "Epoch 505/1000\n",
            "46/46 - 3s - loss: 0.0395 - accuracy: 0.9751 - val_loss: 0.1019 - val_accuracy: 0.9589\n",
            "Epoch 506/1000\n",
            "46/46 - 3s - loss: 0.0407 - accuracy: 0.9746 - val_loss: 0.0794 - val_accuracy: 0.9647\n",
            "Epoch 507/1000\n",
            "46/46 - 3s - loss: 0.0402 - accuracy: 0.9739 - val_loss: 0.1683 - val_accuracy: 0.9454\n",
            "Epoch 508/1000\n",
            "46/46 - 3s - loss: 0.0420 - accuracy: 0.9737 - val_loss: 0.3467 - val_accuracy: 0.9333\n",
            "Epoch 509/1000\n",
            "46/46 - 3s - loss: 0.0415 - accuracy: 0.9729 - val_loss: 0.0842 - val_accuracy: 0.9643\n",
            "Epoch 510/1000\n",
            "46/46 - 3s - loss: 0.0479 - accuracy: 0.9720 - val_loss: 0.1183 - val_accuracy: 0.9534\n",
            "Epoch 511/1000\n",
            "46/46 - 3s - loss: 0.0563 - accuracy: 0.9675 - val_loss: 0.0951 - val_accuracy: 0.9596\n",
            "Epoch 512/1000\n",
            "46/46 - 3s - loss: 0.0494 - accuracy: 0.9687 - val_loss: 0.7632 - val_accuracy: 0.9110\n",
            "Epoch 513/1000\n",
            "46/46 - 3s - loss: 0.0443 - accuracy: 0.9724 - val_loss: 0.1190 - val_accuracy: 0.9503\n",
            "Epoch 514/1000\n",
            "46/46 - 3s - loss: 0.0473 - accuracy: 0.9717 - val_loss: 0.0934 - val_accuracy: 0.9602\n",
            "Epoch 515/1000\n",
            "46/46 - 3s - loss: 0.0429 - accuracy: 0.9736 - val_loss: 0.0843 - val_accuracy: 0.9635\n",
            "Epoch 516/1000\n",
            "46/46 - 3s - loss: 0.0409 - accuracy: 0.9748 - val_loss: 0.0918 - val_accuracy: 0.9647\n",
            "Epoch 517/1000\n",
            "46/46 - 3s - loss: 0.0397 - accuracy: 0.9749 - val_loss: 0.0877 - val_accuracy: 0.9625\n",
            "Epoch 518/1000\n",
            "46/46 - 3s - loss: 0.0405 - accuracy: 0.9749 - val_loss: 0.0899 - val_accuracy: 0.9611\n",
            "Epoch 519/1000\n",
            "46/46 - 3s - loss: 0.0412 - accuracy: 0.9736 - val_loss: 0.6599 - val_accuracy: 0.9157\n",
            "Epoch 520/1000\n",
            "46/46 - 3s - loss: 0.0487 - accuracy: 0.9734 - val_loss: 0.0901 - val_accuracy: 0.9643\n",
            "Epoch 521/1000\n",
            "46/46 - 3s - loss: 0.0435 - accuracy: 0.9734 - val_loss: 0.1055 - val_accuracy: 0.9542\n",
            "Epoch 522/1000\n",
            "46/46 - 3s - loss: 0.0509 - accuracy: 0.9685 - val_loss: 0.1326 - val_accuracy: 0.9444\n",
            "Epoch 523/1000\n",
            "46/46 - 3s - loss: 0.0427 - accuracy: 0.9732 - val_loss: 0.1120 - val_accuracy: 0.9519\n",
            "Epoch 524/1000\n",
            "46/46 - 3s - loss: 0.0438 - accuracy: 0.9717 - val_loss: 0.1428 - val_accuracy: 0.9409\n",
            "Epoch 525/1000\n",
            "46/46 - 3s - loss: 0.0477 - accuracy: 0.9703 - val_loss: 0.1802 - val_accuracy: 0.9499\n",
            "Epoch 526/1000\n",
            "46/46 - 3s - loss: 0.0708 - accuracy: 0.9670 - val_loss: 0.4542 - val_accuracy: 0.9242\n",
            "Epoch 527/1000\n",
            "46/46 - 3s - loss: 0.0496 - accuracy: 0.9708 - val_loss: 0.1081 - val_accuracy: 0.9508\n",
            "Epoch 528/1000\n",
            "46/46 - 3s - loss: 0.0421 - accuracy: 0.9753 - val_loss: 0.0809 - val_accuracy: 0.9643\n",
            "Epoch 529/1000\n",
            "46/46 - 3s - loss: 0.0433 - accuracy: 0.9732 - val_loss: 0.0909 - val_accuracy: 0.9601\n",
            "Epoch 530/1000\n",
            "46/46 - 3s - loss: 0.0418 - accuracy: 0.9720 - val_loss: 0.0889 - val_accuracy: 0.9592\n",
            "Epoch 531/1000\n",
            "46/46 - 3s - loss: 0.0407 - accuracy: 0.9735 - val_loss: 0.1833 - val_accuracy: 0.9336\n",
            "Epoch 532/1000\n",
            "46/46 - 3s - loss: 0.0402 - accuracy: 0.9745 - val_loss: 0.1053 - val_accuracy: 0.9560\n",
            "Epoch 533/1000\n",
            "46/46 - 3s - loss: 0.0415 - accuracy: 0.9719 - val_loss: 0.0940 - val_accuracy: 0.9641\n",
            "Epoch 534/1000\n",
            "46/46 - 3s - loss: 0.0401 - accuracy: 0.9755 - val_loss: 0.1005 - val_accuracy: 0.9563\n",
            "Epoch 535/1000\n",
            "46/46 - 3s - loss: 0.0429 - accuracy: 0.9718 - val_loss: 0.0929 - val_accuracy: 0.9603\n",
            "Epoch 536/1000\n",
            "46/46 - 3s - loss: 0.0416 - accuracy: 0.9729 - val_loss: 0.0957 - val_accuracy: 0.9617\n",
            "Epoch 537/1000\n",
            "46/46 - 3s - loss: 0.0427 - accuracy: 0.9724 - val_loss: 0.0854 - val_accuracy: 0.9621\n",
            "Epoch 538/1000\n",
            "46/46 - 3s - loss: 0.0402 - accuracy: 0.9720 - val_loss: 0.0925 - val_accuracy: 0.9579\n",
            "Epoch 539/1000\n",
            "46/46 - 3s - loss: 0.0385 - accuracy: 0.9740 - val_loss: 0.1857 - val_accuracy: 0.9381\n",
            "Epoch 540/1000\n",
            "46/46 - 3s - loss: 0.0420 - accuracy: 0.9723 - val_loss: 0.0888 - val_accuracy: 0.9603\n",
            "Epoch 541/1000\n",
            "46/46 - 3s - loss: 0.0424 - accuracy: 0.9737 - val_loss: 1.5466 - val_accuracy: 0.9024\n",
            "Epoch 542/1000\n",
            "46/46 - 3s - loss: 0.0535 - accuracy: 0.9693 - val_loss: 0.7414 - val_accuracy: 0.9218\n",
            "Epoch 543/1000\n",
            "46/46 - 3s - loss: 0.0546 - accuracy: 0.9681 - val_loss: 0.6181 - val_accuracy: 0.9143\n",
            "Epoch 544/1000\n",
            "46/46 - 3s - loss: 0.0493 - accuracy: 0.9683 - val_loss: 0.2694 - val_accuracy: 0.9188\n",
            "Epoch 545/1000\n",
            "46/46 - 3s - loss: 0.0424 - accuracy: 0.9737 - val_loss: 0.0982 - val_accuracy: 0.9583\n",
            "Epoch 546/1000\n",
            "46/46 - 3s - loss: 0.0440 - accuracy: 0.9718 - val_loss: 0.0948 - val_accuracy: 0.9580\n",
            "Epoch 547/1000\n",
            "46/46 - 3s - loss: 0.0425 - accuracy: 0.9719 - val_loss: 0.0874 - val_accuracy: 0.9608\n",
            "Epoch 548/1000\n",
            "46/46 - 3s - loss: 0.0409 - accuracy: 0.9729 - val_loss: 0.2147 - val_accuracy: 0.9239\n",
            "Epoch 549/1000\n",
            "46/46 - 3s - loss: 0.0404 - accuracy: 0.9724 - val_loss: 0.0894 - val_accuracy: 0.9637\n",
            "Epoch 550/1000\n",
            "46/46 - 3s - loss: 0.0393 - accuracy: 0.9757 - val_loss: 0.0869 - val_accuracy: 0.9608\n",
            "Epoch 551/1000\n",
            "46/46 - 3s - loss: 0.0402 - accuracy: 0.9752 - val_loss: 0.0884 - val_accuracy: 0.9630\n",
            "Epoch 552/1000\n",
            "46/46 - 3s - loss: 0.0428 - accuracy: 0.9752 - val_loss: 0.0905 - val_accuracy: 0.9614\n",
            "Epoch 553/1000\n",
            "46/46 - 3s - loss: 0.0412 - accuracy: 0.9743 - val_loss: 0.0910 - val_accuracy: 0.9614\n",
            "Epoch 554/1000\n",
            "46/46 - 3s - loss: 0.0528 - accuracy: 0.9724 - val_loss: 0.2792 - val_accuracy: 0.9034\n",
            "Epoch 555/1000\n",
            "46/46 - 3s - loss: 0.0495 - accuracy: 0.9706 - val_loss: 0.0891 - val_accuracy: 0.9598\n",
            "Epoch 556/1000\n",
            "46/46 - 3s - loss: 0.0475 - accuracy: 0.9703 - val_loss: 0.0945 - val_accuracy: 0.9531\n",
            "Epoch 557/1000\n",
            "46/46 - 3s - loss: 0.0435 - accuracy: 0.9729 - val_loss: 0.0792 - val_accuracy: 0.9612\n",
            "Epoch 558/1000\n",
            "46/46 - 3s - loss: 0.0399 - accuracy: 0.9728 - val_loss: 0.1683 - val_accuracy: 0.9435\n",
            "Epoch 559/1000\n",
            "46/46 - 3s - loss: 0.0450 - accuracy: 0.9715 - val_loss: 0.0823 - val_accuracy: 0.9630\n",
            "Epoch 560/1000\n",
            "46/46 - 3s - loss: 0.0403 - accuracy: 0.9747 - val_loss: 0.0863 - val_accuracy: 0.9631\n",
            "Epoch 561/1000\n",
            "46/46 - 3s - loss: 0.0414 - accuracy: 0.9731 - val_loss: 0.0881 - val_accuracy: 0.9646\n",
            "Epoch 562/1000\n",
            "46/46 - 3s - loss: 0.0387 - accuracy: 0.9760 - val_loss: 0.0888 - val_accuracy: 0.9602\n",
            "Epoch 563/1000\n",
            "46/46 - 3s - loss: 0.0382 - accuracy: 0.9745 - val_loss: 0.0857 - val_accuracy: 0.9632\n",
            "Epoch 564/1000\n",
            "46/46 - 3s - loss: 0.0372 - accuracy: 0.9752 - val_loss: 0.0934 - val_accuracy: 0.9618\n",
            "Epoch 565/1000\n",
            "46/46 - 3s - loss: 0.0369 - accuracy: 0.9759 - val_loss: 0.0966 - val_accuracy: 0.9608\n",
            "Epoch 566/1000\n",
            "46/46 - 3s - loss: 0.0402 - accuracy: 0.9745 - val_loss: 0.0839 - val_accuracy: 0.9609\n",
            "Epoch 567/1000\n",
            "46/46 - 3s - loss: 0.0395 - accuracy: 0.9759 - val_loss: 0.1060 - val_accuracy: 0.9583\n",
            "Epoch 568/1000\n",
            "46/46 - 3s - loss: 0.0460 - accuracy: 0.9699 - val_loss: 0.0908 - val_accuracy: 0.9643\n",
            "Epoch 569/1000\n",
            "46/46 - 3s - loss: 0.0429 - accuracy: 0.9735 - val_loss: 0.1014 - val_accuracy: 0.9589\n",
            "Epoch 570/1000\n",
            "46/46 - 3s - loss: 0.0413 - accuracy: 0.9746 - val_loss: 0.0902 - val_accuracy: 0.9605\n",
            "Epoch 571/1000\n",
            "46/46 - 3s - loss: 0.0408 - accuracy: 0.9732 - val_loss: 0.1267 - val_accuracy: 0.9521\n",
            "Epoch 572/1000\n",
            "46/46 - 3s - loss: 0.0477 - accuracy: 0.9729 - val_loss: 0.1255 - val_accuracy: 0.9508\n",
            "Epoch 573/1000\n",
            "46/46 - 3s - loss: 0.0460 - accuracy: 0.9729 - val_loss: 0.5207 - val_accuracy: 0.9213\n",
            "Epoch 574/1000\n",
            "46/46 - 3s - loss: 0.0414 - accuracy: 0.9747 - val_loss: 0.0973 - val_accuracy: 0.9617\n",
            "Epoch 575/1000\n",
            "46/46 - 3s - loss: 0.0436 - accuracy: 0.9724 - val_loss: 0.6133 - val_accuracy: 0.9144\n",
            "Epoch 576/1000\n",
            "46/46 - 3s - loss: 0.0422 - accuracy: 0.9731 - val_loss: 0.1181 - val_accuracy: 0.9497\n",
            "Epoch 577/1000\n",
            "46/46 - 3s - loss: 0.0463 - accuracy: 0.9712 - val_loss: 0.4073 - val_accuracy: 0.9181\n",
            "Epoch 578/1000\n",
            "46/46 - 3s - loss: 0.0438 - accuracy: 0.9729 - val_loss: 0.0987 - val_accuracy: 0.9611\n",
            "Epoch 579/1000\n",
            "46/46 - 3s - loss: 0.0410 - accuracy: 0.9743 - val_loss: 0.1380 - val_accuracy: 0.9403\n",
            "Epoch 580/1000\n",
            "46/46 - 3s - loss: 0.0398 - accuracy: 0.9744 - val_loss: 0.4170 - val_accuracy: 0.9290\n",
            "Epoch 581/1000\n",
            "46/46 - 3s - loss: 0.0401 - accuracy: 0.9749 - val_loss: 0.1782 - val_accuracy: 0.9372\n",
            "Epoch 582/1000\n",
            "46/46 - 3s - loss: 0.0391 - accuracy: 0.9764 - val_loss: 0.0965 - val_accuracy: 0.9605\n",
            "Epoch 583/1000\n",
            "46/46 - 3s - loss: 0.0427 - accuracy: 0.9712 - val_loss: 0.0931 - val_accuracy: 0.9632\n",
            "Epoch 584/1000\n",
            "46/46 - 3s - loss: 0.0439 - accuracy: 0.9731 - val_loss: 0.0860 - val_accuracy: 0.9574\n",
            "Epoch 585/1000\n",
            "46/46 - 3s - loss: 0.0540 - accuracy: 0.9708 - val_loss: 0.4129 - val_accuracy: 0.9252\n",
            "Epoch 586/1000\n",
            "46/46 - 3s - loss: 0.0468 - accuracy: 0.9718 - val_loss: 0.0911 - val_accuracy: 0.9598\n",
            "Epoch 587/1000\n",
            "46/46 - 3s - loss: 0.0413 - accuracy: 0.9730 - val_loss: 0.0858 - val_accuracy: 0.9611\n",
            "Epoch 588/1000\n",
            "46/46 - 3s - loss: 0.0427 - accuracy: 0.9732 - val_loss: 0.0967 - val_accuracy: 0.9582\n",
            "Epoch 589/1000\n",
            "46/46 - 3s - loss: 0.0438 - accuracy: 0.9731 - val_loss: 0.3865 - val_accuracy: 0.9220\n",
            "Epoch 590/1000\n",
            "46/46 - 3s - loss: 0.0388 - accuracy: 0.9749 - val_loss: 0.2122 - val_accuracy: 0.9438\n",
            "Epoch 591/1000\n",
            "46/46 - 3s - loss: 0.0400 - accuracy: 0.9748 - val_loss: 0.1520 - val_accuracy: 0.9356\n",
            "Epoch 592/1000\n",
            "46/46 - 3s - loss: 0.0414 - accuracy: 0.9757 - val_loss: 0.1180 - val_accuracy: 0.9503\n",
            "Epoch 593/1000\n",
            "46/46 - 3s - loss: 0.0393 - accuracy: 0.9737 - val_loss: 0.0999 - val_accuracy: 0.9609\n",
            "Epoch 594/1000\n",
            "46/46 - 3s - loss: 0.0391 - accuracy: 0.9739 - val_loss: 0.0997 - val_accuracy: 0.9599\n",
            "Epoch 595/1000\n",
            "46/46 - 3s - loss: 0.0385 - accuracy: 0.9755 - val_loss: 0.2977 - val_accuracy: 0.9217\n",
            "Epoch 596/1000\n",
            "46/46 - 3s - loss: 0.0412 - accuracy: 0.9755 - val_loss: 0.1007 - val_accuracy: 0.9621\n",
            "Epoch 597/1000\n",
            "46/46 - 3s - loss: 0.0412 - accuracy: 0.9723 - val_loss: 0.1035 - val_accuracy: 0.9577\n",
            "Epoch 598/1000\n",
            "46/46 - 3s - loss: 0.0382 - accuracy: 0.9759 - val_loss: 0.1087 - val_accuracy: 0.9611\n",
            "Epoch 599/1000\n",
            "46/46 - 3s - loss: 0.0389 - accuracy: 0.9751 - val_loss: 0.1090 - val_accuracy: 0.9612\n",
            "Epoch 600/1000\n",
            "46/46 - 3s - loss: 0.0456 - accuracy: 0.9734 - val_loss: 0.5452 - val_accuracy: 0.9200\n",
            "Epoch 601/1000\n",
            "46/46 - 3s - loss: 0.0449 - accuracy: 0.9727 - val_loss: 0.2938 - val_accuracy: 0.9355\n",
            "Epoch 602/1000\n",
            "46/46 - 3s - loss: 0.0559 - accuracy: 0.9707 - val_loss: 0.5087 - val_accuracy: 0.9095\n",
            "Epoch 603/1000\n",
            "46/46 - 3s - loss: 0.0439 - accuracy: 0.9735 - val_loss: 0.1598 - val_accuracy: 0.9358\n",
            "Epoch 604/1000\n",
            "46/46 - 3s - loss: 0.0422 - accuracy: 0.9728 - val_loss: 0.1467 - val_accuracy: 0.9454\n",
            "Epoch 605/1000\n",
            "46/46 - 3s - loss: 0.0445 - accuracy: 0.9732 - val_loss: 0.0914 - val_accuracy: 0.9609\n",
            "Epoch 606/1000\n",
            "46/46 - 3s - loss: 0.0442 - accuracy: 0.9733 - val_loss: 0.4892 - val_accuracy: 0.9153\n",
            "Epoch 607/1000\n",
            "46/46 - 3s - loss: 0.0387 - accuracy: 0.9740 - val_loss: 0.3477 - val_accuracy: 0.9252\n",
            "Epoch 608/1000\n",
            "46/46 - 3s - loss: 0.0422 - accuracy: 0.9729 - val_loss: 0.1070 - val_accuracy: 0.9564\n",
            "Epoch 609/1000\n",
            "46/46 - 3s - loss: 0.0392 - accuracy: 0.9746 - val_loss: 0.3018 - val_accuracy: 0.9208\n",
            "Epoch 610/1000\n",
            "46/46 - 3s - loss: 0.0401 - accuracy: 0.9734 - val_loss: 0.3273 - val_accuracy: 0.9184\n",
            "Epoch 611/1000\n",
            "46/46 - 3s - loss: 0.0411 - accuracy: 0.9742 - val_loss: 0.3168 - val_accuracy: 0.9295\n",
            "Epoch 612/1000\n",
            "46/46 - 3s - loss: 0.0382 - accuracy: 0.9754 - val_loss: 0.0952 - val_accuracy: 0.9619\n",
            "Epoch 613/1000\n",
            "46/46 - 3s - loss: 0.0371 - accuracy: 0.9764 - val_loss: 0.1058 - val_accuracy: 0.9618\n",
            "Epoch 614/1000\n",
            "46/46 - 3s - loss: 0.0383 - accuracy: 0.9764 - val_loss: 0.1050 - val_accuracy: 0.9637\n",
            "Epoch 615/1000\n",
            "46/46 - 3s - loss: 0.0368 - accuracy: 0.9769 - val_loss: 0.1045 - val_accuracy: 0.9638\n",
            "Epoch 616/1000\n",
            "46/46 - 3s - loss: 0.0446 - accuracy: 0.9729 - val_loss: 0.0950 - val_accuracy: 0.9612\n",
            "Epoch 617/1000\n",
            "46/46 - 3s - loss: 0.0495 - accuracy: 0.9723 - val_loss: 0.4977 - val_accuracy: 0.8947\n",
            "Epoch 618/1000\n",
            "46/46 - 3s - loss: 0.0528 - accuracy: 0.9705 - val_loss: 0.0965 - val_accuracy: 0.9586\n",
            "Epoch 619/1000\n",
            "46/46 - 3s - loss: 0.0462 - accuracy: 0.9733 - val_loss: 0.0850 - val_accuracy: 0.9631\n",
            "Epoch 620/1000\n",
            "46/46 - 3s - loss: 0.0413 - accuracy: 0.9741 - val_loss: 0.0857 - val_accuracy: 0.9615\n",
            "Epoch 621/1000\n",
            "46/46 - 3s - loss: 0.0382 - accuracy: 0.9755 - val_loss: 0.0913 - val_accuracy: 0.9586\n",
            "Epoch 622/1000\n",
            "46/46 - 3s - loss: 0.0390 - accuracy: 0.9767 - val_loss: 0.0872 - val_accuracy: 0.9605\n",
            "Epoch 623/1000\n",
            "46/46 - 3s - loss: 0.0389 - accuracy: 0.9746 - val_loss: 0.2190 - val_accuracy: 0.9423\n",
            "Epoch 624/1000\n",
            "46/46 - 3s - loss: 0.0402 - accuracy: 0.9728 - val_loss: 0.3708 - val_accuracy: 0.9179\n",
            "Epoch 625/1000\n",
            "46/46 - 3s - loss: 0.0413 - accuracy: 0.9736 - val_loss: 0.2687 - val_accuracy: 0.9301\n",
            "Epoch 626/1000\n",
            "46/46 - 3s - loss: 0.0408 - accuracy: 0.9735 - val_loss: 0.4630 - val_accuracy: 0.9195\n",
            "Epoch 627/1000\n",
            "46/46 - 3s - loss: 0.0397 - accuracy: 0.9731 - val_loss: 0.1426 - val_accuracy: 0.9468\n",
            "Epoch 628/1000\n",
            "46/46 - 3s - loss: 0.0387 - accuracy: 0.9760 - val_loss: 0.0915 - val_accuracy: 0.9621\n",
            "Epoch 629/1000\n",
            "46/46 - 3s - loss: 0.0392 - accuracy: 0.9749 - val_loss: 0.6618 - val_accuracy: 0.9173\n",
            "Epoch 630/1000\n",
            "46/46 - 3s - loss: 0.0411 - accuracy: 0.9723 - val_loss: 0.1122 - val_accuracy: 0.9577\n",
            "Epoch 631/1000\n",
            "46/46 - 3s - loss: 0.0462 - accuracy: 0.9735 - val_loss: 0.1011 - val_accuracy: 0.9617\n",
            "Epoch 632/1000\n",
            "46/46 - 3s - loss: 0.0482 - accuracy: 0.9712 - val_loss: 0.0890 - val_accuracy: 0.9632\n",
            "Epoch 633/1000\n",
            "46/46 - 3s - loss: 0.0446 - accuracy: 0.9733 - val_loss: 0.0947 - val_accuracy: 0.9630\n",
            "Epoch 634/1000\n",
            "46/46 - 3s - loss: 0.0434 - accuracy: 0.9745 - val_loss: 0.0931 - val_accuracy: 0.9638\n",
            "Epoch 635/1000\n",
            "46/46 - 3s - loss: 0.0428 - accuracy: 0.9739 - val_loss: 0.1025 - val_accuracy: 0.9545\n",
            "Epoch 636/1000\n",
            "46/46 - 3s - loss: 0.0395 - accuracy: 0.9741 - val_loss: 0.0891 - val_accuracy: 0.9615\n",
            "Epoch 637/1000\n",
            "46/46 - 3s - loss: 0.0395 - accuracy: 0.9755 - val_loss: 0.0936 - val_accuracy: 0.9609\n",
            "Epoch 638/1000\n",
            "46/46 - 3s - loss: 0.0365 - accuracy: 0.9770 - val_loss: 0.0898 - val_accuracy: 0.9630\n",
            "Epoch 639/1000\n",
            "46/46 - 3s - loss: 0.0384 - accuracy: 0.9751 - val_loss: 0.0975 - val_accuracy: 0.9603\n",
            "Epoch 640/1000\n",
            "46/46 - 3s - loss: 0.0421 - accuracy: 0.9723 - val_loss: 0.2539 - val_accuracy: 0.9317\n",
            "Epoch 641/1000\n",
            "46/46 - 3s - loss: 0.0408 - accuracy: 0.9725 - val_loss: 0.0990 - val_accuracy: 0.9611\n",
            "Epoch 642/1000\n",
            "46/46 - 3s - loss: 0.0395 - accuracy: 0.9736 - val_loss: 0.0976 - val_accuracy: 0.9614\n",
            "Epoch 643/1000\n",
            "46/46 - 3s - loss: 0.0377 - accuracy: 0.9765 - val_loss: 0.4715 - val_accuracy: 0.9239\n",
            "Epoch 644/1000\n",
            "46/46 - 3s - loss: 0.0419 - accuracy: 0.9744 - val_loss: 0.1331 - val_accuracy: 0.9461\n",
            "Epoch 645/1000\n",
            "46/46 - 3s - loss: 0.0482 - accuracy: 0.9710 - val_loss: 0.1134 - val_accuracy: 0.9531\n",
            "Epoch 646/1000\n",
            "46/46 - 3s - loss: 0.0462 - accuracy: 0.9705 - val_loss: 0.1903 - val_accuracy: 0.9406\n",
            "Epoch 647/1000\n",
            "46/46 - 3s - loss: 0.0432 - accuracy: 0.9734 - val_loss: 0.0942 - val_accuracy: 0.9564\n",
            "Epoch 648/1000\n",
            "46/46 - 3s - loss: 0.0403 - accuracy: 0.9735 - val_loss: 0.0884 - val_accuracy: 0.9634\n",
            "Epoch 649/1000\n",
            "46/46 - 3s - loss: 0.0400 - accuracy: 0.9742 - val_loss: 0.0895 - val_accuracy: 0.9628\n",
            "Epoch 650/1000\n",
            "46/46 - 3s - loss: 0.0373 - accuracy: 0.9754 - val_loss: 0.0964 - val_accuracy: 0.9602\n",
            "Epoch 651/1000\n",
            "46/46 - 3s - loss: 0.0382 - accuracy: 0.9755 - val_loss: 0.0999 - val_accuracy: 0.9609\n",
            "Epoch 652/1000\n",
            "46/46 - 3s - loss: 0.0390 - accuracy: 0.9748 - val_loss: 0.0982 - val_accuracy: 0.9612\n",
            "Epoch 653/1000\n",
            "46/46 - 3s - loss: 0.0394 - accuracy: 0.9757 - val_loss: 0.0906 - val_accuracy: 0.9669\n",
            "Epoch 654/1000\n",
            "46/46 - 3s - loss: 0.0385 - accuracy: 0.9736 - val_loss: 0.0845 - val_accuracy: 0.9644\n",
            "Epoch 655/1000\n",
            "46/46 - 3s - loss: 0.0395 - accuracy: 0.9733 - val_loss: 0.0976 - val_accuracy: 0.9564\n",
            "Epoch 656/1000\n",
            "46/46 - 3s - loss: 0.0397 - accuracy: 0.9756 - val_loss: 0.0932 - val_accuracy: 0.9641\n",
            "Epoch 657/1000\n",
            "46/46 - 3s - loss: 0.0382 - accuracy: 0.9749 - val_loss: 0.1469 - val_accuracy: 0.9497\n",
            "Epoch 658/1000\n",
            "46/46 - 3s - loss: 0.0372 - accuracy: 0.9757 - val_loss: 0.1610 - val_accuracy: 0.9457\n",
            "Epoch 659/1000\n",
            "46/46 - 3s - loss: 0.0390 - accuracy: 0.9756 - val_loss: 0.4202 - val_accuracy: 0.9294\n",
            "Epoch 660/1000\n",
            "46/46 - 3s - loss: 0.0410 - accuracy: 0.9737 - val_loss: 0.2900 - val_accuracy: 0.9429\n",
            "Epoch 661/1000\n",
            "46/46 - 3s - loss: 0.0616 - accuracy: 0.9723 - val_loss: 0.1673 - val_accuracy: 0.9329\n",
            "Epoch 662/1000\n",
            "46/46 - 3s - loss: 0.0480 - accuracy: 0.9715 - val_loss: 0.1088 - val_accuracy: 0.9587\n",
            "Epoch 663/1000\n",
            "46/46 - 3s - loss: 0.0445 - accuracy: 0.9749 - val_loss: 0.1479 - val_accuracy: 0.9351\n",
            "Epoch 664/1000\n",
            "46/46 - 3s - loss: 0.0395 - accuracy: 0.9768 - val_loss: 0.0984 - val_accuracy: 0.9632\n",
            "Epoch 665/1000\n",
            "46/46 - 3s - loss: 0.0397 - accuracy: 0.9758 - val_loss: 0.0914 - val_accuracy: 0.9635\n",
            "Epoch 666/1000\n",
            "46/46 - 3s - loss: 0.0370 - accuracy: 0.9764 - val_loss: 0.0974 - val_accuracy: 0.9608\n",
            "Epoch 667/1000\n",
            "46/46 - 3s - loss: 0.0354 - accuracy: 0.9759 - val_loss: 0.1361 - val_accuracy: 0.9524\n",
            "Epoch 668/1000\n",
            "46/46 - 3s - loss: 0.0378 - accuracy: 0.9758 - val_loss: 0.2389 - val_accuracy: 0.9248\n",
            "Epoch 669/1000\n",
            "46/46 - 3s - loss: 0.0550 - accuracy: 0.9716 - val_loss: 0.3443 - val_accuracy: 0.9211\n",
            "Epoch 670/1000\n",
            "46/46 - 3s - loss: 0.0511 - accuracy: 0.9703 - val_loss: 0.0795 - val_accuracy: 0.9631\n",
            "Epoch 671/1000\n",
            "46/46 - 3s - loss: 0.0419 - accuracy: 0.9730 - val_loss: 0.0842 - val_accuracy: 0.9589\n",
            "Epoch 672/1000\n",
            "46/46 - 3s - loss: 0.0391 - accuracy: 0.9760 - val_loss: 0.0875 - val_accuracy: 0.9608\n",
            "Epoch 673/1000\n",
            "46/46 - 3s - loss: 0.0406 - accuracy: 0.9739 - val_loss: 0.0830 - val_accuracy: 0.9646\n",
            "Epoch 674/1000\n",
            "46/46 - 3s - loss: 0.0362 - accuracy: 0.9764 - val_loss: 0.0936 - val_accuracy: 0.9595\n",
            "Epoch 675/1000\n",
            "46/46 - 3s - loss: 0.0433 - accuracy: 0.9718 - val_loss: 0.8998 - val_accuracy: 0.8858\n",
            "Epoch 676/1000\n",
            "46/46 - 3s - loss: 0.0516 - accuracy: 0.9707 - val_loss: 0.4912 - val_accuracy: 0.9083\n",
            "Epoch 677/1000\n",
            "46/46 - 3s - loss: 0.0421 - accuracy: 0.9737 - val_loss: 0.1847 - val_accuracy: 0.9311\n",
            "Epoch 678/1000\n",
            "46/46 - 3s - loss: 0.0392 - accuracy: 0.9763 - val_loss: 0.0925 - val_accuracy: 0.9601\n",
            "Epoch 679/1000\n",
            "46/46 - 3s - loss: 0.0380 - accuracy: 0.9764 - val_loss: 0.0981 - val_accuracy: 0.9593\n",
            "Epoch 680/1000\n",
            "46/46 - 3s - loss: 0.0366 - accuracy: 0.9772 - val_loss: 0.1773 - val_accuracy: 0.9426\n",
            "Epoch 681/1000\n",
            "46/46 - 3s - loss: 0.0368 - accuracy: 0.9765 - val_loss: 0.0966 - val_accuracy: 0.9605\n",
            "Epoch 682/1000\n",
            "46/46 - 3s - loss: 0.0352 - accuracy: 0.9779 - val_loss: 0.3684 - val_accuracy: 0.9255\n",
            "Epoch 683/1000\n",
            "46/46 - 3s - loss: 0.0367 - accuracy: 0.9745 - val_loss: 0.5571 - val_accuracy: 0.9191\n",
            "Epoch 684/1000\n",
            "46/46 - 3s - loss: 0.0427 - accuracy: 0.9755 - val_loss: 0.0908 - val_accuracy: 0.9641\n",
            "Epoch 685/1000\n",
            "46/46 - 3s - loss: 0.0400 - accuracy: 0.9746 - val_loss: 0.0920 - val_accuracy: 0.9648\n",
            "Epoch 686/1000\n",
            "46/46 - 3s - loss: 0.0373 - accuracy: 0.9760 - val_loss: 0.0924 - val_accuracy: 0.9615\n",
            "Epoch 687/1000\n",
            "46/46 - 3s - loss: 0.0370 - accuracy: 0.9756 - val_loss: 0.1049 - val_accuracy: 0.9630\n",
            "Epoch 688/1000\n",
            "46/46 - 3s - loss: 0.0450 - accuracy: 0.9734 - val_loss: 0.1059 - val_accuracy: 0.9595\n",
            "Epoch 689/1000\n",
            "46/46 - 3s - loss: 0.0381 - accuracy: 0.9739 - val_loss: 0.1119 - val_accuracy: 0.9566\n",
            "Epoch 690/1000\n",
            "46/46 - 3s - loss: 0.0413 - accuracy: 0.9744 - val_loss: 0.2807 - val_accuracy: 0.9232\n",
            "Epoch 691/1000\n",
            "46/46 - 3s - loss: 0.0519 - accuracy: 0.9736 - val_loss: 0.7082 - val_accuracy: 0.9136\n",
            "Epoch 692/1000\n",
            "46/46 - 3s - loss: 0.0413 - accuracy: 0.9727 - val_loss: 0.1134 - val_accuracy: 0.9499\n",
            "Epoch 693/1000\n",
            "46/46 - 3s - loss: 0.0381 - accuracy: 0.9776 - val_loss: 0.0951 - val_accuracy: 0.9644\n",
            "Epoch 694/1000\n",
            "46/46 - 3s - loss: 0.0384 - accuracy: 0.9759 - val_loss: 0.0934 - val_accuracy: 0.9630\n",
            "Epoch 695/1000\n",
            "46/46 - 3s - loss: 0.0352 - accuracy: 0.9769 - val_loss: 0.0973 - val_accuracy: 0.9602\n",
            "Epoch 696/1000\n",
            "46/46 - 3s - loss: 0.0419 - accuracy: 0.9763 - val_loss: 0.0960 - val_accuracy: 0.9635\n",
            "Epoch 697/1000\n",
            "46/46 - 3s - loss: 0.0368 - accuracy: 0.9766 - val_loss: 0.6557 - val_accuracy: 0.9218\n",
            "Epoch 698/1000\n",
            "46/46 - 3s - loss: 0.0377 - accuracy: 0.9757 - val_loss: 0.2198 - val_accuracy: 0.9185\n",
            "Epoch 699/1000\n",
            "46/46 - 3s - loss: 0.0361 - accuracy: 0.9768 - val_loss: 0.0979 - val_accuracy: 0.9611\n",
            "Epoch 700/1000\n",
            "46/46 - 3s - loss: 0.0365 - accuracy: 0.9765 - val_loss: 0.1268 - val_accuracy: 0.9532\n",
            "Epoch 701/1000\n",
            "46/46 - 3s - loss: 0.0415 - accuracy: 0.9766 - val_loss: 0.1134 - val_accuracy: 0.9609\n",
            "Epoch 702/1000\n",
            "46/46 - 3s - loss: 0.0397 - accuracy: 0.9763 - val_loss: 0.0961 - val_accuracy: 0.9647\n",
            "Epoch 703/1000\n",
            "46/46 - 3s - loss: 0.0359 - accuracy: 0.9775 - val_loss: 0.0967 - val_accuracy: 0.9627\n",
            "Epoch 704/1000\n",
            "46/46 - 3s - loss: 0.0362 - accuracy: 0.9765 - val_loss: 0.0954 - val_accuracy: 0.9612\n",
            "Epoch 705/1000\n",
            "46/46 - 3s - loss: 0.0426 - accuracy: 0.9759 - val_loss: 0.2519 - val_accuracy: 0.9204\n",
            "Epoch 706/1000\n",
            "46/46 - 3s - loss: 0.0398 - accuracy: 0.9759 - val_loss: 0.8834 - val_accuracy: 0.9120\n",
            "Epoch 707/1000\n",
            "46/46 - 3s - loss: 0.0462 - accuracy: 0.9717 - val_loss: 0.5566 - val_accuracy: 0.9110\n",
            "Epoch 708/1000\n",
            "46/46 - 3s - loss: 0.0430 - accuracy: 0.9753 - val_loss: 0.0888 - val_accuracy: 0.9637\n",
            "Epoch 709/1000\n",
            "46/46 - 3s - loss: 0.0407 - accuracy: 0.9752 - val_loss: 0.2870 - val_accuracy: 0.9194\n",
            "Epoch 710/1000\n",
            "46/46 - 3s - loss: 0.0352 - accuracy: 0.9775 - val_loss: 0.1064 - val_accuracy: 0.9614\n",
            "Epoch 711/1000\n",
            "46/46 - 3s - loss: 0.0373 - accuracy: 0.9768 - val_loss: 0.2067 - val_accuracy: 0.9306\n",
            "Epoch 712/1000\n",
            "46/46 - 3s - loss: 0.0355 - accuracy: 0.9777 - val_loss: 0.4847 - val_accuracy: 0.9143\n",
            "Epoch 713/1000\n",
            "46/46 - 3s - loss: 0.0433 - accuracy: 0.9732 - val_loss: 0.0960 - val_accuracy: 0.9656\n",
            "Epoch 714/1000\n",
            "46/46 - 3s - loss: 0.0390 - accuracy: 0.9763 - val_loss: 0.1153 - val_accuracy: 0.9433\n",
            "Epoch 715/1000\n",
            "46/46 - 3s - loss: 0.0392 - accuracy: 0.9753 - val_loss: 0.0894 - val_accuracy: 0.9615\n",
            "Epoch 716/1000\n",
            "46/46 - 3s - loss: 0.0369 - accuracy: 0.9772 - val_loss: 0.1732 - val_accuracy: 0.9329\n",
            "Epoch 717/1000\n",
            "46/46 - 3s - loss: 0.0365 - accuracy: 0.9775 - val_loss: 0.0933 - val_accuracy: 0.9599\n",
            "Epoch 718/1000\n",
            "46/46 - 3s - loss: 0.0383 - accuracy: 0.9751 - val_loss: 0.1166 - val_accuracy: 0.9557\n",
            "Epoch 719/1000\n",
            "46/46 - 3s - loss: 0.0416 - accuracy: 0.9735 - val_loss: 0.0955 - val_accuracy: 0.9622\n",
            "Epoch 720/1000\n",
            "46/46 - 3s - loss: 0.0387 - accuracy: 0.9771 - val_loss: 0.0969 - val_accuracy: 0.9641\n",
            "Epoch 721/1000\n",
            "46/46 - 3s - loss: 0.0394 - accuracy: 0.9751 - val_loss: 0.0897 - val_accuracy: 0.9646\n",
            "Epoch 722/1000\n",
            "46/46 - 3s - loss: 0.0361 - accuracy: 0.9779 - val_loss: 0.0994 - val_accuracy: 0.9617\n",
            "Epoch 723/1000\n",
            "46/46 - 3s - loss: 0.0364 - accuracy: 0.9786 - val_loss: 0.0904 - val_accuracy: 0.9663\n",
            "Epoch 724/1000\n",
            "46/46 - 3s - loss: 0.0358 - accuracy: 0.9763 - val_loss: 0.0983 - val_accuracy: 0.9656\n",
            "Epoch 725/1000\n",
            "46/46 - 3s - loss: 0.0344 - accuracy: 0.9778 - val_loss: 0.0963 - val_accuracy: 0.9621\n",
            "Epoch 726/1000\n",
            "46/46 - 3s - loss: 0.0341 - accuracy: 0.9776 - val_loss: 0.0984 - val_accuracy: 0.9621\n",
            "Epoch 727/1000\n",
            "46/46 - 3s - loss: 0.0345 - accuracy: 0.9761 - val_loss: 0.0982 - val_accuracy: 0.9622\n",
            "Epoch 728/1000\n",
            "46/46 - 3s - loss: 0.0346 - accuracy: 0.9769 - val_loss: 0.0997 - val_accuracy: 0.9619\n",
            "Epoch 729/1000\n",
            "46/46 - 3s - loss: 0.0359 - accuracy: 0.9772 - val_loss: 0.0988 - val_accuracy: 0.9647\n",
            "Epoch 730/1000\n",
            "46/46 - 3s - loss: 0.0353 - accuracy: 0.9755 - val_loss: 0.0967 - val_accuracy: 0.9624\n",
            "Epoch 731/1000\n",
            "46/46 - 3s - loss: 0.0408 - accuracy: 0.9752 - val_loss: 0.0934 - val_accuracy: 0.9624\n",
            "Epoch 732/1000\n",
            "46/46 - 3s - loss: 0.0379 - accuracy: 0.9747 - val_loss: 0.1118 - val_accuracy: 0.9560\n",
            "Epoch 733/1000\n",
            "46/46 - 3s - loss: 0.0495 - accuracy: 0.9700 - val_loss: 0.1407 - val_accuracy: 0.9467\n",
            "Epoch 734/1000\n",
            "46/46 - 3s - loss: 0.0455 - accuracy: 0.9742 - val_loss: 0.1005 - val_accuracy: 0.9608\n",
            "Epoch 735/1000\n",
            "46/46 - 3s - loss: 0.0417 - accuracy: 0.9743 - val_loss: 0.0894 - val_accuracy: 0.9608\n",
            "Epoch 736/1000\n",
            "46/46 - 3s - loss: 0.0382 - accuracy: 0.9751 - val_loss: 0.1046 - val_accuracy: 0.9605\n",
            "Epoch 737/1000\n",
            "46/46 - 3s - loss: 0.0359 - accuracy: 0.9755 - val_loss: 0.1015 - val_accuracy: 0.9612\n",
            "Epoch 738/1000\n",
            "46/46 - 3s - loss: 0.0340 - accuracy: 0.9785 - val_loss: 0.1042 - val_accuracy: 0.9619\n",
            "Epoch 739/1000\n",
            "46/46 - 3s - loss: 0.0336 - accuracy: 0.9785 - val_loss: 0.0986 - val_accuracy: 0.9619\n",
            "Epoch 740/1000\n",
            "46/46 - 3s - loss: 0.0353 - accuracy: 0.9756 - val_loss: 0.1028 - val_accuracy: 0.9628\n",
            "Epoch 741/1000\n",
            "46/46 - 3s - loss: 0.0363 - accuracy: 0.9767 - val_loss: 0.0997 - val_accuracy: 0.9615\n",
            "Epoch 742/1000\n",
            "46/46 - 3s - loss: 0.0378 - accuracy: 0.9745 - val_loss: 0.0918 - val_accuracy: 0.9599\n",
            "Epoch 743/1000\n",
            "46/46 - 3s - loss: 0.0443 - accuracy: 0.9724 - val_loss: 0.2152 - val_accuracy: 0.9223\n",
            "Epoch 744/1000\n",
            "46/46 - 3s - loss: 0.0596 - accuracy: 0.9681 - val_loss: 0.1508 - val_accuracy: 0.9487\n",
            "Epoch 745/1000\n",
            "46/46 - 3s - loss: 0.0472 - accuracy: 0.9729 - val_loss: 0.1062 - val_accuracy: 0.9583\n",
            "Epoch 746/1000\n",
            "46/46 - 3s - loss: 0.0411 - accuracy: 0.9752 - val_loss: 0.1021 - val_accuracy: 0.9599\n",
            "Epoch 747/1000\n",
            "46/46 - 3s - loss: 0.0379 - accuracy: 0.9764 - val_loss: 0.1012 - val_accuracy: 0.9622\n",
            "Epoch 748/1000\n",
            "46/46 - 3s - loss: 0.0380 - accuracy: 0.9773 - val_loss: 0.0841 - val_accuracy: 0.9614\n",
            "Epoch 749/1000\n",
            "46/46 - 3s - loss: 0.0352 - accuracy: 0.9773 - val_loss: 0.1197 - val_accuracy: 0.9532\n",
            "Epoch 750/1000\n",
            "46/46 - 3s - loss: 0.0412 - accuracy: 0.9745 - val_loss: 0.0955 - val_accuracy: 0.9608\n",
            "Epoch 751/1000\n",
            "46/46 - 3s - loss: 0.0422 - accuracy: 0.9743 - val_loss: 0.1198 - val_accuracy: 0.9551\n",
            "Epoch 752/1000\n",
            "46/46 - 3s - loss: 0.0369 - accuracy: 0.9766 - val_loss: 0.0887 - val_accuracy: 0.9659\n",
            "Epoch 753/1000\n",
            "46/46 - 3s - loss: 0.0381 - accuracy: 0.9766 - val_loss: 0.1743 - val_accuracy: 0.9471\n",
            "Epoch 754/1000\n",
            "46/46 - 3s - loss: 0.0355 - accuracy: 0.9772 - val_loss: 0.1081 - val_accuracy: 0.9631\n",
            "Epoch 755/1000\n",
            "46/46 - 3s - loss: 0.0346 - accuracy: 0.9773 - val_loss: 0.0981 - val_accuracy: 0.9622\n",
            "Epoch 756/1000\n",
            "46/46 - 3s - loss: 0.0352 - accuracy: 0.9769 - val_loss: 0.1011 - val_accuracy: 0.9609\n",
            "Epoch 757/1000\n",
            "46/46 - 3s - loss: 0.0349 - accuracy: 0.9760 - val_loss: 0.4064 - val_accuracy: 0.9269\n",
            "Epoch 758/1000\n",
            "46/46 - 3s - loss: 0.0345 - accuracy: 0.9779 - val_loss: 0.1069 - val_accuracy: 0.9617\n",
            "Epoch 759/1000\n",
            "46/46 - 3s - loss: 0.0363 - accuracy: 0.9758 - val_loss: 0.1099 - val_accuracy: 0.9596\n",
            "Epoch 760/1000\n",
            "46/46 - 3s - loss: 0.0363 - accuracy: 0.9776 - val_loss: 0.1041 - val_accuracy: 0.9640\n",
            "Epoch 761/1000\n",
            "46/46 - 3s - loss: 0.0360 - accuracy: 0.9757 - val_loss: 0.1040 - val_accuracy: 0.9605\n",
            "Epoch 762/1000\n",
            "46/46 - 3s - loss: 0.0363 - accuracy: 0.9772 - val_loss: 0.1016 - val_accuracy: 0.9644\n",
            "Epoch 763/1000\n",
            "46/46 - 3s - loss: 0.0393 - accuracy: 0.9735 - val_loss: 0.1010 - val_accuracy: 0.9550\n",
            "Epoch 764/1000\n",
            "46/46 - 3s - loss: 0.0394 - accuracy: 0.9749 - val_loss: 0.0935 - val_accuracy: 0.9641\n",
            "Epoch 765/1000\n",
            "46/46 - 3s - loss: 0.0407 - accuracy: 0.9754 - val_loss: 0.0899 - val_accuracy: 0.9634\n",
            "Epoch 766/1000\n",
            "46/46 - 3s - loss: 0.0399 - accuracy: 0.9759 - val_loss: 0.0995 - val_accuracy: 0.9606\n",
            "Epoch 767/1000\n",
            "46/46 - 3s - loss: 0.0377 - accuracy: 0.9758 - val_loss: 0.1016 - val_accuracy: 0.9651\n",
            "Epoch 768/1000\n",
            "46/46 - 3s - loss: 0.0376 - accuracy: 0.9781 - val_loss: 0.1465 - val_accuracy: 0.9483\n",
            "Epoch 769/1000\n",
            "46/46 - 3s - loss: 0.0361 - accuracy: 0.9767 - val_loss: 0.3738 - val_accuracy: 0.9346\n",
            "Epoch 770/1000\n",
            "46/46 - 3s - loss: 0.0391 - accuracy: 0.9766 - val_loss: 0.1219 - val_accuracy: 0.9510\n",
            "Epoch 771/1000\n",
            "46/46 - 3s - loss: 0.0423 - accuracy: 0.9760 - val_loss: 0.1090 - val_accuracy: 0.9622\n",
            "Epoch 772/1000\n",
            "46/46 - 3s - loss: 0.0415 - accuracy: 0.9739 - val_loss: 0.1377 - val_accuracy: 0.9438\n",
            "Epoch 773/1000\n",
            "46/46 - 3s - loss: 0.0342 - accuracy: 0.9775 - val_loss: 0.1487 - val_accuracy: 0.9535\n",
            "Epoch 774/1000\n",
            "46/46 - 3s - loss: 0.0342 - accuracy: 0.9764 - val_loss: 0.5117 - val_accuracy: 0.9250\n",
            "Epoch 775/1000\n",
            "46/46 - 3s - loss: 0.0353 - accuracy: 0.9788 - val_loss: 0.1013 - val_accuracy: 0.9635\n",
            "Epoch 776/1000\n",
            "46/46 - 3s - loss: 0.0423 - accuracy: 0.9759 - val_loss: 0.0997 - val_accuracy: 0.9638\n",
            "Epoch 777/1000\n",
            "46/46 - 3s - loss: 0.0370 - accuracy: 0.9760 - val_loss: 0.1065 - val_accuracy: 0.9640\n",
            "Epoch 778/1000\n",
            "46/46 - 3s - loss: 0.0358 - accuracy: 0.9763 - val_loss: 0.5813 - val_accuracy: 0.9204\n",
            "Epoch 779/1000\n",
            "46/46 - 3s - loss: 0.0367 - accuracy: 0.9771 - val_loss: 0.3302 - val_accuracy: 0.9320\n",
            "Epoch 780/1000\n",
            "46/46 - 3s - loss: 0.0412 - accuracy: 0.9746 - val_loss: 0.1112 - val_accuracy: 0.9614\n",
            "Epoch 781/1000\n",
            "46/46 - 3s - loss: 0.0450 - accuracy: 0.9735 - val_loss: 0.0998 - val_accuracy: 0.9560\n",
            "Epoch 782/1000\n",
            "46/46 - 3s - loss: 0.0364 - accuracy: 0.9767 - val_loss: 0.0906 - val_accuracy: 0.9621\n",
            "Epoch 783/1000\n",
            "46/46 - 3s - loss: 0.0389 - accuracy: 0.9752 - val_loss: 0.1053 - val_accuracy: 0.9510\n",
            "Epoch 784/1000\n",
            "46/46 - 3s - loss: 0.0399 - accuracy: 0.9766 - val_loss: 0.6101 - val_accuracy: 0.9047\n",
            "Epoch 785/1000\n",
            "46/46 - 3s - loss: 0.0423 - accuracy: 0.9756 - val_loss: 0.4210 - val_accuracy: 0.9111\n",
            "Epoch 786/1000\n",
            "46/46 - 3s - loss: 0.0502 - accuracy: 0.9728 - val_loss: 0.2542 - val_accuracy: 0.9317\n",
            "Epoch 787/1000\n",
            "46/46 - 3s - loss: 0.0367 - accuracy: 0.9755 - val_loss: 0.0952 - val_accuracy: 0.9640\n",
            "Epoch 788/1000\n",
            "46/46 - 3s - loss: 0.0396 - accuracy: 0.9783 - val_loss: 0.0968 - val_accuracy: 0.9625\n",
            "Epoch 789/1000\n",
            "46/46 - 3s - loss: 0.0370 - accuracy: 0.9754 - val_loss: 0.0961 - val_accuracy: 0.9646\n",
            "Epoch 790/1000\n",
            "46/46 - 3s - loss: 0.0391 - accuracy: 0.9759 - val_loss: 0.0926 - val_accuracy: 0.9627\n",
            "Epoch 791/1000\n",
            "46/46 - 3s - loss: 0.0394 - accuracy: 0.9761 - val_loss: 0.0930 - val_accuracy: 0.9617\n",
            "Epoch 792/1000\n",
            "46/46 - 3s - loss: 0.0388 - accuracy: 0.9753 - val_loss: 0.1030 - val_accuracy: 0.9585\n",
            "Epoch 793/1000\n",
            "46/46 - 3s - loss: 0.0402 - accuracy: 0.9748 - val_loss: 0.1115 - val_accuracy: 0.9542\n",
            "Epoch 794/1000\n",
            "46/46 - 3s - loss: 0.0385 - accuracy: 0.9752 - val_loss: 0.0912 - val_accuracy: 0.9627\n",
            "Epoch 795/1000\n",
            "46/46 - 3s - loss: 0.0393 - accuracy: 0.9751 - val_loss: 0.0968 - val_accuracy: 0.9621\n",
            "Epoch 796/1000\n",
            "46/46 - 3s - loss: 0.0385 - accuracy: 0.9768 - val_loss: 0.0932 - val_accuracy: 0.9606\n",
            "Epoch 797/1000\n",
            "46/46 - 3s - loss: 0.0373 - accuracy: 0.9758 - val_loss: 0.0960 - val_accuracy: 0.9609\n",
            "Epoch 798/1000\n",
            "46/46 - 3s - loss: 0.0385 - accuracy: 0.9739 - val_loss: 0.0898 - val_accuracy: 0.9618\n",
            "Epoch 799/1000\n",
            "46/46 - 3s - loss: 0.0355 - accuracy: 0.9773 - val_loss: 0.1010 - val_accuracy: 0.9609\n",
            "Epoch 800/1000\n",
            "46/46 - 3s - loss: 0.0343 - accuracy: 0.9771 - val_loss: 0.0973 - val_accuracy: 0.9643\n",
            "Epoch 801/1000\n",
            "46/46 - 3s - loss: 0.0380 - accuracy: 0.9769 - val_loss: 0.1037 - val_accuracy: 0.9615\n",
            "Epoch 802/1000\n",
            "46/46 - 3s - loss: 0.0438 - accuracy: 0.9725 - val_loss: 0.0925 - val_accuracy: 0.9615\n",
            "Epoch 803/1000\n",
            "46/46 - 3s - loss: 0.0379 - accuracy: 0.9776 - val_loss: 0.0976 - val_accuracy: 0.9617\n",
            "Epoch 804/1000\n",
            "46/46 - 3s - loss: 0.0357 - accuracy: 0.9768 - val_loss: 0.1027 - val_accuracy: 0.9628\n",
            "Epoch 805/1000\n",
            "46/46 - 3s - loss: 0.0342 - accuracy: 0.9777 - val_loss: 0.1070 - val_accuracy: 0.9617\n",
            "Epoch 806/1000\n",
            "46/46 - 3s - loss: 0.0343 - accuracy: 0.9777 - val_loss: 0.1108 - val_accuracy: 0.9625\n",
            "Epoch 807/1000\n",
            "46/46 - 3s - loss: 0.0337 - accuracy: 0.9779 - val_loss: 0.3516 - val_accuracy: 0.9338\n",
            "Epoch 808/1000\n",
            "46/46 - 3s - loss: 0.0421 - accuracy: 0.9751 - val_loss: 0.1066 - val_accuracy: 0.9646\n",
            "Epoch 809/1000\n",
            "46/46 - 3s - loss: 0.0369 - accuracy: 0.9776 - val_loss: 0.1133 - val_accuracy: 0.9573\n",
            "Epoch 810/1000\n",
            "46/46 - 3s - loss: 0.0528 - accuracy: 0.9705 - val_loss: 0.2701 - val_accuracy: 0.9223\n",
            "Epoch 811/1000\n",
            "46/46 - 3s - loss: 0.0406 - accuracy: 0.9757 - val_loss: 0.2683 - val_accuracy: 0.9243\n",
            "Epoch 812/1000\n",
            "46/46 - 3s - loss: 0.0392 - accuracy: 0.9768 - val_loss: 0.8359 - val_accuracy: 0.9031\n",
            "Epoch 813/1000\n",
            "46/46 - 3s - loss: 0.0348 - accuracy: 0.9757 - val_loss: 0.1176 - val_accuracy: 0.9569\n",
            "Epoch 814/1000\n",
            "46/46 - 3s - loss: 0.0339 - accuracy: 0.9790 - val_loss: 0.1049 - val_accuracy: 0.9628\n",
            "Epoch 815/1000\n",
            "46/46 - 3s - loss: 0.0338 - accuracy: 0.9770 - val_loss: 0.1053 - val_accuracy: 0.9631\n",
            "Epoch 816/1000\n",
            "46/46 - 3s - loss: 0.0342 - accuracy: 0.9776 - val_loss: 0.1006 - val_accuracy: 0.9640\n",
            "Epoch 817/1000\n",
            "46/46 - 3s - loss: 0.0422 - accuracy: 0.9756 - val_loss: 0.1022 - val_accuracy: 0.9619\n",
            "Epoch 818/1000\n",
            "46/46 - 3s - loss: 0.0349 - accuracy: 0.9773 - val_loss: 0.1122 - val_accuracy: 0.9617\n",
            "Epoch 819/1000\n",
            "46/46 - 3s - loss: 0.0339 - accuracy: 0.9768 - val_loss: 0.1018 - val_accuracy: 0.9627\n",
            "Epoch 820/1000\n",
            "46/46 - 3s - loss: 0.0339 - accuracy: 0.9780 - val_loss: 0.1057 - val_accuracy: 0.9643\n",
            "Epoch 821/1000\n",
            "46/46 - 3s - loss: 0.0344 - accuracy: 0.9779 - val_loss: 0.1229 - val_accuracy: 0.9550\n",
            "Epoch 822/1000\n",
            "46/46 - 3s - loss: 0.0366 - accuracy: 0.9785 - val_loss: 0.1077 - val_accuracy: 0.9609\n",
            "Epoch 823/1000\n",
            "46/46 - 3s - loss: 0.0385 - accuracy: 0.9773 - val_loss: 0.0967 - val_accuracy: 0.9634\n",
            "Epoch 824/1000\n",
            "46/46 - 3s - loss: 0.0358 - accuracy: 0.9767 - val_loss: 0.1025 - val_accuracy: 0.9603\n",
            "Epoch 825/1000\n",
            "46/46 - 3s - loss: 0.0386 - accuracy: 0.9760 - val_loss: 0.1828 - val_accuracy: 0.9444\n",
            "Epoch 826/1000\n",
            "46/46 - 3s - loss: 0.0345 - accuracy: 0.9763 - val_loss: 0.1002 - val_accuracy: 0.9650\n",
            "Epoch 827/1000\n",
            "46/46 - 3s - loss: 0.0357 - accuracy: 0.9776 - val_loss: 0.1123 - val_accuracy: 0.9615\n",
            "Epoch 828/1000\n",
            "46/46 - 3s - loss: 0.0412 - accuracy: 0.9755 - val_loss: 0.1229 - val_accuracy: 0.9525\n",
            "Epoch 829/1000\n",
            "46/46 - 3s - loss: 0.0424 - accuracy: 0.9753 - val_loss: 0.0996 - val_accuracy: 0.9593\n",
            "Epoch 830/1000\n",
            "46/46 - 3s - loss: 0.0380 - accuracy: 0.9764 - val_loss: 0.1133 - val_accuracy: 0.9577\n",
            "Epoch 831/1000\n",
            "46/46 - 3s - loss: 0.0375 - accuracy: 0.9745 - val_loss: 0.1060 - val_accuracy: 0.9622\n",
            "Epoch 832/1000\n",
            "46/46 - 3s - loss: 0.0448 - accuracy: 0.9729 - val_loss: 0.2380 - val_accuracy: 0.9345\n",
            "Epoch 833/1000\n",
            "46/46 - 3s - loss: 0.0777 - accuracy: 0.9651 - val_loss: 0.1175 - val_accuracy: 0.9452\n",
            "Epoch 834/1000\n",
            "46/46 - 3s - loss: 0.0448 - accuracy: 0.9729 - val_loss: 0.0840 - val_accuracy: 0.9617\n",
            "Epoch 835/1000\n",
            "46/46 - 3s - loss: 0.0382 - accuracy: 0.9766 - val_loss: 0.0921 - val_accuracy: 0.9632\n",
            "Epoch 836/1000\n",
            "46/46 - 3s - loss: 0.0375 - accuracy: 0.9767 - val_loss: 0.0906 - val_accuracy: 0.9625\n",
            "Epoch 837/1000\n",
            "46/46 - 3s - loss: 0.0352 - accuracy: 0.9780 - val_loss: 0.0995 - val_accuracy: 0.9618\n",
            "Epoch 838/1000\n",
            "46/46 - 3s - loss: 0.0361 - accuracy: 0.9776 - val_loss: 0.1200 - val_accuracy: 0.9580\n",
            "Epoch 839/1000\n",
            "46/46 - 3s - loss: 0.0438 - accuracy: 0.9756 - val_loss: 0.1033 - val_accuracy: 0.9619\n",
            "Epoch 840/1000\n",
            "46/46 - 3s - loss: 0.0370 - accuracy: 0.9760 - val_loss: 0.1066 - val_accuracy: 0.9624\n",
            "Epoch 841/1000\n",
            "46/46 - 3s - loss: 0.0426 - accuracy: 0.9742 - val_loss: 0.4557 - val_accuracy: 0.9140\n",
            "Epoch 842/1000\n",
            "46/46 - 3s - loss: 0.0374 - accuracy: 0.9769 - val_loss: 0.1671 - val_accuracy: 0.9384\n",
            "Epoch 843/1000\n",
            "46/46 - 3s - loss: 0.0369 - accuracy: 0.9756 - val_loss: 0.1167 - val_accuracy: 0.9574\n",
            "Epoch 844/1000\n",
            "46/46 - 3s - loss: 0.0365 - accuracy: 0.9769 - val_loss: 0.0927 - val_accuracy: 0.9625\n",
            "Epoch 845/1000\n",
            "46/46 - 3s - loss: 0.0362 - accuracy: 0.9758 - val_loss: 0.0946 - val_accuracy: 0.9628\n",
            "Epoch 846/1000\n",
            "46/46 - 3s - loss: 0.0379 - accuracy: 0.9764 - val_loss: 0.0995 - val_accuracy: 0.9618\n",
            "Epoch 847/1000\n",
            "46/46 - 3s - loss: 0.0363 - accuracy: 0.9770 - val_loss: 0.1420 - val_accuracy: 0.9473\n",
            "Epoch 848/1000\n",
            "46/46 - 3s - loss: 0.0361 - accuracy: 0.9761 - val_loss: 0.1009 - val_accuracy: 0.9654\n",
            "Epoch 849/1000\n",
            "46/46 - 3s - loss: 0.0349 - accuracy: 0.9767 - val_loss: 0.1028 - val_accuracy: 0.9635\n",
            "Epoch 850/1000\n",
            "46/46 - 3s - loss: 0.0372 - accuracy: 0.9786 - val_loss: 0.2780 - val_accuracy: 0.9348\n",
            "Epoch 851/1000\n",
            "46/46 - 3s - loss: 0.0350 - accuracy: 0.9752 - val_loss: 0.1887 - val_accuracy: 0.9479\n",
            "Epoch 852/1000\n",
            "46/46 - 3s - loss: 0.0353 - accuracy: 0.9781 - val_loss: 0.1020 - val_accuracy: 0.9634\n",
            "Epoch 853/1000\n",
            "46/46 - 3s - loss: 0.0356 - accuracy: 0.9764 - val_loss: 0.1211 - val_accuracy: 0.9557\n",
            "Epoch 854/1000\n",
            "46/46 - 3s - loss: 0.0358 - accuracy: 0.9767 - val_loss: 0.1263 - val_accuracy: 0.9560\n",
            "Epoch 855/1000\n",
            "46/46 - 3s - loss: 0.0405 - accuracy: 0.9772 - val_loss: 0.0993 - val_accuracy: 0.9595\n",
            "Epoch 856/1000\n",
            "46/46 - 3s - loss: 0.0392 - accuracy: 0.9758 - val_loss: 0.1540 - val_accuracy: 0.9473\n",
            "Epoch 857/1000\n",
            "46/46 - 3s - loss: 0.0445 - accuracy: 0.9744 - val_loss: 0.1030 - val_accuracy: 0.9596\n",
            "Epoch 858/1000\n",
            "46/46 - 3s - loss: 0.0398 - accuracy: 0.9733 - val_loss: 0.1040 - val_accuracy: 0.9593\n",
            "Epoch 859/1000\n",
            "46/46 - 3s - loss: 0.0419 - accuracy: 0.9764 - val_loss: 0.0977 - val_accuracy: 0.9605\n",
            "Epoch 860/1000\n",
            "46/46 - 3s - loss: 0.0381 - accuracy: 0.9741 - val_loss: 0.0947 - val_accuracy: 0.9619\n",
            "Epoch 861/1000\n",
            "46/46 - 3s - loss: 0.0352 - accuracy: 0.9777 - val_loss: 0.0957 - val_accuracy: 0.9609\n",
            "Epoch 862/1000\n",
            "46/46 - 3s - loss: 0.0340 - accuracy: 0.9779 - val_loss: 0.2108 - val_accuracy: 0.9301\n",
            "Epoch 863/1000\n",
            "46/46 - 3s - loss: 0.0343 - accuracy: 0.9785 - val_loss: 0.1131 - val_accuracy: 0.9598\n",
            "Epoch 864/1000\n",
            "46/46 - 3s - loss: 0.0355 - accuracy: 0.9768 - val_loss: 0.1722 - val_accuracy: 0.9365\n",
            "Epoch 865/1000\n",
            "46/46 - 3s - loss: 0.0341 - accuracy: 0.9788 - val_loss: 0.1150 - val_accuracy: 0.9587\n",
            "Epoch 866/1000\n",
            "46/46 - 3s - loss: 0.0341 - accuracy: 0.9785 - val_loss: 0.1067 - val_accuracy: 0.9631\n",
            "Epoch 867/1000\n",
            "46/46 - 3s - loss: 0.0330 - accuracy: 0.9790 - val_loss: 0.1053 - val_accuracy: 0.9624\n",
            "Epoch 868/1000\n",
            "46/46 - 3s - loss: 0.0342 - accuracy: 0.9769 - val_loss: 0.1102 - val_accuracy: 0.9646\n",
            "Epoch 869/1000\n",
            "46/46 - 3s - loss: 0.0339 - accuracy: 0.9770 - val_loss: 0.1096 - val_accuracy: 0.9653\n",
            "Epoch 870/1000\n",
            "46/46 - 3s - loss: 0.0347 - accuracy: 0.9763 - val_loss: 0.1065 - val_accuracy: 0.9595\n",
            "Epoch 871/1000\n",
            "46/46 - 3s - loss: 0.0341 - accuracy: 0.9782 - val_loss: 0.1049 - val_accuracy: 0.9641\n",
            "Epoch 872/1000\n",
            "46/46 - 3s - loss: 0.0328 - accuracy: 0.9808 - val_loss: 0.1111 - val_accuracy: 0.9624\n",
            "Epoch 873/1000\n",
            "46/46 - 3s - loss: 0.0339 - accuracy: 0.9790 - val_loss: 0.1169 - val_accuracy: 0.9614\n",
            "Epoch 874/1000\n",
            "46/46 - 3s - loss: 0.0344 - accuracy: 0.9764 - val_loss: 0.1090 - val_accuracy: 0.9606\n",
            "Epoch 875/1000\n",
            "46/46 - 3s - loss: 0.0339 - accuracy: 0.9769 - val_loss: 0.1091 - val_accuracy: 0.9608\n",
            "Epoch 876/1000\n",
            "46/46 - 3s - loss: 0.0351 - accuracy: 0.9772 - val_loss: 0.1119 - val_accuracy: 0.9619\n",
            "Epoch 877/1000\n",
            "46/46 - 3s - loss: 0.0347 - accuracy: 0.9778 - val_loss: 0.1085 - val_accuracy: 0.9606\n",
            "Epoch 878/1000\n",
            "46/46 - 3s - loss: 0.0331 - accuracy: 0.9782 - val_loss: 0.1115 - val_accuracy: 0.9619\n",
            "Epoch 879/1000\n",
            "46/46 - 3s - loss: 0.0354 - accuracy: 0.9771 - val_loss: 0.1082 - val_accuracy: 0.9602\n",
            "Epoch 880/1000\n",
            "46/46 - 3s - loss: 0.0417 - accuracy: 0.9763 - val_loss: 0.1139 - val_accuracy: 0.9580\n",
            "Epoch 881/1000\n",
            "46/46 - 3s - loss: 0.0393 - accuracy: 0.9763 - val_loss: 0.0988 - val_accuracy: 0.9673\n",
            "Epoch 882/1000\n",
            "46/46 - 3s - loss: 0.0414 - accuracy: 0.9756 - val_loss: 0.1580 - val_accuracy: 0.9532\n",
            "Epoch 883/1000\n",
            "46/46 - 3s - loss: 0.0443 - accuracy: 0.9756 - val_loss: 0.0981 - val_accuracy: 0.9615\n",
            "Epoch 884/1000\n",
            "46/46 - 3s - loss: 0.0446 - accuracy: 0.9734 - val_loss: 0.0964 - val_accuracy: 0.9587\n",
            "Epoch 885/1000\n",
            "46/46 - 3s - loss: 0.0439 - accuracy: 0.9757 - val_loss: 0.1049 - val_accuracy: 0.9566\n",
            "Epoch 886/1000\n",
            "46/46 - 3s - loss: 0.0368 - accuracy: 0.9755 - val_loss: 0.1075 - val_accuracy: 0.9573\n",
            "Epoch 887/1000\n",
            "46/46 - 3s - loss: 0.0356 - accuracy: 0.9772 - val_loss: 0.1022 - val_accuracy: 0.9618\n",
            "Epoch 888/1000\n",
            "46/46 - 3s - loss: 0.0337 - accuracy: 0.9771 - val_loss: 0.1007 - val_accuracy: 0.9667\n",
            "Epoch 889/1000\n",
            "46/46 - 3s - loss: 0.0356 - accuracy: 0.9789 - val_loss: 0.1225 - val_accuracy: 0.9628\n",
            "Epoch 890/1000\n",
            "46/46 - 3s - loss: 0.0345 - accuracy: 0.9776 - val_loss: 0.1035 - val_accuracy: 0.9627\n",
            "Epoch 891/1000\n",
            "46/46 - 3s - loss: 0.0362 - accuracy: 0.9766 - val_loss: 0.1080 - val_accuracy: 0.9628\n",
            "Epoch 892/1000\n",
            "46/46 - 3s - loss: 0.0340 - accuracy: 0.9763 - val_loss: 0.1031 - val_accuracy: 0.9624\n",
            "Epoch 893/1000\n",
            "46/46 - 3s - loss: 0.0338 - accuracy: 0.9783 - val_loss: 0.0933 - val_accuracy: 0.9621\n",
            "Epoch 894/1000\n",
            "46/46 - 3s - loss: 0.0335 - accuracy: 0.9771 - val_loss: 0.0964 - val_accuracy: 0.9622\n",
            "Epoch 895/1000\n",
            "46/46 - 3s - loss: 0.0361 - accuracy: 0.9741 - val_loss: 0.0935 - val_accuracy: 0.9621\n",
            "Epoch 896/1000\n",
            "46/46 - 3s - loss: 0.0329 - accuracy: 0.9792 - val_loss: 0.1034 - val_accuracy: 0.9662\n",
            "Epoch 897/1000\n",
            "46/46 - 3s - loss: 0.0330 - accuracy: 0.9794 - val_loss: 0.1011 - val_accuracy: 0.9615\n",
            "Epoch 898/1000\n",
            "46/46 - 3s - loss: 0.0332 - accuracy: 0.9785 - val_loss: 0.1032 - val_accuracy: 0.9615\n",
            "Epoch 899/1000\n",
            "46/46 - 3s - loss: 0.0331 - accuracy: 0.9797 - val_loss: 0.1025 - val_accuracy: 0.9612\n",
            "Epoch 900/1000\n",
            "46/46 - 3s - loss: 0.0328 - accuracy: 0.9778 - val_loss: 0.0996 - val_accuracy: 0.9628\n",
            "Epoch 901/1000\n",
            "46/46 - 3s - loss: 0.0348 - accuracy: 0.9792 - val_loss: 0.0935 - val_accuracy: 0.9624\n",
            "Epoch 902/1000\n",
            "46/46 - 3s - loss: 0.0337 - accuracy: 0.9791 - val_loss: 0.1035 - val_accuracy: 0.9634\n",
            "Epoch 903/1000\n",
            "46/46 - 3s - loss: 0.0337 - accuracy: 0.9796 - val_loss: 0.1226 - val_accuracy: 0.9617\n",
            "Epoch 904/1000\n",
            "46/46 - 3s - loss: 0.0402 - accuracy: 0.9747 - val_loss: 0.2157 - val_accuracy: 0.9377\n",
            "Epoch 905/1000\n",
            "46/46 - 3s - loss: 0.0348 - accuracy: 0.9763 - val_loss: 0.7176 - val_accuracy: 0.9094\n",
            "Epoch 906/1000\n",
            "46/46 - 3s - loss: 0.0419 - accuracy: 0.9751 - val_loss: 0.5717 - val_accuracy: 0.9101\n",
            "Epoch 907/1000\n",
            "46/46 - 3s - loss: 0.0484 - accuracy: 0.9733 - val_loss: 0.1088 - val_accuracy: 0.9632\n",
            "Epoch 908/1000\n",
            "46/46 - 3s - loss: 0.0427 - accuracy: 0.9749 - val_loss: 0.0980 - val_accuracy: 0.9569\n",
            "Epoch 909/1000\n",
            "46/46 - 3s - loss: 0.0385 - accuracy: 0.9747 - val_loss: 0.0889 - val_accuracy: 0.9631\n",
            "Epoch 910/1000\n",
            "46/46 - 3s - loss: 0.0353 - accuracy: 0.9769 - val_loss: 0.0908 - val_accuracy: 0.9619\n",
            "Epoch 911/1000\n",
            "46/46 - 3s - loss: 0.0341 - accuracy: 0.9781 - val_loss: 0.0958 - val_accuracy: 0.9659\n",
            "Epoch 912/1000\n",
            "46/46 - 3s - loss: 0.0399 - accuracy: 0.9759 - val_loss: 0.4660 - val_accuracy: 0.9173\n",
            "Epoch 913/1000\n",
            "46/46 - 3s - loss: 0.0386 - accuracy: 0.9773 - val_loss: 0.1480 - val_accuracy: 0.9432\n",
            "Epoch 914/1000\n",
            "46/46 - 3s - loss: 0.0370 - accuracy: 0.9770 - val_loss: 0.1144 - val_accuracy: 0.9617\n",
            "Epoch 915/1000\n",
            "46/46 - 3s - loss: 0.0432 - accuracy: 0.9760 - val_loss: 0.0993 - val_accuracy: 0.9603\n",
            "Epoch 916/1000\n",
            "46/46 - 3s - loss: 0.0378 - accuracy: 0.9756 - val_loss: 0.0952 - val_accuracy: 0.9598\n",
            "Epoch 917/1000\n",
            "46/46 - 3s - loss: 0.0372 - accuracy: 0.9769 - val_loss: 0.1002 - val_accuracy: 0.9641\n",
            "Epoch 918/1000\n",
            "46/46 - 3s - loss: 0.0437 - accuracy: 0.9728 - val_loss: 0.0982 - val_accuracy: 0.9609\n",
            "Epoch 919/1000\n",
            "46/46 - 3s - loss: 0.0384 - accuracy: 0.9782 - val_loss: 0.1103 - val_accuracy: 0.9550\n",
            "Epoch 920/1000\n",
            "46/46 - 3s - loss: 0.0350 - accuracy: 0.9777 - val_loss: 0.1153 - val_accuracy: 0.9528\n",
            "Epoch 921/1000\n",
            "46/46 - 3s - loss: 0.0346 - accuracy: 0.9763 - val_loss: 0.0984 - val_accuracy: 0.9617\n",
            "Epoch 922/1000\n",
            "46/46 - 3s - loss: 0.0341 - accuracy: 0.9776 - val_loss: 0.1003 - val_accuracy: 0.9650\n",
            "Epoch 923/1000\n",
            "46/46 - 3s - loss: 0.0336 - accuracy: 0.9781 - val_loss: 0.0947 - val_accuracy: 0.9622\n",
            "Epoch 924/1000\n",
            "46/46 - 3s - loss: 0.0334 - accuracy: 0.9796 - val_loss: 0.1020 - val_accuracy: 0.9608\n",
            "Epoch 925/1000\n",
            "46/46 - 3s - loss: 0.0341 - accuracy: 0.9773 - val_loss: 0.1197 - val_accuracy: 0.9509\n",
            "Epoch 926/1000\n",
            "46/46 - 3s - loss: 0.0336 - accuracy: 0.9789 - val_loss: 0.0997 - val_accuracy: 0.9603\n",
            "Epoch 927/1000\n",
            "46/46 - 3s - loss: 0.0347 - accuracy: 0.9782 - val_loss: 0.0986 - val_accuracy: 0.9612\n",
            "Epoch 928/1000\n",
            "46/46 - 3s - loss: 0.0412 - accuracy: 0.9765 - val_loss: 0.1099 - val_accuracy: 0.9625\n",
            "Epoch 929/1000\n",
            "46/46 - 3s - loss: 0.0395 - accuracy: 0.9758 - val_loss: 0.0970 - val_accuracy: 0.9643\n",
            "Epoch 930/1000\n",
            "46/46 - 3s - loss: 0.0336 - accuracy: 0.9792 - val_loss: 0.1003 - val_accuracy: 0.9606\n",
            "Epoch 931/1000\n",
            "46/46 - 3s - loss: 0.0341 - accuracy: 0.9779 - val_loss: 0.1614 - val_accuracy: 0.9432\n",
            "Epoch 932/1000\n",
            "46/46 - 3s - loss: 0.0366 - accuracy: 0.9766 - val_loss: 0.1147 - val_accuracy: 0.9601\n",
            "Epoch 933/1000\n",
            "46/46 - 3s - loss: 0.0384 - accuracy: 0.9755 - val_loss: 0.0981 - val_accuracy: 0.9644\n",
            "Epoch 934/1000\n",
            "46/46 - 3s - loss: 0.0376 - accuracy: 0.9776 - val_loss: 0.1047 - val_accuracy: 0.9611\n",
            "Epoch 935/1000\n",
            "46/46 - 3s - loss: 0.0365 - accuracy: 0.9772 - val_loss: 0.1001 - val_accuracy: 0.9641\n",
            "Epoch 936/1000\n",
            "46/46 - 3s - loss: 0.0360 - accuracy: 0.9759 - val_loss: 0.1191 - val_accuracy: 0.9583\n",
            "Epoch 937/1000\n",
            "46/46 - 3s - loss: 0.0345 - accuracy: 0.9796 - val_loss: 0.0996 - val_accuracy: 0.9619\n",
            "Epoch 938/1000\n",
            "46/46 - 3s - loss: 0.0346 - accuracy: 0.9780 - val_loss: 0.1035 - val_accuracy: 0.9634\n",
            "Epoch 939/1000\n",
            "46/46 - 3s - loss: 0.0363 - accuracy: 0.9749 - val_loss: 0.1011 - val_accuracy: 0.9621\n",
            "Epoch 940/1000\n",
            "46/46 - 3s - loss: 0.0338 - accuracy: 0.9790 - val_loss: 0.0993 - val_accuracy: 0.9638\n",
            "Epoch 941/1000\n",
            "46/46 - 3s - loss: 0.0346 - accuracy: 0.9780 - val_loss: 0.1059 - val_accuracy: 0.9615\n",
            "Epoch 942/1000\n",
            "46/46 - 3s - loss: 0.0358 - accuracy: 0.9790 - val_loss: 0.1270 - val_accuracy: 0.9522\n",
            "Epoch 943/1000\n",
            "46/46 - 3s - loss: 0.0335 - accuracy: 0.9778 - val_loss: 0.1052 - val_accuracy: 0.9632\n",
            "Epoch 944/1000\n",
            "46/46 - 3s - loss: 0.0334 - accuracy: 0.9792 - val_loss: 0.1087 - val_accuracy: 0.9603\n",
            "Epoch 945/1000\n",
            "46/46 - 3s - loss: 0.0379 - accuracy: 0.9770 - val_loss: 0.1022 - val_accuracy: 0.9630\n",
            "Epoch 946/1000\n",
            "46/46 - 3s - loss: 0.0354 - accuracy: 0.9770 - val_loss: 0.1040 - val_accuracy: 0.9651\n",
            "Epoch 947/1000\n",
            "46/46 - 3s - loss: 0.0332 - accuracy: 0.9795 - val_loss: 0.1049 - val_accuracy: 0.9648\n",
            "Epoch 948/1000\n",
            "46/46 - 3s - loss: 0.0322 - accuracy: 0.9795 - val_loss: 0.1156 - val_accuracy: 0.9635\n",
            "Epoch 949/1000\n",
            "46/46 - 3s - loss: 0.0349 - accuracy: 0.9777 - val_loss: 0.1024 - val_accuracy: 0.9617\n",
            "Epoch 950/1000\n",
            "46/46 - 3s - loss: 0.0345 - accuracy: 0.9770 - val_loss: 0.1084 - val_accuracy: 0.9682\n",
            "Epoch 951/1000\n",
            "46/46 - 3s - loss: 0.0330 - accuracy: 0.9765 - val_loss: 0.1029 - val_accuracy: 0.9641\n",
            "Epoch 952/1000\n",
            "46/46 - 3s - loss: 0.0322 - accuracy: 0.9789 - val_loss: 0.1129 - val_accuracy: 0.9622\n",
            "Epoch 953/1000\n",
            "46/46 - 3s - loss: 0.0346 - accuracy: 0.9775 - val_loss: 0.1099 - val_accuracy: 0.9615\n",
            "Epoch 954/1000\n",
            "46/46 - 3s - loss: 0.0612 - accuracy: 0.9706 - val_loss: 0.0970 - val_accuracy: 0.9621\n",
            "Epoch 955/1000\n",
            "46/46 - 3s - loss: 0.0390 - accuracy: 0.9764 - val_loss: 0.0960 - val_accuracy: 0.9622\n",
            "Epoch 956/1000\n",
            "46/46 - 3s - loss: 0.0370 - accuracy: 0.9778 - val_loss: 0.0919 - val_accuracy: 0.9614\n",
            "Epoch 957/1000\n",
            "46/46 - 3s - loss: 0.0353 - accuracy: 0.9769 - val_loss: 0.0870 - val_accuracy: 0.9621\n",
            "Epoch 958/1000\n",
            "46/46 - 3s - loss: 0.0391 - accuracy: 0.9760 - val_loss: 0.0894 - val_accuracy: 0.9635\n",
            "Epoch 959/1000\n",
            "46/46 - 3s - loss: 0.0353 - accuracy: 0.9775 - val_loss: 0.1070 - val_accuracy: 0.9602\n",
            "Epoch 960/1000\n",
            "46/46 - 3s - loss: 0.0343 - accuracy: 0.9766 - val_loss: 0.0974 - val_accuracy: 0.9599\n",
            "Epoch 961/1000\n",
            "46/46 - 3s - loss: 0.0454 - accuracy: 0.9760 - val_loss: 0.1077 - val_accuracy: 0.9608\n",
            "Epoch 962/1000\n",
            "46/46 - 3s - loss: 0.0601 - accuracy: 0.9704 - val_loss: 0.3768 - val_accuracy: 0.9017\n",
            "Epoch 963/1000\n",
            "46/46 - 3s - loss: 0.0526 - accuracy: 0.9695 - val_loss: 0.1094 - val_accuracy: 0.9567\n",
            "Epoch 964/1000\n",
            "46/46 - 3s - loss: 0.0454 - accuracy: 0.9743 - val_loss: 0.1070 - val_accuracy: 0.9656\n",
            "Epoch 965/1000\n",
            "46/46 - 3s - loss: 0.0417 - accuracy: 0.9758 - val_loss: 0.1013 - val_accuracy: 0.9640\n",
            "Epoch 966/1000\n",
            "46/46 - 3s - loss: 0.0399 - accuracy: 0.9768 - val_loss: 0.1006 - val_accuracy: 0.9602\n",
            "Epoch 967/1000\n",
            "46/46 - 3s - loss: 0.0369 - accuracy: 0.9789 - val_loss: 0.0950 - val_accuracy: 0.9637\n",
            "Epoch 968/1000\n",
            "46/46 - 3s - loss: 0.0368 - accuracy: 0.9783 - val_loss: 0.1010 - val_accuracy: 0.9624\n",
            "Epoch 969/1000\n",
            "46/46 - 3s - loss: 0.0364 - accuracy: 0.9785 - val_loss: 0.1020 - val_accuracy: 0.9598\n",
            "Epoch 970/1000\n",
            "46/46 - 3s - loss: 0.0371 - accuracy: 0.9780 - val_loss: 0.1072 - val_accuracy: 0.9590\n",
            "Epoch 971/1000\n",
            "46/46 - 3s - loss: 0.0376 - accuracy: 0.9746 - val_loss: 0.1064 - val_accuracy: 0.9638\n",
            "Epoch 972/1000\n",
            "46/46 - 3s - loss: 0.0357 - accuracy: 0.9781 - val_loss: 0.1028 - val_accuracy: 0.9592\n",
            "Epoch 973/1000\n",
            "46/46 - 3s - loss: 0.0335 - accuracy: 0.9785 - val_loss: 0.1036 - val_accuracy: 0.9618\n",
            "Epoch 974/1000\n",
            "46/46 - 3s - loss: 0.0358 - accuracy: 0.9765 - val_loss: 0.1067 - val_accuracy: 0.9596\n",
            "Epoch 975/1000\n",
            "46/46 - 3s - loss: 0.0355 - accuracy: 0.9785 - val_loss: 0.1010 - val_accuracy: 0.9605\n",
            "Epoch 976/1000\n",
            "46/46 - 3s - loss: 0.0394 - accuracy: 0.9751 - val_loss: 0.4595 - val_accuracy: 0.9169\n",
            "Epoch 977/1000\n",
            "46/46 - 3s - loss: 0.0372 - accuracy: 0.9764 - val_loss: 0.1375 - val_accuracy: 0.9502\n",
            "Epoch 978/1000\n",
            "46/46 - 3s - loss: 0.0399 - accuracy: 0.9751 - val_loss: 0.1080 - val_accuracy: 0.9615\n",
            "Epoch 979/1000\n",
            "46/46 - 3s - loss: 0.0366 - accuracy: 0.9767 - val_loss: 0.1019 - val_accuracy: 0.9608\n",
            "Epoch 980/1000\n",
            "46/46 - 3s - loss: 0.0399 - accuracy: 0.9748 - val_loss: 0.1000 - val_accuracy: 0.9695\n",
            "Epoch 981/1000\n",
            "46/46 - 3s - loss: 0.0382 - accuracy: 0.9745 - val_loss: 0.1008 - val_accuracy: 0.9640\n",
            "Epoch 982/1000\n",
            "46/46 - 3s - loss: 0.0357 - accuracy: 0.9777 - val_loss: 0.0924 - val_accuracy: 0.9625\n",
            "Epoch 983/1000\n",
            "46/46 - 3s - loss: 0.0333 - accuracy: 0.9792 - val_loss: 0.0946 - val_accuracy: 0.9631\n",
            "Epoch 984/1000\n",
            "46/46 - 3s - loss: 0.0327 - accuracy: 0.9789 - val_loss: 0.0992 - val_accuracy: 0.9638\n",
            "Epoch 985/1000\n",
            "46/46 - 3s - loss: 0.0326 - accuracy: 0.9781 - val_loss: 0.1002 - val_accuracy: 0.9632\n",
            "Epoch 986/1000\n",
            "46/46 - 3s - loss: 0.0343 - accuracy: 0.9772 - val_loss: 0.1075 - val_accuracy: 0.9606\n",
            "Epoch 987/1000\n",
            "46/46 - 3s - loss: 0.0335 - accuracy: 0.9795 - val_loss: 0.1058 - val_accuracy: 0.9615\n",
            "Epoch 988/1000\n",
            "46/46 - 3s - loss: 0.0334 - accuracy: 0.9789 - val_loss: 0.1023 - val_accuracy: 0.9659\n",
            "Epoch 989/1000\n",
            "46/46 - 3s - loss: 0.0340 - accuracy: 0.9793 - val_loss: 0.1067 - val_accuracy: 0.9615\n",
            "Epoch 990/1000\n",
            "46/46 - 3s - loss: 0.0351 - accuracy: 0.9776 - val_loss: 0.1039 - val_accuracy: 0.9617\n",
            "Epoch 991/1000\n",
            "46/46 - 3s - loss: 0.0381 - accuracy: 0.9756 - val_loss: 0.1359 - val_accuracy: 0.9561\n",
            "Epoch 992/1000\n",
            "46/46 - 3s - loss: 0.0407 - accuracy: 0.9746 - val_loss: 0.1145 - val_accuracy: 0.9528\n",
            "Epoch 993/1000\n",
            "46/46 - 3s - loss: 0.0476 - accuracy: 0.9767 - val_loss: 0.1056 - val_accuracy: 0.9608\n",
            "Epoch 994/1000\n",
            "46/46 - 3s - loss: 0.0430 - accuracy: 0.9745 - val_loss: 0.4502 - val_accuracy: 0.9248\n",
            "Epoch 995/1000\n",
            "46/46 - 3s - loss: 0.0352 - accuracy: 0.9765 - val_loss: 0.1127 - val_accuracy: 0.9590\n",
            "Epoch 996/1000\n",
            "46/46 - 3s - loss: 0.0345 - accuracy: 0.9789 - val_loss: 0.2555 - val_accuracy: 0.9333\n",
            "Epoch 997/1000\n",
            "46/46 - 3s - loss: 0.0335 - accuracy: 0.9788 - val_loss: 0.1048 - val_accuracy: 0.9625\n",
            "Epoch 998/1000\n",
            "46/46 - 3s - loss: 0.0328 - accuracy: 0.9781 - val_loss: 0.1118 - val_accuracy: 0.9614\n",
            "Epoch 999/1000\n",
            "46/46 - 3s - loss: 0.0365 - accuracy: 0.9777 - val_loss: 0.0975 - val_accuracy: 0.9627\n",
            "Epoch 1000/1000\n",
            "46/46 - 3s - loss: 0.0363 - accuracy: 0.9763 - val_loss: 0.0986 - val_accuracy: 0.9619\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0F_DkMZ-KVe",
        "outputId": "b473d4f4-05e9-4483-e4c0-34f839845cc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#Test_X,Test_Y = prepare_test_data()\n",
        "\n",
        "#Test_Y_1 = to_categorical(Test_Y)\n",
        "Train_Y_1 = to_categorical(Train_Y)\n",
        "#print(Test_X.shape)\n",
        "#print(Test_Y.shape)\n",
        "#print(to_categorical(Test_Y).shape)\n",
        "print(Train_Y.shape)\n",
        "print(to_categorical(Train_Y).shape)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(9180, 9)\n",
            "(9180, 9, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgjRnDLQ-S8b",
        "outputId": "f3d23139-ba16-4919-b060-c4d2a5506327",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from numpy import argmax\n",
        "from numpy import random\n",
        "print ('Training ',model.metrics_names,' = ',model.evaluate(Train_X, Train_Y, verbose=0))\n",
        "print ('Testing  ', model.metrics_names,' = ',model.evaluate(Test_X, Test_Y, verbose=0))\n",
        "print ('true (Test)     \\n',Test_Y[:100].astype('int'))\n",
        "print ('predicted (Test)\\n',model.predict(Test_X[:100]).astype('int'))\n",
        "\n",
        "print ('true (Train)     \\n',Train_Y[:100].astype('int'))    \n",
        "print ('predicted (Train)\\n', model.predict(Train_X[:100]).astype('int'))     #make random check: Test_X*0.0090, random.shuffle(Test_X), Test_X*random.random()*0.05            \n",
        "print (model.summary())\n",
        " \n",
        " \n",
        "#numpy.savetxt('/content/gdrive/My Drive/Colab Notebooks/test_data/fileO.csv',model.predict(Test_X),delimiter=',')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training  ['loss', 'accuracy']  =  [0.03371916711330414, 0.9789760112762451]\n",
            "Testing   ['loss', 'accuracy']  =  [0.10468439012765884, 0.9641301035881042]\n",
            "true (Test)     \n",
            " [[0 0 1 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 1 0 0 0]\n",
            " [0 0 0 0 0 1 0 0 0]\n",
            " [0 0 0 1 0 0 0 0 0]\n",
            " [0 1 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 1 0 0 0 0]\n",
            " [0 0 0 0 1 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 1]\n",
            " [0 0 1 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 1 0 0]\n",
            " [0 0 0 0 0 0 0 0 1]\n",
            " [0 0 1 0 0 0 0 0 0]\n",
            " [0 0 1 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 1 0 0]\n",
            " [0 0 0 0 1 0 0 0 0]\n",
            " [1 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 1 0 0 0 0 0]\n",
            " [0 1 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 1 0 0 0 0]\n",
            " [1 0 0 0 0 0 0 0 0]\n",
            " [0 1 0 0 0 0 0 0 0]\n",
            " [0 0 0 1 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 1]\n",
            " [0 0 0 0 0 0 1 0 0]\n",
            " [0 0 0 0 0 0 0 0 1]\n",
            " [1 0 0 0 0 0 0 0 0]\n",
            " [1 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 1]\n",
            " [0 1 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 1]\n",
            " [0 0 1 0 0 0 0 0 0]\n",
            " [0 0 0 1 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 1 0]\n",
            " [0 0 0 0 0 0 0 1 0]\n",
            " [0 0 0 0 1 0 0 0 0]\n",
            " [1 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 1 0 0 0 0 0]\n",
            " [0 0 0 0 1 0 0 0 0]\n",
            " [0 0 0 1 0 0 0 0 0]\n",
            " [1 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 1 0 0]\n",
            " [0 1 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 1 0]\n",
            " [0 0 0 0 0 0 0 0 1]\n",
            " [0 0 0 0 0 0 0 0 1]\n",
            " [0 0 0 0 0 0 1 0 0]\n",
            " [0 1 0 0 0 0 0 0 0]\n",
            " [0 0 1 0 0 0 0 0 0]\n",
            " [0 1 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 1 0 0 0 0]\n",
            " [0 1 0 0 0 0 0 0 0]\n",
            " [0 1 0 0 0 0 0 0 0]\n",
            " [1 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 1 0 0 0 0 0]\n",
            " [0 0 1 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 1 0]\n",
            " [1 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 1 0 0 0]\n",
            " [0 0 0 0 0 1 0 0 0]\n",
            " [0 0 1 0 0 0 0 0 0]\n",
            " [0 0 1 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 1 0 0]\n",
            " [0 0 0 0 0 0 1 0 0]\n",
            " [1 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 1 0 0 0 0 0]\n",
            " [0 0 0 0 1 0 0 0 0]\n",
            " [0 0 0 0 0 0 1 0 0]\n",
            " [0 0 0 1 0 0 0 0 0]\n",
            " [1 0 0 0 0 0 0 0 0]\n",
            " [0 1 0 0 0 0 0 0 0]\n",
            " [1 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 1 0 0 0 0 0]\n",
            " [0 0 0 0 1 0 0 0 0]\n",
            " [0 0 0 0 0 1 0 0 0]\n",
            " [0 0 0 0 0 1 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 1]\n",
            " [0 0 0 0 0 1 0 0 0]\n",
            " [0 0 0 1 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 1]\n",
            " [0 0 0 1 0 0 0 0 0]\n",
            " [0 1 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 1 0 0 0]\n",
            " [0 0 0 0 0 0 0 1 0]\n",
            " [1 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 1]\n",
            " [0 0 0 0 0 1 0 0 0]\n",
            " [0 0 0 0 0 1 0 0 0]\n",
            " [1 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 1]\n",
            " [0 0 0 0 0 0 1 0 0]\n",
            " [0 0 0 0 0 0 0 1 0]\n",
            " [0 0 0 0 0 0 0 1 0]\n",
            " [0 0 1 0 0 0 0 0 0]\n",
            " [0 0 1 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 1 0 0]\n",
            " [0 1 0 0 0 0 0 0 0]\n",
            " [0 0 1 0 0 0 0 0 0]\n",
            " [1 0 0 0 0 0 0 0 0]\n",
            " [0 0 1 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 1 0]]\n",
            "predicted (Test)\n",
            " [[0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]]\n",
            "true (Train)     \n",
            " [[0 0 0 0 0 0 0 1 0]\n",
            " [0 0 0 0 0 0 0 1 0]\n",
            " [0 0 0 0 1 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 1]\n",
            " [0 1 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 1 0 0]\n",
            " [0 1 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 1 0 0 0 0]\n",
            " [0 0 1 0 0 0 0 0 0]\n",
            " [0 0 0 1 0 0 0 0 0]\n",
            " [0 0 1 0 0 0 0 0 0]\n",
            " [0 0 0 0 1 0 0 0 0]\n",
            " [0 0 0 1 0 0 0 0 0]\n",
            " [0 0 1 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 1 0 0 0]\n",
            " [0 0 0 0 0 0 1 0 0]\n",
            " [0 0 0 0 1 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 1 0]\n",
            " [0 0 1 0 0 0 0 0 0]\n",
            " [1 0 0 0 0 0 0 0 0]\n",
            " [0 0 1 0 0 0 0 0 0]\n",
            " [0 1 0 0 0 0 0 0 0]\n",
            " [1 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 1 0 0]\n",
            " [0 1 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 1 0 0 0]\n",
            " [0 1 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 1 0]\n",
            " [0 0 0 0 1 0 0 0 0]\n",
            " [1 0 0 0 0 0 0 0 0]\n",
            " [0 0 1 0 0 0 0 0 0]\n",
            " [0 0 0 1 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 1 0]\n",
            " [1 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 1]\n",
            " [0 0 0 0 0 0 0 0 1]\n",
            " [0 0 0 1 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 1]\n",
            " [0 0 0 0 0 0 0 1 0]\n",
            " [0 1 0 0 0 0 0 0 0]\n",
            " [1 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 1 0 0]\n",
            " [0 0 0 0 0 0 1 0 0]\n",
            " [0 0 0 0 0 0 1 0 0]\n",
            " [0 0 0 0 0 1 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 1]\n",
            " [0 0 0 0 0 1 0 0 0]\n",
            " [0 0 0 0 0 1 0 0 0]\n",
            " [1 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 1 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 1]\n",
            " [0 0 1 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 1 0]\n",
            " [0 1 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 1]\n",
            " [0 0 0 0 0 0 0 1 0]\n",
            " [0 0 0 0 0 0 1 0 0]\n",
            " [0 0 0 0 0 0 0 0 1]\n",
            " [0 0 0 1 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 1 0 0]\n",
            " [0 0 0 0 0 0 0 0 1]\n",
            " [0 0 0 0 1 0 0 0 0]\n",
            " [0 0 0 0 1 0 0 0 0]\n",
            " [0 1 0 0 0 0 0 0 0]\n",
            " [0 0 0 1 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 1 0 0]\n",
            " [1 0 0 0 0 0 0 0 0]\n",
            " [0 0 1 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 1]\n",
            " [0 0 1 0 0 0 0 0 0]\n",
            " [0 0 1 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 1]\n",
            " [0 0 0 0 0 0 0 0 1]\n",
            " [0 0 0 0 0 0 1 0 0]\n",
            " [0 0 0 0 0 1 0 0 0]\n",
            " [0 0 1 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 1 0 0 0]\n",
            " [0 0 0 1 0 0 0 0 0]\n",
            " [0 0 0 0 1 0 0 0 0]\n",
            " [0 1 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 1 0]\n",
            " [0 0 0 0 0 0 1 0 0]\n",
            " [0 0 0 1 0 0 0 0 0]\n",
            " [0 0 1 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 1]\n",
            " [0 0 0 0 0 0 0 1 0]\n",
            " [0 0 0 0 1 0 0 0 0]\n",
            " [0 1 0 0 0 0 0 0 0]\n",
            " [1 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 1 0 0]\n",
            " [1 0 0 0 0 0 0 0 0]\n",
            " [1 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 1 0 0 0 0]\n",
            " [0 0 0 0 0 1 0 0 0]\n",
            " [0 0 0 0 1 0 0 0 0]\n",
            " [0 0 0 1 0 0 0 0 0]\n",
            " [0 0 1 0 0 0 0 0 0]\n",
            " [0 0 0 0 1 0 0 0 0]\n",
            " [0 0 0 0 0 0 1 0 0]\n",
            " [0 0 1 0 0 0 0 0 0]]\n",
            "predicted (Train)\n",
            " [[0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 1]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0]]\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "data (InputLayer)            [(None, 5, 5000, 1)]      0         \n",
            "_________________________________________________________________\n",
            "conv2d_69 (Conv2D)           (None, 4, 2498, 50)       550       \n",
            "_________________________________________________________________\n",
            "conv2d_70 (Conv2D)           (None, 3, 1249, 50)       10050     \n",
            "_________________________________________________________________\n",
            "batch_normalization_117 (Bat (None, 3, 1249, 50)       200       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_54 (MaxPooling (None, 3, 124, 50)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_71 (Conv2D)           (None, 2, 60, 50)         25050     \n",
            "_________________________________________________________________\n",
            "conv2d_72 (Conv2D)           (None, 2, 28, 50)         12550     \n",
            "_________________________________________________________________\n",
            "batch_normalization_118 (Bat (None, 2, 28, 50)         200       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_55 (MaxPooling (None, 2, 3, 50)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_73 (Conv2D)           (None, 1, 1, 50)          15050     \n",
            "_________________________________________________________________\n",
            "batch_normalization_119 (Bat (None, 1, 1, 50)          200       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_56 (MaxPooling (None, 1, 1, 50)          0         \n",
            "_________________________________________________________________\n",
            "flatten_9 (Flatten)          (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense_72 (Dense)             (None, 64)                3264      \n",
            "_________________________________________________________________\n",
            "batch_normalization_120 (Bat (None, 64)                256       \n",
            "_________________________________________________________________\n",
            "dense_73 (Dense)             (None, 58)                3770      \n",
            "_________________________________________________________________\n",
            "batch_normalization_121 (Bat (None, 58)                232       \n",
            "_________________________________________________________________\n",
            "dense_74 (Dense)             (None, 52)                3068      \n",
            "_________________________________________________________________\n",
            "batch_normalization_122 (Bat (None, 52)                208       \n",
            "_________________________________________________________________\n",
            "dense_75 (Dense)             (None, 46)                2438      \n",
            "_________________________________________________________________\n",
            "batch_normalization_123 (Bat (None, 46)                184       \n",
            "_________________________________________________________________\n",
            "dense_76 (Dense)             (None, 40)                1880      \n",
            "_________________________________________________________________\n",
            "batch_normalization_124 (Bat (None, 40)                160       \n",
            "_________________________________________________________________\n",
            "dense_77 (Dense)             (None, 32)                1312      \n",
            "_________________________________________________________________\n",
            "batch_normalization_125 (Bat (None, 32)                128       \n",
            "_________________________________________________________________\n",
            "dense_78 (Dense)             (None, 16)                528       \n",
            "_________________________________________________________________\n",
            "batch_normalization_126 (Bat (None, 16)                64        \n",
            "_________________________________________________________________\n",
            "dense_79 (Dense)             (None, 9)                 153       \n",
            "=================================================================\n",
            "Total params: 81,495\n",
            "Trainable params: 80,579\n",
            "Non-trainable params: 916\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zh9bju8u-W5-",
        "outputId": "040d8319-466e-4c8b-a6a3-0693a2106c8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 590
        }
      },
      "source": [
        "#Plot the model\n",
        " \n",
        "plot_model(model, to_file='model.png', show_shapes = True, show_layer_names = True)\n",
        " \n",
        "print(history.history.keys())\n",
        "# Plot training & validation accuracy values\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()\n",
        " \n",
        "# Plot training & validation loss values\n",
        "plt.plot(history.history['loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxU9b3/8dcnk5UQwhZACBAQlMUFNOKuqG3dWultbSu3t9Vq60N/rdbbxWoXtVZvq128eq9ttdVLN7VWa0tdcMFdURZFVpEdgixJgLBlz+f3x5wMM8kEEmSYJOf9fDzyYM4yc74nR+ed7/d7zvdr7o6IiIRXRroLICIi6aUgEBEJOQWBiEjIKQhEREJOQSAiEnIKAhGRkFMQiLSDmZWYmZtZZjv2vczMXv+onyNyqCgIpNsxszVmVmdm/Vusfzf4Ei5JT8lEOicFgXRXq4GpzQtmdjTQI33FEem8FATSXf0J+HLc8qXAH+N3MLNCM/ujmZWb2Voz+6GZZQTbImb2CzOrMLNVwIVJ3vuAmW00sw1mdpuZRTpaSDMbbGbTzWyrma0ws6/FbZtkZnPNbIeZbTazXwXrc83sz2ZWaWbbzWyOmQ3s6LFFmikIpLt6C+hlZmODL+hLgD+32Od/gEJgJHAm0eD4SrDta8AngYlAKXBxi/dOAxqAUcE+nwC+egDlfAQoAwYHx/gvMzs72HY3cLe79wIOBx4N1l8alHso0A+4Cqg+gGOLAAoC6d6aawUfB5YCG5o3xIXDje6+093XAL8EvhTs8nngv919vbtvBX4a996BwAXAde6+2923AHcFn9duZjYUOBX4nrvXuPt84PfsrcnUA6PMrL+773L3t+LW9wNGuXuju89z9x0dObZIPAWBdGd/Av4duIwWzUJAfyALWBu3bi0wJHg9GFjfYluz4cF7NwZNM9uB+4ABHSzfYGCru+9sowxXAEcA7wfNP5+MO69ngUfM7EMzu9PMsjp4bJEYBYF0W+6+lmin8QXA31tsriD6l/XwuHXD2Ftr2Ei06SV+W7P1QC3Q3917Bz+93H18B4v4IdDXzAqSlcHdl7v7VKIBcwfwmJnlu3u9u//Y3ccBpxBtwvoyIgdIQSDd3RXA2e6+O36luzcSbXO/3cwKzGw48C329iM8ClxrZsVm1ge4Ie69G4HngF+aWS8zyzCzw83szI4UzN3XA28CPw06gI8JyvtnADP7DzMrcvcmYHvwtiYzO8vMjg6at3YQDbSmjhxbJJ6CQLo1d1/p7nPb2HwNsBtYBbwOPAQ8GGz7HdHml/eAd2hdo/gykA0sAbYBjwGHHUARpwIlRGsHTwA3u/sLwbbzgMVmtotox/El7l4NDAqOt4No38crRJuLRA6IaWIaEZFwU41ARCTkFAQiIiGnIBARCTkFgYhIyHW5oXD79+/vJSUl6S6GiEiXMm/evAp3L0q2rcsFQUlJCXPntnU3oIiIJGNma9vapqYhEZGQUxCIiIScgkBEJOS6XB9BMvX19ZSVlVFTU5PuoqRcbm4uxcXFZGVpsEkROTi6RRCUlZVRUFBASUkJZpbu4qSMu1NZWUlZWRkjRoxId3FEpJvoFk1DNTU19OvXr1uHAICZ0a9fv1DUfETk0OkWQQB0+xBoFpbzFJFDp9sEwf7U1DeyqaqG+kYN2y4iEi9UQbBlZw2NTQd/2O3KykomTJjAhAkTGDRoEEOGDIkt19XV7fO9c+fO5dprrz3oZRIRaa9u0Vmcbv369WP+/PkA3HLLLfTs2ZPvfOc7se0NDQ1kZib/VZeWllJaWnpIyikikkzKagRm9qCZbTGzRW1s/6KZLTCzhWb2ppkdm6qypMNll13GVVddxYknnsj111/P7NmzOfnkk5k4cSKnnHIKy5YtA+Dll1/mk5+Mzkl+yy23cPnllzN58mRGjhzJPffck85TEJGQSGWNYBrwv8Af29i+GjjT3beZ2fnA/cCJH/WgP/7XYpZ8uKPV+sYmp6a+kbzsCBkd7HAdN7gXN3+qo/OSR29rffPNN4lEIuzYsYPXXnuNzMxMXnjhBb7//e/z+OOPt3rP+++/z0svvcTOnTs58sgjufrqq/XMgIikVMqCwN1fNbOSfWx/M27xLaA4VWVJl8997nNEIhEAqqqquPTSS1m+fDlmRn19fdL3XHjhheTk5JCTk8OAAQPYvHkzxcXd7lcjIp1IZ+kjuAJ45mB8UFt/uVdV17G2cg+jBxSQlx05GIfar/z8/NjrH/3oR5x11lk88cQTrFmzhsmTJyd9T05OTux1JBKhoaEh1cUUkZBLexCY2VlEg+C0fexzJXAlwLBhww5RyQ6uqqoqhgwZAsC0adPSWxgRkThpvX3UzI4Bfg9McffKtvZz9/vdvdTdS4uKks6r0J6jNX/aAb7/o7n++uu58cYbmThxov7KF5FOxdxT98UY9BE86e5HJdk2DHgR+HKL/oJ9Ki0t9ZYT0yxdupSxY8fu831V1fWsrdzN6AE9yctOe0XoI2nP+YqIxDOzee6e9F71lH0jmtnDwGSgv5mVATcDWQDu/lvgJqAf8Otg2ISGtgopIiKpk8q7hqbuZ/tXga+m6vgiItI+3WaIif01caW3h+DgSWVTnoiEU7cIgtzcXCorK7v9l2TzfAS5ubnpLoqIdCNdu9c0UFxcTFlZGeXl5W3uU1PfSMWuOnxbDtmZXTf/mmcoExE5WLpFEGRlZe13xq6ZSzfztelz+efXT2Xs0N6HqGQiIp1f1/3TuIOahxfq3o1HIiIdF54gCLqLu3s/gohIR4UmCNAMjyIiSYUnCAKqD4iIJApNEMSeI1ASiIgkCE8QWHd5pExE5OAKTxCkuwAiIp1UaIKgmZqGREQShSYI9ByBiEhy4QmC2HMEaS6IiEgnE54gUCeBiEhSoQmCZnqyWEQkUWiCQDePiogkF5ogaE4CVQhERBKFJghMTxKIiCQVmiBo5mocEhFJEJog0AgTIiLJhScIgn+VAyIiicITBHqQQEQkqdAEQTPdNSQikihlQWBmD5rZFjNb1MZ2M7N7zGyFmS0ws+NSVZbo8aL/qrNYRCRRKmsE04Dz9rH9fGB08HMl8JsUlkUT04iItCFlQeDurwJb97HLFOCPHvUW0NvMDktVedRFICKSXDr7CIYA6+OWy4J1rZjZlWY218zmlpeXf6SDqkIgIpKoS3QWu/v97l7q7qVFRUUH+CnNw1ArCkRE4qUzCDYAQ+OWi4N1KaGJaUREkktnEEwHvhzcPXQSUOXuG1N1MHURiIgkl5mqDzazh4HJQH8zKwNuBrIA3P23wNPABcAKYA/wlVSVJYGqBCIiCVIWBO4+dT/bHfh6qo7fUvOTxXqOQEQkUZfoLD4Y9ByBiEhy4QkCdRKIiCQVmiBophqBiEii0ARB8wxlygERkUThCYLYnMWKAhGReKEJAhERSS50QaD6gIhIotAEwd6mofSWQ0SkswlPEGjWYhGRpMITBHqOQEQkqdAEQTM1DYmIJApNEGgYahGR5MITBLGJadJcEBGRTiY8QaA+AhGRpEITBM00DLWISKLQBIGGoRYRSS48QaDOYhGRpEITBJq1WEQkuRAFQZRGHxURSRSaINBdQyIiyYUnCIJ/VSEQEUkUniBQlUBEJKnQBEEzPUcgIpIoNEGgpiERkeRSGgRmdp6ZLTOzFWZ2Q5Ltw8zsJTN718wWmNkFqStL9F8FgYhIopQFgZlFgHuB84FxwFQzG9ditx8Cj7r7ROAS4NcpK4+eIxARSSqVNYJJwAp3X+XudcAjwJQW+zjQK3hdCHyYwvLEDigiInulMgiGAOvjlsuCdfFuAf7DzMqAp4Frkn2QmV1pZnPNbG55efkBFWZv05CiQEQkXro7i6cC09y9GLgA+JOZtSqTu9/v7qXuXlpUVPSRDqgYEBFJlMog2AAMjVsuDtbFuwJ4FMDdZwG5QP9UFEaPEYiIJJfKIJgDjDazEWaWTbQzeHqLfdYB5wCY2ViiQXBgbT/tpSqBiEiClAWBuzcA3wCeBZYSvTtosZndamYXBbt9G/iamb0HPAxc5ilqxG9+slgPlImIJMpM5Ye7+9NEO4Hj190U93oJcGoqy9BMD5SJiCSX7s7iQ0Z9BCIiyYUmCJqpQiAikig0QdD8ZLGahkREEoUnCGJzFisJRETihScI0l0AEZFOKjRB0ExNQyIiicITBLGmIRERiReaIIgNQ60qgYhIgvAEgToJRESSCk0QNFN9QEQkUWiCQENMiIgkF54gaB50TkkgIpIgPEGQ7gKIiHRSoQmCZqoPiIgkalcQmFl+8xSSZnaEmV1kZlmpLdrBZbp7VEQkqfbWCF4Fcs1sCPAc8CVgWqoKlQqxQefSXA4Rkc6mvUFg7r4H+Azwa3f/HDA+dcVKAXUSiIgk1e4gMLOTgS8CTwXrIqkpUmrpriERkUTtDYLrgBuBJ4J5h0cCL6WuWAefniwWEUmuXXMWu/srwCsAQadxhbtfm8qCHWx6oExEJLn23jX0kJn1MrN8YBGwxMy+m9qiHVymKoGISFLtbRoa5+47gE8DzwAjiN451OVohjIRkUTtDYKs4LmBTwPT3b2eLnYnppqGRESSa28Q3AesAfKBV81sOLAjVYVKBdPENCIiSbUrCNz9Hncf4u4XeNRa4Kz9vc/MzjOzZWa2wsxuaGOfz5vZEjNbbGYPdbD87WZ6kEBEJKl23TVkZoXAzcAZwapXgFuBqn28JwLcC3wcKAPmmNl0d18St89oorelnuru28xswAGdRQeoaUhEJFF7m4YeBHYCnw9+dgD/t5/3TAJWuPsqd68DHgGmtNjna8C97r4NwN23tLfgHbW3aUhJICISr101AuBwd/9s3PKPzWz+ft4zBFgft1wGnNhinyMAzOwNok8q3+LuM1p+kJldCVwJMGzYsHYWOTnVCEREErW3RlBtZqc1L5jZqUD1QTh+JjAamAxMBX5nZr1b7uTu97t7qbuXFhUVHdCBMjQxjYhIUu2tEVwF/DHoKwDYBly6n/dsAIbGLRcH6+KVAW8Ht6OuNrMPiAbDnHaWq90iGdEgaGw62J8sItK1tfeuoffc/VjgGOAYd58InL2ft80BRpvZCDPLBi4BprfY5x9EawOYWX+iTUWr2l/89gtygEbVCEREEnRohjJ33xE8YQzwrf3s2wB8A3gWWAo8GgxYd6uZXRTs9ixQaWZLiA5i9113r+zQGbSTmZFh0NSkIBARidfepqFk9ntjvrs/DTzdYt1Nca+daKDsM1QOlkiGqUYgItLCR5mzuMt9o2aYqUYgItLCPmsEZraT5F/4BuSlpEQpFMkwGhUEIiIJ9hkE7l5wqApyKERMTUMiIi19lKahLicjQ01DIiIthSoI1FksItJaqIIgw0wPlImItBCqIIhk6DkCEZGWQhUEGWY0qWlIRCRB6IJAfQQiIolCFQQR3TUkItJK6IKgUTkgIpIgVEGgQedERFoLVRBoiAkRkdZCFQTqLBYRaS1UQaDOYhGR1kIXBKoRiIgkClUQRIeYUBCIiMQLVRBEMvRksYhIS+EKAtUIRERaCVUQZGRAk0YfFRFJEKogUGexiEhrIQuCDBo0IYGISIJQBUFeVgY19QoCEZF4IQuCCDUNjekuhohIp5LSIDCz88xsmZmtMLMb9rHfZ83Mzaw0leXJy45QXacgEBGJl7IgMLMIcC9wPjAOmGpm45LsVwB8E3g7VWVplpsVobpeQSAiEi+VNYJJwAp3X+XudcAjwJQk+/0EuAOoSWFZgGgQ1CgIREQSpDIIhgDr45bLgnUxZnYcMNTdn9rXB5nZlWY218zmlpeXH3CB8rIi1Dc69bpzSEQkJm2dxWaWAfwK+Pb+9nX3+9291N1Li4qKDviYeVkRANUKRETipDIINgBD45aLg3XNCoCjgJfNbA1wEjA9lR3GudnRIFA/gYjIXqkMgjnAaDMbYWbZwCXA9OaN7l7l7v3dvcTdS4C3gIvcfW6qChSrEdSpaUhEpFnKgsDdG4BvAM8CS4FH3X2xmd1qZhel6rj70hwEqhGIiOyVmcoPd/engadbrLupjX0np7IsAHnZ0dxTH4GIyF6herI4N1M1AhGRlsIVBOosFhFpJVRBsLezWEEgItIslEGgGoGIyF6hCoKeudG+8R3V9WkuiYhI5xGqIOjTI5sMg4pddekuiohIpxGqIIhkGH3zc6jYVZvuooiIdBqhCgKA/j2zFQQiInFCFwRFBTmUq2lIRCQmdEHQv2cOlaoRiIjEhC4I+uVHm4bcPd1FERHpFEIXBP0Lcqipb2K3HioTEQHCGAQ9cwCo2KnmIRERCGUQZAPoziERkUAIgyCoESgIRESAEAZBUUE0CHQLqYhIVOiCoG9+tGlIt5CKiESFLgiyIhn06ZGlpiERkUDoggCi/QQVO9U0JCICYQ4C1QhERICwBkGBgkBEpFk4g6BntuYkEBEJhDQIcthV20CNpqwUEQlnEBTmZQHwm5dXprkkIiLpl9IgMLPzzGyZma0wsxuSbP+WmS0xswVmNtPMhqeyPM2aHyr7nxeXH4rDiYh0aikLAjOLAPcC5wPjgKlmNq7Fbu8Cpe5+DPAYcGeqyhPvE+MG0qdHFhOG9j4UhxMR6dRSWSOYBKxw91XuXgc8AkyJ38HdX3L3PcHiW0BxCssTY2acPrqIrbvVYSwiksogGAKsj1suC9a15QrgmWQbzOxKM5trZnPLy8sPSuHyczLZVavOYhGRTtFZbGb/AZQCP0+23d3vd/dSdy8tKio6KMcsyM1kV2095Ttr2VlTf1A+U0SkK0plEGwAhsYtFwfrEpjZx4AfABe5+yF7yis/O5Oa+iZOuP0Fzr3r1UN1WBGRTieVQTAHGG1mI8wsG7gEmB6/g5lNBO4jGgJbUliWVvJzIrHXH1bVHMpDi4h0KikLAndvAL4BPAssBR5198VmdquZXRTs9nOgJ/A3M5tvZtPb+LiDrvlZAhGRsMtM5Ye7+9PA0y3W3RT3+mOpPP6+nHvUIL772ILY8sryXRxe1DNdxRERSZtO0VmcDr1ys5hx3en8+ovHAfDlB2azZYeaiEQkfEIbBABjBvXi3PGDANiwvZpJ/zWTxianobGJd9dtS3PpREQOjZQ2DXUFkQxLWB77oxnUNTYBMOO60xkzqFer99Q2NGIY2ZmhzlER6Sb0TQYcP7xP7HVzCABMe2MNs1dvBWBhWRXLN+8E4NSfvcRpd7xIxa5avvfYAo1iKiJdmoIA+OuVJzF+cOu//B+Zs57P3zeLsm17+NT/vs7Hg+cNKnbVsmVnLb98bhl/nbuef7334aEusojIQaMgADIjGTx17ek8ec1pjBlU0Gp7/ANnlXEzmz08OzqCxvceX8DSjTtSX1ARkRRQEMQ5akghM647g7GHJdYOdtftbfo5/rYXWr2vyeHyaXN4bXk57p7ycoqIHEwKgiSevva02Ot7//24dr1nY1UNX3pgNo/NK0tVsUREUkJBkISZMXVSdJikM49sPcjdhKG9+fSEwbHl+KeUX11eQVOTagUi0nWE/vbRtvxkylF84+zR9MzJ5LJTSpixaBObggfOpkwYzFdOHUFtQxM7axo4ZVQ/7pyxDIB/vfchhXmZnDaqiPVb93D5aSN4fF4Zhw/omXB3kohIZ2FdrU27tLTU586dm5ZjX//Yezw6t4xpXzmByUcOAMDdqa5v5IbHFzI9yd1D154zmntmLmfUgJ688K0zk35ubUMjdz2/nH+bOIQjk3RWp0p9YxNGtLNcRLo3M5vn7qXJtukboAN+fNFR3PnZYzhtVP/YOjOjR3Ym90ydyPLbz+eOzx6d8J43V1QAsGLLLv7y9lqq6xpZV7knYZ8/zVrLb19ZybQ317R57E1VNTy9cOPBOxlgwo+f46xfvnxQP1NEuh4FQQfkZUf4/AlD2/wLOiuSwRdOGMZtnz4qtm7u2r1DVfzgiUWMvWkGZ/z8Jf7xbnRqhjUVu7ntqaXA3ltT3Z1/zt/AtmAqzaYm56SfzuT//eUd5qzZynOLNzH55y9RH/fwG0TD4pbpi1utb8vuukbWb61u59mLSHelPoIU+I+ThlNT3xj7gr91ynjWVOzhwTdWx/a57q/zqa5v5Ma/L4yte27JZi65fxZz1myjMehw/tlnjuaGuH3e37iDu2euiD3UNqR3Xmzbj/65iOeXbOasMQM484iDM5ObSFe2fuseemRH6NczJ91F6dRUI0iRr54+kqeuPY2PjR3I544fyk2fGsfdl0zgvPGDyAnGKIoPgQcvizbdvbVqaywEgIQQAHh64Saq6xoA2LqrLmFb81AXlz44mxmLNvHQ2+v49csrgOgw21dMm8Oe4L3psG13Hdv31O1/x27I3RMeRpRD4/Q7X+K0O15KdzE6PdUIUmj84EJ+f+nevpkpE4YwZcIQAL75yLv8c360c7l0eB/OHjOwXZ85a1Vl7PW8tVsZN7gXL76/hc07anhteUVs2/ceX0BVdXQu5guPPozP/3YWlbvrmLWyknPGDkx6i2tzAGVY9CG5+15dyRcnDaewR/JJfH74j4VMPmIAJ47sG2ti2lFTz0kj+yXdf+JPngdgzc8ubNe5tiybARktBgnsKn7/2mpuf3opr3/vLIr79Eh3cUKlWmOB7ZeCIE3uvmQiXzt9JL94bhk3fXIcAJefOoInF3zIlWeM5NRR/ZmzZis3/XMxEK0xvLKsnD/MWhv7jJ88tZQH3lidtJ2/OQQAzvz5y7HXe+oaeWHJZr76x713XpXc8BT9e2bjDtmZGYwa0DMWKg+9vY57pk7kuGF92LKjhpzMCIU9sti+p44/v7WOP7+1jslHFvHysvLY53X0i/7Gvy/kucWbmP2Dj8VGg12+eSd3zHifWy4aT3GfHhx187OMH9yLx64+pUOf/czCjdQ1NsUCOF2eXbwJgPVbqzttEOyqbeDnM97nO+ceSUFu6mbwW7pxB4N754V2lsCH3l7HpBF96ZWbyeqK3ZzYxh9Oh5KCII2OGlLItK9Mii3f9Klx/ODCsbEvw7GH9eLkkf3YWFXDGUcUMfmIAVw1+XDuev4DhvfL5+4Xlne4s/dPs9Yye83WVusr4pqZNsbN4Vy2rZrP/PrN2HJuVga/+eLxfGXanNi6+BAAuGfmco4pLuSEkr68tGwL9Y1N3PSPxbHtzy3exPpt1Vx8fDGFeVk8PHsdALc/tZSbPjUOd+cHTyxi9pqtnFDSly+cMJTq+kbmrt3Gtx6dzzljBtK7RxZvrKjg+vPGxD53w/ZqsiLGgIJcINrJfvVf3omd01dPG0FmJIPahkZeen8Lnxg3KKGGcd0j73LEoAKuPvNwzFrXPGobGsnKyGBN5W6yIhkM7dv2F/qNf1/A2WMG8vFx0ZpeRvB51fV7m+aqqut54p0yvnDCMPKyI1TuqiU3K0J+Ttv/W+6qbWD26sqEGmRVdT23TF/MDy8cG2sLd3fKtlXvs4wtPfT2Wv4way1983MYc1gBPXMyOTXuDrlmjU3eavj29mpqcs6/+zWOHlLIv645bf9vaIetu+vIycxo9Xurbeh8NYGGxia+/8RCeuZkMrRvD5Zu3MHiH5+7z2t+KOg5gi5sbeVuMswwizYF3TrlKNZU7ObXL6/kZ585muv+Op+GRic/J8Lu2kZ65WUyZ030LqarzjycPj2yuHvmcvbUdZ7/YYb17UGvvEwWbWjfIH5FBTnc9MlxFOZl8fW/vEOjOz/9zNEU9czh2kfmUxHXLn/K4f1YXbE7Iehu/7ejmHrCMGobmhh70wwA+vTIYt4PP06TOxW76hhUmMvGqmpO/umLCcdefvv5/PbllTjRGwR+9fwyzh0/iBH982Pt0gtu+QRT/vcNVlfsBuDOi4/h86XRp9Z/8uQSHnh9NbdOGc+XTy5h/E0zyIxkMP+mj2NmNDVFn1F5d912Jg7rTW5WhB/+YxEPz17Hk9ecxlFDCgH47Ssr+dkz73P15MP5XhCMdz3/AXfPXM6z153BkYMKaGpynlq4kTNGF1HYIwt359nFm5g0oh9987MB+N2rq7j96aVcdkpJ7FbmTx07mLJte3ji/50KwJadNUy6fSa/+NyxXHx8cex3UbWnvs0mxPKdtfzPi8v57rlHsru2kZN+OhNof81xZ0093/nbe/zggnEM69c62EpueIqR/fN58TuTE9ZX7qqNjQ12IM2R+1Jd18jj75RxyT7uIkwmvkzN/nj5JM7Yx80ds1ZWxq7/R7Gv5wgUBCHS2OQ8v2QTW3bW8qWThmNmbN9TR0aGMW/NNo4pLuSemcvZWFXDuq17+O9LJrCmYg/vrNvGA6+v5ozR/emVl8WeukZqG5r44YVj+c+/zqdPj2wmH1lEcZ8ezFpZkdB8dUJJn1j4zPnBx3h64UZunh6tHRQV5FC+M/pFfc6YAcx8f8uh/6W0w6QRfZm3dltCJ/6+DOmdx4btbdfUpk4aSlV1Pc8s2kTz/34//czRCTcPPPTVE3ni3Q38LW7sqsOL8tmys5adNdFaxZ2fPYYjBxUw5d43YvtMmTCYq848nC89MJuKXbV8/azDOX10EYs2VHHbU0s5YmBPbvnUeN5avZV7Zi5nYK8c3rzhHBqamvjdq6v4xXMfcPzwPsxbmzhD34JbPsG0N9bwq+c/AKBvfja/+eJx5GRFeOKdMv4way3XnD2KuoYmrjh9BFt21MaC6uZ/LuIPs9Zy6cnD+dSxg7n4t7MAuO9LxzOsb4/YII976hrYvqeeD7dXs3V3HRW76li6cQd/eiv639MlJwzlhvPHUJiXxeYdtfzsmaVcc85ozvnlKwA8ec1p1DU2cdywPtQ1NHHHjPd54PXonXrnHzWIvOwIv7j42Fgt8MHXV3PXCx/w3H+ewWGFe+++g2h43ffKSt5YWcltnx7P8cP7Jmy/7ckl/P711fxkyngyMoxH56zn+vPGcOqo/qyr3ENhXlbSYFxZvitW3n752VTuruOyU0q45aLxALHwb64hrNiyk4/96lX+beIQ7vrChKT/PbWXgkAOuZr6RrIjGWRkGHvqGsiKZJAV95eTu2NmVNc1kp2ZQSTY7/F3NlBT18ixQ3tz9JBCKnbVMrBXLnPWbCU3K8KAghzeXr2VXrmZ9M3P5q9z1o7nuwoAAApgSURBVPO3eWWcOKIvP7xwHB9WVfP711aRmZFBXnaEIb3z+PpZo2hy5w+z1pBhRo+sCEcOKuDxd8p4dvHmfZ5Hz5xMdtVGv3iH9e3Buq172tw3JzMjOtVpG4HRv2dOQg0lHZpvBDgUJpX05dJTSvj6Q9HmuYLcTE4e2Y/nliT+zr9/wRg+3F7D3+auTxjp90CNGtCTFVt2Jd127NDe4E7f/GxeCpo087Mj/PLzExg1IJ+sSAblO2v59t/eY23w4OeAghwuOWEogwrzmHxkEa8vr+D6xxck/fyZ3z4z9kV/THEhE4ZG/5LfVFXD8H496JufzY//taTV+04e2Y+tu+tYFkx+9dXTRnDlGSO564UPeHj2eszgmrNGccKIvpw++sBuDVcQiLShqckTZqXbXdtAz9xMNlXVkJcVYUCvXDbvqGHpxh0Jw4rMXr2V/gU5HF7Uk4bGJhqanMYmZ2X5LtZU7uHMI4romZPJjEWbOHZoYayDeG3lbt5cWcmQ3nks3FDFVWcezs6aep5dvInxgwvp3SOLv80tY86arSzfsov//sIERvTPZ2CvXN5dt41FG6r47PHFvPj+Fl75oJytu+vo3zOHH104joUbqrhn5nI+rKrGHW77t6N4bvEmSvrls6OmnouPH8r7G3dw57PLGNgrh3PHD6K6vpFZKysp6ZfPyvJdXH7qCB6bV8bLH2yhdHhfXl9RwYXHHMYzCzfGAuRjYwfwwtLE2tsxxYUsKKsCooMwxt+sADC4MJdte+qprm/komMHs2zTztiXXvw+Q/v24O3ViX1YWREjJzPCrtoGJo3oy4fbqynb1r6+sXPGDGBjVQ1L2pgvZFCv3NgYYsl86aThsRpJR+VmZVBTv++HO39+8TH8c/6HzFpV2a4a59fPOpzvnjtmv/sloyAQkQ6prmskL3tvm/Su2gayIxmxebp31TaQkxmt5TV3Hu+sqSc3KxKr+W3YXs3yzTsZ1rcHI4t68sHmnazfuoezx0QDtaq6Hvdoc8nwfvkUFezt6H5r1VaK++S12dm9fPNOCntk8e667Ywa0BOARRuiQTR6QEHwEFk2BblZ1DY0UlPfFLtLaVNVDXvqGhhUmEteVoRZKytZsnEHNfWNNHm02au6rpHPHl9M77ws/rXgQ7bvqWdV+S7MjKrqek4d1Z8Ljz6MxR9WcUxxb7IzM3h33TbeW7+dooJcGpqamHzkAMp31vL68nKq65vYWBVt8ho3uBdfOmk4q8p3c/SQQjIyjPrGJp5ZtInTR/WnIDeTP85ay8aqaiYM7cPHxw3k+SWbqWts5MKjBx/wXOkKAhGRkEvboHNmdp6ZLTOzFWZ2Q5LtOWb212D722ZWksryiIhIaykLAjOLAPcC5wPjgKlmNq7FblcA29x9FHAXcEeqyiMiIsmlskYwCVjh7qvcvQ54BJjSYp8pwB+C148B51iyJ3lERCRlUhkEQ4D1cctlwbqk+7h7A1AFtHre2syuNLO5Zja3vLy85WYREfkIusToo+5+v7uXuntpUZGGVxYROZhSGQQbgKFxy8XBuqT7mFkmUAhUIiIih0wqg2AOMNrMRphZNnAJML3FPtOBS4PXFwMvele7n1VEpItL2ZB37t5gZt8AngUiwIPuvtjMbgXmuvt04AHgT2a2AthKNCxEROQQ6nIPlJlZOXBgz3xDf6Biv3t1LzrncNA5h8NHOefh7p60k7XLBcFHYWZz23qyrrvSOYeDzjkcUnXOXeKuIRERSR0FgYhIyIUtCO5PdwHSQOccDjrncEjJOYeqj0BERFoLW41ARERaUBCIiIRcaIJgf3MjdFVmNtTMXjKzJWa22My+Gazva2bPm9ny4N8+wXozs3uC38MCMzsuvWdwYMwsYmbvmtmTwfKIYE6LFcEcF9nB+m4z54WZ9Tazx8zsfTNbamYnd+frbGb/Gfw3vcjMHjaz3O54nc3sQTPbYmaL4tZ1+Lqa2aXB/svN7NJkx2pLKIKgnXMjdFUNwLfdfRxwEvD14NxuAGa6+2hgZrAM0d/B6ODnSuA3h77IB8U3gaVxy3cAdwVzW2wjOtcFdK85L+4GZrj7GOBYouffLa+zmQ0BrgVK3f0ooqMTXEL3vM7TgPNarOvQdTWzvsDNwIlEpwC4uTk82sXdu/0PcDLwbNzyjcCN6S5Xis71n8DHgWXAYcG6w4Blwev7gKlx+8f26yo/RAcwnAmcDTwJGNGnLTNbXm+iQ5ycHLzODPazdJ/DAZxzIbC6Zdm763Vm7xD1fYPr9iRwbne9zkAJsOhAryswFbgvbn3Cfvv7CUWNgPbNjdDlBdXhicDbwEB33xhs2gQMDF53h9/FfwPXA03Bcj9gu0fntIDEc2rXnBddwAigHPi/oEns92aWTze9zu6+AfgFsA7YSPS6zaP7X+dmHb2uH+l6hyUIuj0z6wk8Dlzn7jvit3n0T4RucZ+wmX0S2OLu89JdlkMsEzgO+I27TwR2s7e5AOh217kP0RkMRwCDgXxaN5+EwqG4rmEJgvbMjdBlmVkW0RD4i7v/PVi92cwOC7YfBmwJ1nf138WpwEVmtobo9KdnE2077x3MaQGJ59Rd5rwoA8rc/e1g+TGiwdBdr/PHgNXuXu7u9cDfiV777n6dm3X0un6k6x2WIGjP3AhdkpkZ0eG8l7r7r+I2xc/1cCnRvoPm9V8O7j44CaiKq4J2eu5+o7sXu3sJ0ev4ort/EXiJ6JwW0Pp8u/ycF+6+CVhvZkcGq84BltBNrzPRJqGTzKxH8N948/l26+scp6PX9VngE2bWJ6hNfSJY1z7p7iQ5hJ0xFwAfACuBH6S7PAfxvE4jWm1cAMwPfi4g2j46E1gOvAD0DfY3ondQrQQWEr0rI+3ncYDnPhl4Mng9EpgNrAD+BuQE63OD5RXB9pHpLvdHON8JwNzgWv8D6NOdrzPwY+B9YBHwJyCnO15n4GGi/SD1RGt+VxzIdQUuD85/BfCVjpRBQ0yIiIRcWJqGRESkDQoCEZGQUxCIiIScgkBEJOQUBCIiIacgEGnBzBrNbH7cz0EbrdbMSuJHmRTpDDL3v4tI6FS7+4R0F0LkUFGNQKSdzGyNmd1pZgvNbLaZjQrWl5jZi8H48DPNbFiwfqCZPWFm7wU/pwQfFTGz3wVj7T9nZnlpOykRFAQiyeS1aBr6Qty2Knc/GvhfoqOgAvwP8Ad3Pwb4C3BPsP4e4BV3P5bouECLg/WjgXvdfTywHfhsis9HZJ/0ZLFIC2a2y917Jlm/Bjjb3VcFA/1tcvd+ZlZBdOz4+mD9Rnfvb2blQLG718Z9RgnwvEcnHMHMvgdkufttqT8zkeRUIxDpGG/jdUfUxr1uRH11kmYKApGO+ULcv7OC128SHQkV4IvAa8HrmcDVEJtjufBQFVKkI/SXiEhreWY2P255hrs330Lax8wWEP2rfmqw7hqiM4d9l+gsYl8J1n8TuN/MriD6l//VREeZFOlU1Ecg0k5BH0Gpu1ekuywiB5OahkREQk41AhGRkFONQEQk5BQEIiIhpyAQEQk5BYGISMgpCEREQu7/A98EDBP+4v+AAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMxOw2un-hDZ"
      },
      "source": [
        "#print (model.predict_classes(Test_X[:1,]))\n",
        "#model.save('my_model.h5')\n",
        "#Test_X[0]"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pafL7Li0jyXW"
      },
      "source": [
        ""
      ],
      "execution_count": 25,
      "outputs": []
    }
  ]
}